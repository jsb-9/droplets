{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af9ca3ba-3cc3-4e10-a207-3ba2d183c79b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:28:31.159125Z",
     "iopub.status.busy": "2024-12-12T04:28:31.158596Z",
     "iopub.status.idle": "2024-12-12T04:28:33.382171Z",
     "shell.execute_reply": "2024-12-12T04:28:33.380925Z",
     "shell.execute_reply.started": "2024-12-12T04:28:31.159102Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal\n",
    "import plotly.graph_objects as go\n",
    "import polars as pl\n",
    "from dash import Dash, dcc, html\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "nse = mcal.get_calendar(\"NSE\")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 25_000)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pl.Config.set_tbl_cols(500)\n",
    "pl.Config.set_tbl_rows(10_000)\n",
    "\n",
    "pd.options.display.float_format = \"{:.4f}\".format\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "# from tooling.enums import AssetClass, Index, Spot, StrikeSpread\n",
    "# from tooling.fetch import fetch_option_data, fetch_spot_data\n",
    "# from tooling.filter import find_atm, option_tool\n",
    "\n",
    "from fetching_from_local_db.enums import AssetClass, Index, StrikeSpread\n",
    "from fetching_from_local_db.fetch_from_db import (\n",
    "    _fetch_batch,\n",
    "    fetch_data,\n",
    "    fetch_spot_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f7152f-eed9-4ecc-81f9-e42c40063e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:28:37.887794Z",
     "iopub.status.busy": "2024-12-12T04:28:37.887041Z",
     "iopub.status.idle": "2024-12-12T04:28:37.902212Z",
     "shell.execute_reply": "2024-12-12T04:28:37.901211Z",
     "shell.execute_reply.started": "2024-12-12T04:28:37.887774Z"
    }
   },
   "outputs": [],
   "source": [
    "async def get_expiry(f_today):\n",
    "\n",
    "    if (f_today <= dt.date(2024, 1, 25)) and (f_today >= dt.date(2024, 1, 18)):\n",
    "        f_expiry = dt.date(2024, 1, 25)\n",
    "    elif (f_today <= dt.date(2024, 1, 31)) and (f_today >= dt.date(2024, 1, 26)):\n",
    "        f_expiry = dt.date(2024, 1, 31)\n",
    "    elif (f_today <= dt.date(2024, 2, 22)) and (f_today >= dt.date(2024, 2, 29)):\n",
    "        f_expiry = dt.date(2024, 2, 29)\n",
    "    elif (f_today <= dt.date(2024, 3, 25)) and (f_today >= dt.date(2024, 3, 27)):\n",
    "        f_expiry = dt.date(2024, 2, 27)\n",
    "    elif f_today < dt.date(2023, 9, 1):\n",
    "        days_to_thursday = (3 - f_today.weekday()) % 7\n",
    "        nearest_thursday = f_today + dt.timedelta(days=days_to_thursday)\n",
    "        f_expiry = nearest_thursday\n",
    "        if nse.valid_days(start_date=nearest_thursday, end_date=nearest_thursday).empty:\n",
    "            f_expiry = nearest_thursday - dt.timedelta(days=1)\n",
    "    elif f_today >= dt.date(2023, 9, 1):\n",
    "        if f_today.day < 24:\n",
    "            days_to_wednesday = (2 - f_today.weekday()) % 7\n",
    "            nearest_wednesday = f_today + dt.timedelta(days=days_to_wednesday)\n",
    "            f_expiry = nearest_wednesday\n",
    "            if nse.valid_days(\n",
    "                start_date=nearest_wednesday, end_date=nearest_wednesday\n",
    "            ).empty:\n",
    "                f_expiry = nearest_wednesday - dt.timedelta(days=1)\n",
    "        else:\n",
    "            days_to_thursday = (3 - f_today.weekday()) % 7\n",
    "            nearest_thursday = f_today + dt.timedelta(days=days_to_thursday)\n",
    "            f_expiry = nearest_thursday\n",
    "            if nse.valid_days(\n",
    "                start_date=nearest_thursday, end_date=nearest_thursday\n",
    "            ).empty:\n",
    "                f_expiry = nearest_thursday - dt.timedelta(days=1)\n",
    "    return f_expiry\n",
    "\n",
    "\n",
    "async def get_expiry_finnifty(f_today):\n",
    "\n",
    "    days_to_thursday = (1 - f_today.weekday()) % 7\n",
    "    nearest_thursday = f_today + dt.timedelta(days=days_to_thursday)\n",
    "    f_expiry = nearest_thursday\n",
    "    if nse.valid_days(start_date=nearest_thursday, end_date=nearest_thursday).empty:\n",
    "        f_expiry = nearest_thursday - dt.timedelta(days=1)\n",
    "    return f_expiry\n",
    "\n",
    "async def get_expiry_nifty(f_today):\n",
    "\n",
    "    days_to_thursday = (3 - f_today.weekday()) % 7\n",
    "    nearest_thursday = f_today + dt.timedelta(days=days_to_thursday)\n",
    "    f_expiry = nearest_thursday\n",
    "    if nse.valid_days(start_date=nearest_thursday, end_date=nearest_thursday).empty:\n",
    "        f_expiry = nearest_thursday - dt.timedelta(days=1)\n",
    "    return f_expiry\n",
    "\n",
    "async def get_expiry_midcpnifty(f_today):\n",
    "\n",
    "    days_to_thursday = (0 - f_today.weekday()) % 7\n",
    "    nearest_thursday = f_today + dt.timedelta(days=days_to_thursday)\n",
    "    f_expiry = nearest_thursday\n",
    "    if nse.valid_days(start_date=nearest_thursday, end_date=nearest_thursday).empty:\n",
    "        f_expiry = nearest_thursday - dt.timedelta(days=1)\n",
    "    return f_expiry\n",
    "\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "async def get_monthly_expiry_nifty(input_date):\n",
    "    # Get the last day of the current month\n",
    "    current_month_last_day = (input_date.replace(day=28) + dt.timedelta(days=4)).replace(day=1) - dt.timedelta(days=1)\n",
    "    \n",
    "    # Find the last Thursday of the current month\n",
    "    last_thursday_current_month = current_month_last_day - dt.timedelta(days=(current_month_last_day.weekday() - 3) % 7)\n",
    "    \n",
    "    # Check if the current date is less than the last Thursday of the current month\n",
    "    if input_date < last_thursday_current_month:\n",
    "        last_thursday = last_thursday_current_month\n",
    "    else:\n",
    "        # If the current date has passed the last Thursday, find the last Thursday of the next month\n",
    "        next_month = (input_date.month % 12) + 1\n",
    "        next_month_year = input_date.year if next_month > 1 else input_date.year + 1\n",
    "\n",
    "        # Get the last day of the next month (considering February correctly)\n",
    "        if next_month == 2:  # February\n",
    "            if next_month_year % 4 == 0 and (next_month_year % 100 != 0 or next_month_year % 400 == 0):\n",
    "                last_day_of_next_month = 29  # Leap year\n",
    "            else:\n",
    "                last_day_of_next_month = 28  # Non-leap year\n",
    "        else:\n",
    "            # Calculate the last day of the next month\n",
    "            last_day_of_next_month = (dt.date(next_month_year, next_month, 1) + dt.timedelta(days=31)).replace(day=1) - dt.timedelta(days=1)\n",
    "            last_day_of_next_month = last_day_of_next_month.day  # Extract the day as an integer\n",
    "\n",
    "        # Create a date for the last day of the next month\n",
    "        last_day_of_next_month_date = dt.date(next_month_year, next_month, last_day_of_next_month)\n",
    "\n",
    "        # Find the last Thursday of the next month\n",
    "        last_thursday = last_day_of_next_month_date - dt.timedelta(days=(last_day_of_next_month_date.weekday() - 3) % 7)\n",
    "\n",
    "    # Validate if the last Thursday is a trading day\n",
    "    if nse.valid_days(start_date=last_thursday, end_date=last_thursday).empty:\n",
    "        # If it's a holiday, find the previous valid trading day\n",
    "        last_thursday -= dt.timedelta(days=1)\n",
    "        while nse.valid_days(start_date=last_thursday, end_date=last_thursday).empty:\n",
    "            last_thursday -= dt.timedelta(days=1)\n",
    "\n",
    "    return last_thursday\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def get_option_contract_name(symbol, strike, expiry, opt_type):\n",
    "    temp = \"0\"\n",
    "    mth = expiry.month\n",
    "\n",
    "    if (expiry + dt.timedelta(days=7)).month != expiry.month:\n",
    "        date_string = expiry.strftime(\"%y%b\").upper()\n",
    "        return f\"{symbol}{date_string}{strike}{opt_type}\"\n",
    "    else:\n",
    "        if expiry.day <= 9:\n",
    "            date_string = f\"{expiry.year - 2000}{mth}{temp}{expiry.day}\"\n",
    "        else:\n",
    "            date_string = f\"{expiry.year - 2000}{mth}{expiry.day}\"\n",
    "        return f\"{symbol}{date_string}{strike}{opt_type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b874682a-d055-4f77-b7d0-ae3310288852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:28:38.043447Z",
     "iopub.status.busy": "2024-12-12T04:28:38.042584Z",
     "iopub.status.idle": "2024-12-12T04:28:38.465487Z",
     "shell.execute_reply": "2024-12-12T04:28:38.464071Z",
     "shell.execute_reply.started": "2024-12-12T04:28:38.043423Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/bnf.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# bnf_pandas = pd.read_csv(\"../data/bnf_min.csv\")\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m bnf_pandas \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../data/bnf.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# bnf_pandas = pd.read_csv(\"../data/fin_min.csv\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# bnf_pandas = pd.read_csv(\"../data/midcp_min.csv\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# bnf_pandas = pd.read_csv(\"../data/sensex_min.csv\")\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# bnf_pandas = pd.read_csv(\"../data/bankex_min.csv\")\u001b[39;00m\n",
      "File \u001b[0;32m~/strategies/droplets/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/strategies/droplets/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/strategies/droplets/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/strategies/droplets/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/strategies/droplets/.venv/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/bnf.csv'"
     ]
    }
   ],
   "source": [
    "# bnf_pandas = pd.read_csv(\"../data/bnf_min.csv\")\n",
    "bnf_pandas = pd.read_csv(\"../../data/bnf.csv\")\n",
    "# bnf_pandas = pd.read_csv(\"../data/fin_min.csv\")\n",
    "# bnf_pandas = pd.read_csv(\"../data/midcp_min.csv\")\n",
    "# bnf_pandas = pd.read_csv(\"../data/sensex_min.csv\")\n",
    "# bnf_pandas = pd.read_csv(\"../data/bankex_min.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f313ce-ca7b-4c8e-b968-00426800160d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-12T04:28:38.466090Z",
     "iopub.status.idle": "2024-12-12T04:28:38.466459Z",
     "shell.execute_reply": "2024-12-12T04:28:38.466361Z",
     "shell.execute_reply.started": "2024-12-12T04:28:38.466335Z"
    }
   },
   "outputs": [],
   "source": [
    "# If Stocks Data ...\n",
    "bnf_pandas[\"datetime\"] = pd.to_datetime(bnf_pandas[\"datetime\"])\n",
    "bnf_pandas[\"datetime\"] = bnf_pandas[\"datetime\"].dt.tz_localize(None)\n",
    "bnf_pandas = bnf_pandas[bnf_pandas[\"datetime\"].dt.year >= 2017]\n",
    "# bnf_pandas.drop(columns=[\"time\"], inplace=True)\n",
    "# bnf_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d2675-5899-4ce8-b026-6b939a14e28b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-12T04:28:38.467766Z",
     "iopub.status.idle": "2024-12-12T04:28:38.468002Z",
     "shell.execute_reply": "2024-12-12T04:28:38.467913Z",
     "shell.execute_reply.started": "2024-12-12T04:28:38.467902Z"
    }
   },
   "outputs": [],
   "source": [
    "bnf = pl.DataFrame(bnf_pandas)\n",
    "print(type(bnf))\n",
    "# bnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518a81b7-8609-4070-a747-2e0368a79391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:28:38.509146Z",
     "iopub.status.busy": "2024-12-12T04:28:38.508802Z",
     "iopub.status.idle": "2024-12-12T04:28:38.537519Z",
     "shell.execute_reply": "2024-12-12T04:28:38.528707Z",
     "shell.execute_reply.started": "2024-12-12T04:28:38.509127Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bnf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bnf \u001b[38;5;241m=\u001b[39m \u001b[43mbnf\u001b[49m\u001b[38;5;241m.\u001b[39mwith_columns([pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bnf' is not defined"
     ]
    }
   ],
   "source": [
    "bnf = bnf.with_columns([pl.col(\"datetime\").alias(\"index\")]).drop(\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c42e332-535b-45e3-a6f1-cff6182bb317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:28:38.593853Z",
     "iopub.status.busy": "2024-12-12T04:28:38.593338Z",
     "iopub.status.idle": "2024-12-12T04:28:38.615633Z",
     "shell.execute_reply": "2024-12-12T04:28:38.613954Z",
     "shell.execute_reply.started": "2024-12-12T04:28:38.593833Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bnf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bnf \u001b[38;5;241m=\u001b[39m \u001b[43mbnf\u001b[49m\u001b[38;5;241m.\u001b[39mwith_columns(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bnf' is not defined"
     ]
    }
   ],
   "source": [
    "bnf = bnf.with_columns(pl.col(\"index\").alias(\"datetime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c817c6cb-d64d-4294-ac37-026782a16d54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:28:38.774400Z",
     "iopub.status.busy": "2024-12-12T04:28:38.773805Z",
     "iopub.status.idle": "2024-12-12T04:28:38.790610Z",
     "shell.execute_reply": "2024-12-12T04:28:38.789348Z",
     "shell.execute_reply.started": "2024-12-12T04:28:38.774365Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bnf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bnf \u001b[38;5;241m=\u001b[39m \u001b[43mbnf\u001b[49m\u001b[38;5;241m.\u001b[39mrename({\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bnf' is not defined"
     ]
    }
   ],
   "source": [
    "bnf = bnf.rename({\n",
    "    'open': 'o',\n",
    "    'high': 'h',\n",
    "    'low': 'l',\n",
    "    'close': 'c',\n",
    "    'volume': 'v'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8146b55a-f7c1-4745-b115-bb9b0d03a11e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:28:38.837730Z",
     "iopub.status.busy": "2024-12-12T04:28:38.837298Z",
     "iopub.status.idle": "2024-12-12T04:28:38.843372Z",
     "shell.execute_reply": "2024-12-12T04:28:38.842144Z",
     "shell.execute_reply.started": "2024-12-12T04:28:38.837711Z"
    }
   },
   "outputs": [],
   "source": [
    "def resample(\n",
    "    data: pl.DataFrame, timeframe, offset: dt.timedelta | None = None\n",
    ") -> pl.DataFrame:\n",
    "    return (\n",
    "        data.set_sorted(\"datetime\")\n",
    "        .group_by_dynamic(\n",
    "            index_column=\"datetime\",\n",
    "            every=timeframe,\n",
    "            period=timeframe,\n",
    "            label=\"left\",\n",
    "            offset=offset,\n",
    "        )\n",
    "        .agg(\n",
    "            [\n",
    "                pl.col(\"o\").first().alias(\"o\"),\n",
    "                pl.col(\"h\").max().alias(\"h\"),\n",
    "                pl.col(\"l\").min().alias(\"l\"),\n",
    "                pl.col(\"c\").last().alias(\"c\"),\n",
    "                pl.col(\"v\").sum().alias(\"v\"),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# ohlc_resampled = resample(bnf, '5m', pd.Timedelta(minutes=0))\n",
    "\n",
    "# bnf_1hr = ohlc_resampled\n",
    "# bnf_final = bnf_1hr.to_pandas()\n",
    "# bnf_final['datetime'] = pd.to_datetime(bnf_final['datetime'])\n",
    "# bnf_final\n",
    "# bnf_1hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e97fb97-991b-4a62-bf86-7fa41108c15a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T16:06:47.957399Z",
     "iopub.status.busy": "2024-12-08T16:06:47.956770Z",
     "iopub.status.idle": "2024-12-08T16:06:47.962483Z",
     "shell.execute_reply": "2024-12-08T16:06:47.961582Z",
     "shell.execute_reply.started": "2024-12-08T16:06:47.957381Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_signals(df, signal_ma, candles_in_num):\n",
    "    df[\"c\"] = pd.to_numeric(df[\"c\"], errors=\"coerce\")\n",
    "    df[\"Signal MA\"] = df[\"c\"].rolling(window=signal_ma).mean()\n",
    "    # df[\"Trailing MA\"] = df[\"c\"].rolling(window=trailing_ma).mean()\n",
    "\n",
    "    df[\"Sell Signal\"] = 0\n",
    "\n",
    "    # Generate signals using boolean masking\n",
    "    sell_signal_mask = df[\"Signal MA\"] <= df[\"Signal MA\"].shift(1)\n",
    "\n",
    "    for i in range(1, candles_in_num):\n",
    "        sell_signal_mask &= df[\"Signal MA\"].shift(i) <= df[\"Signal MA\"].shift(i + 1)\n",
    "\n",
    "    df.loc[sell_signal_mask, \"Sell Signal\"] = 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fab286d2-22e5-4059-a502-772c10566d2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T16:06:48.576570Z",
     "iopub.status.busy": "2024-12-08T16:06:48.575662Z",
     "iopub.status.idle": "2024-12-08T16:06:48.739240Z",
     "shell.execute_reply": "2024-12-08T16:06:48.737817Z",
     "shell.execute_reply.started": "2024-12-08T16:06:48.576553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687621   2024-06-07 15:25:00\n",
      "687622   2024-06-07 15:26:00\n",
      "687623   2024-06-07 15:27:00\n",
      "687624   2024-06-07 15:28:00\n",
      "687625   2024-06-07 15:29:00\n",
      "Name: datetime, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "data = bnf_pandas.copy()\n",
    "# data['datetime'] = pd.to_datetime(data['datetime'].dt.date)\n",
    "print(data[\"datetime\"].tail())\n",
    "trading_days_set = set(data[\"datetime\"].dt.date)\n",
    "# sorted(trading_days_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "404289d5-30ae-4909-acf1-03e090f04ceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T16:07:08.135376Z",
     "iopub.status.busy": "2024-12-08T16:07:08.134863Z",
     "iopub.status.idle": "2024-12-08T16:07:08.140352Z",
     "shell.execute_reply": "2024-12-08T16:07:08.139190Z",
     "shell.execute_reply.started": "2024-12-08T16:07:08.135359Z"
    }
   },
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "INSTRUMENT = \"BANKNIFTY\"\n",
    "INDEX = \"bnf\"\n",
    "# INDEX_MROUND=500\n",
    "INDEX_MROUND=100\n",
    "\n",
    "# INSTRUMENT = \"NIFTY\"\n",
    "# INDEX = \"nifty\"\n",
    "# INDEX_MROUND=50\n",
    "\n",
    "PORTFOLIO_VALUE = 10_00_000\n",
    "INDEX_LEV = 6\n",
    "RPT_CE=0.01\n",
    "RPT_PE=0.01\n",
    "SLIPPAGE=0.01\n",
    "TF='5m'\n",
    "\n",
    "# SIGNAL_MA = 20\n",
    "# NUM_OF_CANDELS = 1\n",
    "# T_MA=20\n",
    "# TARGET=100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a07d3a9-6ded-45fd-9659-1a882dd95c5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T16:07:08.895646Z",
     "iopub.status.busy": "2024-12-08T16:07:08.895409Z",
     "iopub.status.idle": "2024-12-08T16:07:08.979982Z",
     "shell.execute_reply": "2024-12-08T16:07:08.978450Z",
     "shell.execute_reply.started": "2024-12-08T16:07:08.895630Z"
    }
   },
   "outputs": [],
   "source": [
    "bnf=resample(bnf, TF)\n",
    "data=bnf.to_pandas()\n",
    "\n",
    "# data[['MA','signal_spot']]=MA(data,200)\n",
    "# data[data['signal_spot']==1].head(50)\n",
    "# bnf\n",
    "# data.tail(50)\n",
    "# data[data['datetime'].dt.date == dt.date(2024, 4, 29)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6753a51e-8622-4828-99d2-82799b45352b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T16:07:09.406311Z",
     "iopub.status.busy": "2024-12-08T16:07:09.405989Z",
     "iopub.status.idle": "2024-12-08T16:07:09.440374Z",
     "shell.execute_reply": "2024-12-08T16:07:09.439228Z",
     "shell.execute_reply.started": "2024-12-08T16:07:09.406293Z"
    }
   },
   "outputs": [],
   "source": [
    "async def ce_trade(data,SIGNAL_MA,NUM_CANDELS):\n",
    "    df=data.copy()\n",
    "\n",
    "    start_date = dt.date(2019, 1, 2)\n",
    "    end_date = dt.date(2024, 6, 30)\n",
    "\n",
    "    current_date = start_date\n",
    "\n",
    "    combined_trades = pd.DataFrame()\n",
    "    total_trades = pd.DataFrame()\n",
    "    time_of_day = dt.time(9, 15)\n",
    "    trade_book = []\n",
    "    ce_lowest_low = float('inf')\n",
    "    ce_highest_high = float('-inf')\n",
    "    \n",
    "\n",
    "    while current_date < end_date:\n",
    "        \n",
    "        entry=0\n",
    "        initial_sl=0\n",
    "        exit=0\n",
    "        in_ce_trade=False\n",
    "        in_pe_trade=False\n",
    "        # signal_exist=False\n",
    "        \n",
    "        points_captured=0\n",
    "        remark = \"\"\n",
    "        trailing_active=False\n",
    "        tsl=0\n",
    "        stop_trading=False\n",
    "        is_gap_ce_sl = False\n",
    "        previous_ce_sl_hit=False\n",
    "        current_date_increament_flag= False\n",
    "     \n",
    "        \n",
    "         \n",
    "        starting_time = dt.time(9, 15)\n",
    "        \n",
    "        ending_time = dt.time(15, 25)\n",
    "        \n",
    "        if not in_ce_trade and current_date in  trading_days_set:\n",
    "            \n",
    "            ce_search_datetime = dt.datetime.combine(current_date, time_of_day)\n",
    "            # print(f'current date : {ce_search_datetime}')\n",
    "    \n",
    "            spot_open = df.loc[df[\"datetime\"] >= ce_search_datetime, \"o\"].iloc[0]\n",
    "            # print(f'spot open : {spot_open}')\n",
    "            # spot_atm = int(round(spot_open / INDEX_MROUND) * INDEX_MROUND)\n",
    "            spot_atm = int(math.ceil(spot_open / INDEX_MROUND) * INDEX_MROUND)  ##ROUNDS TO NEAREST 500 OTM\n",
    "            # print(f'spot atm : {spot_atm}')\n",
    "            # nearest_expiry = await get_expiry(current_date)\n",
    "            nearest_expiry = await get_expiry_nifty(current_date)\n",
    "            # if current_date== nearest_expiry:\n",
    "            #     next_expiry_passing_value = current_date + dt.timedelta(days=1)\n",
    "            #     nearest_expiry = await get_expiry_nifty( next_expiry_passing_value)\n",
    "            # print(f'passing date for expry : {current_date}')\n",
    "            # nearest_expiry = await get_monthly_expiry_nifty(current_date)\n",
    "            # print(f'nearest expiry{nearest_expiry}')\n",
    "            selected_strike_ce=spot_atm\n",
    "            # print(f'selected strike : {selected_strike_ce}')\n",
    "            ce_df =  await fetch_data(\n",
    "                            index=INDEX,\n",
    "                            start_date=nearest_expiry-dt.timedelta(days=6),\n",
    "                            start_time=starting_time,\n",
    "                            end_date=nearest_expiry,\n",
    "                            end_time=ending_time,\n",
    "                            strike=selected_strike_ce,\n",
    "                            asset_class=\"C\",\n",
    "                            expiry=nearest_expiry,\n",
    "                        )\n",
    "            if ce_df is not None and not isinstance(ce_df, str):\n",
    "                # print('new data fetched')\n",
    "                data_ce=True\n",
    "                ce_df = ce_df.select([\"datetime\", \"o\", \"h\", \"l\", \"c\",\"v\"])\n",
    "                ce_df = resample(ce_df, TF)\n",
    "                ce_df_pandas = ce_df.to_pandas()\n",
    "                ce_df =  generate_signals(ce_df_pandas,SIGNAL_MA,NUM_CANDELS)\n",
    "                # print(ce_df)\n",
    "            else:\n",
    "                data_ce=False\n",
    "                current_date += dt.timedelta(days=1)\n",
    "                continue\n",
    "                \n",
    "           \n",
    "        \n",
    "            if data_ce:\n",
    "                \n",
    "                for i in range (0,len(ce_df)):\n",
    "                    current_candle_open = ce_df.iloc[i]['o']\n",
    "                    current_candle_high = ce_df.iloc[i]['h']\n",
    "                    current_candle_low = ce_df.iloc[i]['l']\n",
    "                    current_candle_close = ce_df.iloc[i]['c']\n",
    "\n",
    "                    previous_candle_low = ce_df.iloc[i-1]['l']\n",
    "                    \n",
    "                    expiry = nearest_expiry\n",
    "                    strike = selected_strike_ce\n",
    "                    asset_class = 'C'\n",
    "                    # print(ce_df.iloc[i])\n",
    "    \n",
    "                    signal = ce_df.iloc[i-1]['Sell Signal'] \n",
    "\n",
    "                    if ce_df.iloc[i]['datetime']>=ce_search_datetime:\n",
    "                        \n",
    "                        if  not previous_ce_sl_hit and not in_ce_trade  and  signal and current_candle_low < previous_candle_low and ce_df.iloc[i]['datetime'].time() > time_of_day and ((nearest_expiry-ce_df.iloc[i]['datetime'].date()).days > 0 and (nearest_expiry-ce_df.iloc[i]['datetime'].date()).days < 8) and  ce_df.iloc[i]['datetime'].time() < dt.time(15,20) :\n",
    "                            # print(ce_df.iloc[i])\n",
    "                            # print(f'entry found {current_candle_close}')\n",
    "                            # print(f'entry datetime {ce_df.iloc[i][\"datetime\"]}')\n",
    "                            entry = previous_candle_low\n",
    "                            entry_date = ce_df.iloc[i]['datetime'].date()\n",
    "                            entry_time = ce_df.iloc[i]['datetime'].time()\n",
    "                            initial_sl = ce_df.iloc[i-SIGNAL_MA:i]['h'].max()\n",
    "                            in_ce_trade = True\n",
    "                            ce_lowest_low = float('inf')\n",
    "                            ce_highest_high = float('-inf')\n",
    "                            \n",
    "                            qty=RPT_CE*PORTFOLIO_VALUE/(initial_sl-entry)\n",
    "                            if ((qty*strike)/(INDEX_LEV*PORTFOLIO_VALUE))*100 > 200:\n",
    "                                qty = PORTFOLIO_VALUE*INDEX_LEV/strike*2\n",
    "\n",
    "                            \n",
    "                        # While in trade, track the highest high and lowest low\n",
    "                        if in_ce_trade:\n",
    "                            # Track the highest high\n",
    "                            ce_highest_high = max(ce_highest_high, current_candle_high)\n",
    "                            \n",
    "                            # Track the lowest low\n",
    "                            ce_lowest_low = min(ce_lowest_low, current_candle_low)\n",
    "\n",
    "        \n",
    "                        if in_ce_trade and ce_df.iloc[i]['datetime'].time()==dt.time(9,15) and current_candle_open > initial_sl :\n",
    "                        \n",
    "                            # print(ce_df.iloc[i])\n",
    "                            # print(f'GAP sl hit {initial_sl}')\n",
    "                            # print(f'GAP sl datetime {ce_df.iloc[i][\"datetime\"]}')\n",
    "                            exit=current_candle_close\n",
    "                            in_ce_trade=False\n",
    "                            stop_trading=False\n",
    "                            previous_ce_sl_hit=True\n",
    "                            is_gap_ce_sl = False\n",
    "                            points_captured=entry-exit\n",
    "                            exit_time = ce_df.iloc[i]['datetime'].time()\n",
    "                            slippage= SLIPPAGE * (entry+exit)\n",
    "                            pnl=(qty*(points_captured-slippage))\n",
    "                            remark = \"Gap SL hit\"\n",
    "                            weekday_int = entry_date.weekday()\n",
    "                            weekday_name = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"][weekday_int]\n",
    "                            trade = {\n",
    "                                    'date' : entry_date,\n",
    "                                    'day' : weekday_name,\n",
    "                                    'expiry' : expiry,\n",
    "                                    'DTE' : (nearest_expiry-entry_date).days,\n",
    "                                    # 'atm' : atm,\n",
    "                                    # 'scrip' : index ,\n",
    "                                    'strike' : strike,\n",
    "                                    'type' : asset_class,\n",
    "                                    'Entry Price': entry,\n",
    "                                    'Entry Time': entry_time,\n",
    "                                    'initial sl' : initial_sl,\n",
    "                                    'TSL' : tsl,\n",
    "                                    # 'OTM Entry' : otm_entry,\n",
    "                                    'Exit Price': exit,\n",
    "                                    'Exit date' : ce_df.iloc[i]['datetime'].date(),\n",
    "                                    'Exit Time': exit_time,\n",
    "                                    # 'OTM EXIT ' : otm_exit,\n",
    "                                    'Remark' : remark, \n",
    "                                    'Points Captured': points_captured,\n",
    "                                    'Slippage': slippage,\n",
    "                                    # 'OTM cost' : otm_exit-otm_entry,\n",
    "                                    'Qty': qty,\n",
    "                                    'PnL' : pnl,\n",
    "                                    'ROI%': (pnl/ PORTFOLIO_VALUE) * 100,\n",
    "                                    'Trade Year': ce_df.iloc[i]['datetime'].year,\n",
    "                                    'Trade Month': ce_df.iloc[i]['datetime'].month,\n",
    "                                    'Highest High': ce_highest_high,  # Add highest high to trade data\n",
    "                                    'Lowest Low': ce_lowest_low ,      # Add lowest low to trade data\n",
    "                                    'Max ROI%' : ((qty*(entry-ce_lowest_low))/PORTFOLIO_VALUE)*100,\n",
    "                                    'Margin' : ((qty*strike)/(INDEX_LEV*PORTFOLIO_VALUE))*100\n",
    "                                      }\n",
    "                            # print('apending initial sl trade')\n",
    "                            trade_book.append(trade)\n",
    "                            points_captured=0\n",
    "                            current_date = ce_df.iloc[i]['datetime'].date()\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = ce_df.iloc[i]['datetime'].time()\n",
    "                            # print(f'current date changed to : {current_date} and time to {time_of_day}')\n",
    "                            break\n",
    "        \n",
    "                        if in_ce_trade and current_candle_high > initial_sl:\n",
    "                            # print(ce_df.iloc[i])\n",
    "                            # print(f'initial sl hit {initial_sl}')\n",
    "                            # print(f'initial sl datetime {ce_df.iloc[i][\"datetime\"]}')\n",
    "                            exit=initial_sl\n",
    "                            otm_datetime = ce_df.iloc[i]['datetime']\n",
    "                            in_ce_trade=False\n",
    "                            stop_trading=False\n",
    "                            previous_ce_sl_hit=True\n",
    "                            is_gap_ce_sl = False\n",
    "                            points_captured=entry-exit\n",
    "                            exit_time = ce_df.iloc[i]['datetime'].time()\n",
    "                            slippage= SLIPPAGE * (entry+exit)\n",
    "                            pnl=(qty*(points_captured-slippage))\n",
    "                            # pnl=(qty*(points_captured-slippage))-qty*(otm_exit-otm_entry)\n",
    "                            remark = \"SL hit\"\n",
    "                            weekday_int = entry_date.weekday()\n",
    "                            weekday_name = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"][weekday_int]\n",
    "                            trade = {\n",
    "                                    'date' : entry_date,\n",
    "                                    'day' : weekday_name,\n",
    "                                    'expiry' : expiry,\n",
    "                                    'DTE' : (nearest_expiry-entry_date).days,\n",
    "                                    # 'atm' : atm,\n",
    "                                    # 'scrip' : index ,\n",
    "                                    'strike' : strike,\n",
    "                                    'type' : asset_class,\n",
    "                                    'Entry Price': entry,\n",
    "                                    'Entry Time': entry_time,\n",
    "                                    'initial sl' : initial_sl,\n",
    "                                    'TSL' : tsl,\n",
    "                                    # 'OTM Entry' : otm_entry,\n",
    "                                    'Exit Price': exit,\n",
    "                                    'Exit date' : ce_df.iloc[i]['datetime'].date(),\n",
    "                                    'Exit Time': exit_time,\n",
    "                                    # 'OTM EXIT ' : otm_exit,\n",
    "                                    'Remark' : remark, \n",
    "                                    'Points Captured': points_captured,\n",
    "                                    'Slippage': slippage,\n",
    "                                    # 'OTM cost' : otm_exit-otm_entry,\n",
    "                                    'Qty': qty,\n",
    "                                    'PnL' : pnl,\n",
    "                                    'ROI%': (pnl/ PORTFOLIO_VALUE) * 100,\n",
    "                                    'Trade Year': ce_df.iloc[i]['datetime'].year,\n",
    "                                    'Trade Month': ce_df.iloc[i]['datetime'].month,\n",
    "                                    'Highest High': ce_highest_high,  # Add highest high to trade data\n",
    "                                    'Lowest Low': ce_lowest_low ,      # Add lowest low to trade data\n",
    "                                    'Max ROI%' : ((qty*(entry-ce_lowest_low))/PORTFOLIO_VALUE)*100,\n",
    "                                    'Margin' : ((qty*strike)/(INDEX_LEV*PORTFOLIO_VALUE))*100\n",
    "                                      }\n",
    "                            # print('apending initial sl trade')\n",
    "                            trade_book.append(trade)\n",
    "                            points_captured=0\n",
    "                            current_date = ce_df.iloc[i]['datetime'].date()\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = ce_df.iloc[i]['datetime'].time()\n",
    "                            # print(f'current date changed to : {current_date} and time to {time_of_day}')\n",
    "                            break\n",
    "\n",
    "                        if in_ce_trade and ce_df.iloc[i]['datetime'].date() == nearest_expiry and i == ce_df.index[-1]:\n",
    "                            # print(ce_df.iloc[i])\n",
    "                            # print(f'EOD exit {current_candle_close}')\n",
    "                            # print(f'EOD datetime {ce_df.iloc[i][\"datetime\"]}')\n",
    "                            exit=  current_candle_close\n",
    "                            otm_datetime = ce_df.iloc[i]['datetime']\n",
    "                            in_ce_trade = False\n",
    "                            previous_ce_sl_hit=True\n",
    "                            is_gap_ce_sl = False\n",
    "                            points_captured=entry-exit\n",
    "                            exit_time = ce_df.iloc[i]['datetime'].time()\n",
    "                            slippage= SLIPPAGE * (entry+exit)\n",
    "                            pnl=(qty*(points_captured-slippage))\n",
    "                            # pnl=(qty*(points_captured-slippage))-qty*(otm_exit-otm_entry)\n",
    "                            remark = \"EOD exit\"\n",
    "                            weekday_int = entry_date.weekday()\n",
    "                            weekday_name = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"][weekday_int]\n",
    "                            trade = {\n",
    "                                    'date' : entry_date,\n",
    "                                    'day' : weekday_name,\n",
    "                                    'expiry' : expiry,\n",
    "                                    'DTE' : (nearest_expiry-entry_date).days,\n",
    "                                    # 'atm' : atm,\n",
    "                                    # 'scrip' : index ,\n",
    "                                    'strike' : strike,\n",
    "                                    'type' : asset_class,\n",
    "                                    'Entry Price': entry,\n",
    "                                    'Entry Time': entry_time,\n",
    "                                    'initial sl' : initial_sl,\n",
    "                                    'TSL' : tsl,\n",
    "                                    # 'OTM Entry' : otm_entry,\n",
    "                                    'Exit Price': exit,\n",
    "                                    'Exit date' : ce_df.iloc[i]['datetime'].date(),\n",
    "                                    'Exit Time': exit_time,\n",
    "                                    # 'OTM EXIT ' : otm_exit,\n",
    "                                    'Remark' : remark, \n",
    "                                    'Points Captured': points_captured,\n",
    "                                    'Slippage': slippage,\n",
    "                                    # 'OTM cost' : otm_exit-otm_entry,\n",
    "                                    'Qty': qty,\n",
    "                                    'PnL' : pnl,\n",
    "                                    'ROI%': (pnl/ PORTFOLIO_VALUE) * 100,\n",
    "                                    'Trade Year': ce_df.iloc[i]['datetime'].year,\n",
    "                                    'Trade Month': ce_df.iloc[i]['datetime'].month,\n",
    "                                    'Highest High': ce_highest_high,  # Add highest high to trade data\n",
    "                                    'Lowest Low': ce_lowest_low,      # Add lowest low to trade data\n",
    "                                    'Max ROI%' : ((qty*(entry-ce_lowest_low))/PORTFOLIO_VALUE)*100,\n",
    "                                    'Margin' : ((qty*strike)/(INDEX_LEV*PORTFOLIO_VALUE))*100\n",
    "                                      }\n",
    "                            # print('apending EOD trade')\n",
    "                            trade_book.append(trade)\n",
    "                            points_captured=0\n",
    "                            current_date = nearest_expiry + dt.timedelta(days=1)\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = dt.time(9, 15)\n",
    "                            # print(f'current date increased by 1 on expiry : {current_date}')\n",
    "                            break\n",
    "\n",
    "                        if not in_ce_trade and not previous_ce_sl_hit and  ce_df.iloc[i]['datetime'].time() > dt.time(15,00):\n",
    "                            # print('inside exoiry non trade date increment')\n",
    "                            current_date = current_date + dt.timedelta(days=1)\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = dt.time(9, 15)\n",
    "                            break\n",
    "                        \n",
    "                        \n",
    "        if not current_date_increament_flag:\n",
    "                current_date = current_date + dt.timedelta(days=1)\n",
    "                current_date_increament_flag = False\n",
    "            \n",
    "    trade_book_df = pd.DataFrame(trade_book)\n",
    "  \n",
    "            \n",
    "    return(trade_book_df)\n",
    "            \n",
    "\n",
    "             \n",
    "\n",
    "            \n",
    "             \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a32c1045-13cc-4b71-a595-305d39d34856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T16:07:16.024199Z",
     "iopub.status.busy": "2024-12-08T16:07:16.023865Z",
     "iopub.status.idle": "2024-12-08T16:07:16.048453Z",
     "shell.execute_reply": "2024-12-08T16:07:16.047573Z",
     "shell.execute_reply.started": "2024-12-08T16:07:16.024184Z"
    }
   },
   "outputs": [],
   "source": [
    "async def pe_trade(data,SIGNAL_MA,NUM_CANDELS):\n",
    "    df=data.copy()\n",
    "\n",
    "    start_date = dt.date(2017, 1, 2)\n",
    "    end_date = dt.date(2024, 6, 30)\n",
    "\n",
    "    current_date = start_date\n",
    "\n",
    "    combined_trades = pd.DataFrame()\n",
    "    total_trades = pd.DataFrame()\n",
    "    time_of_day = dt.time(9, 15)\n",
    "    trade_book = []\n",
    "    pe_lowest_low = float('inf')\n",
    "    pe_highest_high = float('-inf')\n",
    "    \n",
    "\n",
    "    while current_date < end_date:\n",
    "        \n",
    "        entry=0\n",
    "        initial_sl=0\n",
    "        exit=0\n",
    "        in_pe_trade=False\n",
    "        in_pe_trade=False\n",
    "        # signal_exist=False\n",
    "        \n",
    "        points_captured=0\n",
    "        remark = \"\"\n",
    "        trailing_active=False\n",
    "        tsl=0\n",
    "        stop_trading=False\n",
    "        is_gap_pe_sl = False\n",
    "        previous_pe_sl_hit=False\n",
    "        current_date_increament_flag= False\n",
    "       \n",
    "        \n",
    "         \n",
    "        starting_time = dt.time(9, 15)\n",
    "        \n",
    "        ending_time = dt.time(15, 25)\n",
    "        \n",
    "        if not in_pe_trade and current_date in  trading_days_set:\n",
    "            \n",
    "            pe_search_datetime = dt.datetime.combine(current_date, time_of_day)\n",
    "            # print(f'current date : {pe_search_datetime}')\n",
    "    \n",
    "            spot_open = df.loc[df[\"datetime\"] >= pe_search_datetime, \"o\"].iloc[0]\n",
    "            # print(f'spot open : {spot_open}')\n",
    "            # spot_atm = int(round(spot_open / INDEX_MROUND) * INDEX_MROUND)\n",
    "            spot_atm = int(math.ceil(spot_open / INDEX_MROUND) * INDEX_MROUND)  ##ROUNDS TO NEAREST 500 OTM\n",
    "            # print(f'spot atm : {spot_atm}')\n",
    "            # nearest_expiry = await get_expiry(current_date)\n",
    "            nearest_expiry = await get_expiry_nifty(current_date)\n",
    "            # if current_date== nearest_expiry:\n",
    "            #     next_expiry_passing_value = current_date + dt.timedelta(days=1)\n",
    "            #     nearest_expiry = await get_expiry_nifty( next_expiry_passing_value)\n",
    "            # print(f'passing date for expry : {current_date}')\n",
    "            # nearest_expiry = await get_monthly_expiry_nifty(current_date)\n",
    "            # print(f'nearest expiry{nearest_expiry}')\n",
    "            selected_strike_pe=spot_atm\n",
    "            # print(f'selected strike : {selected_strike_pe}')\n",
    "            pe_df =  await fetch_data(\n",
    "                            index=INDEX,\n",
    "                            start_date=nearest_expiry-dt.timedelta(days=6),\n",
    "                            start_time=starting_time,\n",
    "                            end_date=nearest_expiry,\n",
    "                            end_time=ending_time,\n",
    "                            strike=selected_strike_pe,\n",
    "                            asset_class=\"C\",\n",
    "                            expiry=nearest_expiry,\n",
    "                        )\n",
    "            if pe_df is not None and not isinstance(pe_df, str):\n",
    "                # print('new data fetched')\n",
    "                data_pe=True\n",
    "                pe_df = pe_df.select([\"datetime\", \"o\", \"h\", \"l\", \"c\",\"v\"])\n",
    "                pe_df = resample(pe_df, TF)\n",
    "                pe_df_pandas = pe_df.to_pandas()\n",
    "                pe_df =  generate_signals(pe_df_pandas,SIGNAL_MA,NUM_CANDELS)\n",
    "                # print(ce_df)\n",
    "            else:\n",
    "                data_pe=False\n",
    "                current_date += dt.timedelta(days=1)\n",
    "                continue\n",
    "                \n",
    "           \n",
    "        \n",
    "            if data_pe:\n",
    "                \n",
    "                for i in range (0,len(pe_df)):\n",
    "                    current_candle_open = pe_df.iloc[i]['o']\n",
    "                    current_candle_high = pe_df.iloc[i]['h']\n",
    "                    current_candle_low = pe_df.iloc[i]['l']\n",
    "                    current_candle_close = pe_df.iloc[i]['c']\n",
    "\n",
    "                    previous_candle_low = pe_df.iloc[i-1]['l']\n",
    "                    \n",
    "                    expiry = nearest_expiry\n",
    "                    strike = selected_strike_pe\n",
    "                    asset_class = 'P'\n",
    "                    # print(pe_df.iloc[i])\n",
    "    \n",
    "                    signal =pe_df.iloc[i-1]['Sell Signal'] \n",
    "\n",
    "                    if pe_df.iloc[i]['datetime']>=pe_search_datetime:\n",
    "                        \n",
    "                        if  not previous_pe_sl_hit and not in_pe_trade  and  signal and current_candle_low < previous_candle_low and pe_df.iloc[i]['datetime'].time() > time_of_day and ((nearest_expiry-pe_df.iloc[i]['datetime'].date()).days > 0 and (nearest_expiry-pe_df.iloc[i]['datetime'].date()).days < 8) and  pe_df.iloc[i]['datetime'].time() < dt.time(15,20) :\n",
    "                            # print(pe_df.iloc[i])\n",
    "                            # print(f'entry found {current_candle_close}')\n",
    "                            # print(f'entry datetime {pe_df.iloc[i][\"datetime\"]}')\n",
    "                            entry = previous_candle_low\n",
    "                            entry_date = pe_df.iloc[i]['datetime'].date()\n",
    "                            entry_time = pe_df.iloc[i]['datetime'].time()\n",
    "                            initial_sl = pe_df.iloc[i-SIGNAL_MA:i]['h'].max()\n",
    "                            in_pe_trade = True\n",
    "                            pe_lowest_low = float('inf')\n",
    "                            pe_highest_high = float('-inf')\n",
    "                            \n",
    "                            qty=RPT_PE*PORTFOLIO_VALUE/(initial_sl-entry)\n",
    "                            if ((qty*strike)/(INDEX_LEV*PORTFOLIO_VALUE))*100 > 200:\n",
    "                                qty = PORTFOLIO_VALUE*INDEX_LEV/strike*2\n",
    "\n",
    "                            \n",
    "                        # While in trade, track the highest high and lowest low\n",
    "                        if in_pe_trade:\n",
    "                            # Track the highest high\n",
    "                            pe_highest_high = max(pe_highest_high, current_candle_high)\n",
    "                            \n",
    "                            # Track the lowest low\n",
    "                            pe_lowest_low = min(pe_lowest_low, current_candle_low)\n",
    "\n",
    "        \n",
    "                        if in_pe_trade and pe_df.iloc[i]['datetime'].time()==dt.time(9,15) and current_candle_open > initial_sl :\n",
    "                        \n",
    "                            # print(pe_df.iloc[i])\n",
    "                            # print(f'GAP sl hit {initial_sl}')\n",
    "                            # print(f'GAP sl datetime {pe_df.iloc[i][\"datetime\"]}')\n",
    "                            exit=current_candle_close\n",
    "                            in_pe_trade=False\n",
    "                            stop_trading=False\n",
    "                            previous_pe_sl_hit=True\n",
    "                            is_gap_pe_sl = False\n",
    "                            points_captured=entry-exit\n",
    "                            exit_time = pe_df.iloc[i]['datetime'].time()\n",
    "                            slippage= SLIPPAGE * (entry+exit)\n",
    "                            pnl=(qty*(points_captured-slippage))\n",
    "                            remark = \"Gap SL hit\"\n",
    "                            weekday_int = entry_date.weekday()\n",
    "                            weekday_name = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"][weekday_int]\n",
    "                            trade = {\n",
    "                                    'date' : entry_date,\n",
    "                                    'day' : weekday_name,\n",
    "                                    'expiry' : expiry,\n",
    "                                    'DTE' : (nearest_expiry-entry_date).days,\n",
    "                                    # 'atm' : atm,\n",
    "                                    # 'scrip' : index ,\n",
    "                                    'strike' : strike,\n",
    "                                    'type' : asset_class,\n",
    "                                    'Entry Price': entry,\n",
    "                                    'Entry Time': entry_time,\n",
    "                                    'initial sl' : initial_sl,\n",
    "                                    'TSL' : tsl,\n",
    "                                    # 'OTM Entry' : otm_entry,\n",
    "                                    'Exit Price': exit,\n",
    "                                    'Exit date' : pe_df.iloc[i]['datetime'].date(),\n",
    "                                    'Exit Time': exit_time,\n",
    "                                    # 'OTM EXIT ' : otm_exit,\n",
    "                                    'Remark' : remark, \n",
    "                                    'Points Captured': points_captured,\n",
    "                                    'Slippage': slippage,\n",
    "                                    # 'OTM cost' : otm_exit-otm_entry,\n",
    "                                    'Qty': qty,\n",
    "                                    'PnL' : pnl,\n",
    "                                    'ROI%': (pnl/ PORTFOLIO_VALUE) * 100,\n",
    "                                    'Trade Year': pe_df.iloc[i]['datetime'].year,\n",
    "                                    'Trade Month': pe_df.iloc[i]['datetime'].month,\n",
    "                                    'Highest High': pe_highest_high,  # Add highest high to trade data\n",
    "                                    'Lowest Low': pe_lowest_low ,      # Add lowest low to trade data\n",
    "                                    'Max ROI%' : ((qty*(entry-pe_lowest_low))/PORTFOLIO_VALUE)*100,\n",
    "                                    'Margin' : ((qty*strike)/(INDEX_LEV*PORTFOLIO_VALUE))*100\n",
    "                                      }\n",
    "                            # print('apending initial sl trade')\n",
    "                            trade_book.append(trade)\n",
    "                            points_captured=0\n",
    "                            current_date = pe_df.iloc[i]['datetime'].date()\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = pe_df.iloc[i]['datetime'].time()\n",
    "                            # print(f'current date changed to : {current_date} and time to {time_of_day}')\n",
    "                            break\n",
    "        \n",
    "                        if in_pe_trade and current_candle_high > initial_sl:\n",
    "                            # print(pe_df.iloc[i])\n",
    "                            # print(f'initial sl hit {initial_sl}')\n",
    "                            # print(f'initial sl datetime {pe_df.iloc[i][\"datetime\"]}')\n",
    "                            exit=initial_sl\n",
    "                            otm_datetime = pe_df.iloc[i]['datetime']\n",
    "                            in_pe_trade=False\n",
    "                            stop_trading=False\n",
    "                            previous_pe_sl_hit=True\n",
    "                            is_gap_pe_sl = False\n",
    "                            points_captured=entry-exit\n",
    "                            exit_time = pe_df.iloc[i]['datetime'].time()\n",
    "                            slippage= SLIPPAGE * (entry+exit)\n",
    "                            pnl=(qty*(points_captured-slippage))\n",
    "                            # pnl=(qty*(points_captured-slippage))-qty*(otm_exit-otm_entry)\n",
    "                            remark = \"SL hit\"\n",
    "                            weekday_int = entry_date.weekday()\n",
    "                            weekday_name = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"][weekday_int]\n",
    "                            trade = {\n",
    "                                    'date' : entry_date,\n",
    "                                    'day' : weekday_name,\n",
    "                                    'expiry' : expiry,\n",
    "                                    'DTE' : (nearest_expiry-entry_date).days,\n",
    "                                    # 'atm' : atm,\n",
    "                                    # 'scrip' : index ,\n",
    "                                    'strike' : strike,\n",
    "                                    'type' : asset_class,\n",
    "                                    'Entry Price': entry,\n",
    "                                    'Entry Time': entry_time,\n",
    "                                    'initial sl' : initial_sl,\n",
    "                                    'TSL' : tsl,\n",
    "                                    # 'OTM Entry' : otm_entry,\n",
    "                                    'Exit Price': exit,\n",
    "                                    'Exit date' : pe_df.iloc[i]['datetime'].date(),\n",
    "                                    'Exit Time': exit_time,\n",
    "                                    # 'OTM EXIT ' : otm_exit,\n",
    "                                    'Remark' : remark, \n",
    "                                    'Points Captured': points_captured,\n",
    "                                    'Slippage': slippage,\n",
    "                                    # 'OTM cost' : otm_exit-otm_entry,\n",
    "                                    'Qty': qty,\n",
    "                                    'PnL' : pnl,\n",
    "                                    'ROI%': (pnl/ PORTFOLIO_VALUE) * 100,\n",
    "                                    'Trade Year': pe_df.iloc[i]['datetime'].year,\n",
    "                                    'Trade Month': pe_df.iloc[i]['datetime'].month,\n",
    "                                    'Highest High': pe_highest_high,  # Add highest high to trade data\n",
    "                                    'Lowest Low': pe_lowest_low ,      # Add lowest low to trade data\n",
    "                                    'Max ROI%' : ((qty*(entry-pe_lowest_low))/PORTFOLIO_VALUE)*100,\n",
    "                                    'Margin' : ((qty*strike)/(INDEX_LEV*PORTFOLIO_VALUE))*100\n",
    "                                      }\n",
    "                            # print('apending initial sl trade')\n",
    "                            trade_book.append(trade)\n",
    "                            points_captured=0\n",
    "                            current_date = pe_df.iloc[i]['datetime'].date()\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = pe_df.iloc[i]['datetime'].time()\n",
    "                            # print(f'current date changed to : {current_date} and time to {time_of_day}')\n",
    "                            break\n",
    "\n",
    "                        if in_pe_trade and pe_df.iloc[i]['datetime'].date() == nearest_expiry and i == pe_df.index[-1]:\n",
    "                            # print(pe_df.iloc[i])\n",
    "                            # print(f'EOD exit {current_candle_close}')\n",
    "                            # print(f'EOD datetime {pe_df.iloc[i][\"datetime\"]}')\n",
    "                            exit=  current_candle_close\n",
    "                            otm_datetime = pe_df.iloc[i]['datetime']\n",
    "                            in_pe_trade = False\n",
    "                            previous_pe_sl_hit=True\n",
    "                            is_gap_pe_sl = False\n",
    "                            points_captured=entry-exit\n",
    "                            exit_time = pe_df.iloc[i]['datetime'].time()\n",
    "                            slippage= SLIPPAGE * (entry+exit)\n",
    "                            pnl=(qty*(points_captured-slippage))\n",
    "                            # pnl=(qty*(points_captured-slippage))-qty*(otm_exit-otm_entry)\n",
    "                            remark = \"EOD exit\"\n",
    "                            weekday_int = entry_date.weekday()\n",
    "                            weekday_name = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"][weekday_int]\n",
    "                            trade = {\n",
    "                                    'date' : entry_date,\n",
    "                                    'day' : weekday_name,\n",
    "                                    'expiry' : expiry,\n",
    "                                    'DTE' : (nearest_expiry-entry_date).days,\n",
    "                                    # 'atm' : atm,\n",
    "                                    # 'scrip' : index ,\n",
    "                                    'strike' : strike,\n",
    "                                    'type' : asset_class,\n",
    "                                    'Entry Price': entry,\n",
    "                                    'Entry Time': entry_time,\n",
    "                                    'initial sl' : initial_sl,\n",
    "                                    'TSL' : tsl,\n",
    "                                    # 'OTM Entry' : otm_entry,\n",
    "                                    'Exit Price': exit,\n",
    "                                    'Exit date' : pe_df.iloc[i]['datetime'].date(),\n",
    "                                    'Exit Time': exit_time,\n",
    "                                    # 'OTM EXIT ' : otm_exit,\n",
    "                                    'Remark' : remark, \n",
    "                                    'Points Captured': points_captured,\n",
    "                                    'Slippage': slippage,\n",
    "                                    # 'OTM cost' : otm_exit-otm_entry,\n",
    "                                    'Qty': qty,\n",
    "                                    'PnL' : pnl,\n",
    "                                    'ROI%': (pnl/ PORTFOLIO_VALUE) * 100,\n",
    "                                    'Trade Year': pe_df.iloc[i]['datetime'].year,\n",
    "                                    'Trade Month': pe_df.iloc[i]['datetime'].month,\n",
    "                                    'Highest High': pe_highest_high,  # Add highest high to trade data\n",
    "                                    'Lowest Low': pe_lowest_low,      # Add lowest low to trade data\n",
    "                                    'Max ROI%' : ((qty*(entry-pe_lowest_low))/PORTFOLIO_VALUE)*100,\n",
    "                                    'Margin' : ((qty*strike)/(INDEX_LEV*PORTFOLIO_VALUE))*100\n",
    "                                      }\n",
    "                            # print('apending EOD trade')\n",
    "                            trade_book.append(trade)\n",
    "                            points_captured=0\n",
    "                            current_date = nearest_expiry + dt.timedelta(days=1)\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = dt.time(9, 15)\n",
    "                            # print(f'current date increased by 1 on expiry : {current_date}')\n",
    "                            break\n",
    "\n",
    "                        if not in_pe_trade and not previous_pe_sl_hit and  pe_df.iloc[i]['datetime'].time() > dt.time(15,00):\n",
    "                            # print('inside exoiry non trade date increment')\n",
    "                            current_date = current_date + dt.timedelta(days=1)\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = dt.time(9, 15)\n",
    "                            break\n",
    "                        \n",
    "                        \n",
    "        if not current_date_increament_flag:\n",
    "                current_date = current_date + dt.timedelta(days=1)\n",
    "                current_date_increament_flag = False\n",
    "            \n",
    "    trade_book_df = pd.DataFrame(trade_book)\n",
    "  \n",
    "            \n",
    "    return(trade_book_df)\n",
    "            \n",
    "\n",
    "             \n",
    "\n",
    "            \n",
    "             \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8bb6721-48c0-451f-a1e3-2b421dc5adfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T16:07:17.118909Z",
     "iopub.status.busy": "2024-12-08T16:07:17.118629Z",
     "iopub.status.idle": "2024-12-08T16:07:17.124329Z",
     "shell.execute_reply": "2024-12-08T16:07:17.123399Z",
     "shell.execute_reply.started": "2024-12-08T16:07:17.118890Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "async def execute (DF,SIGNAL_MA,NUM_CANDELS):\n",
    "    data=DF.copy()\n",
    "    tb_ce=await ce_trade(data,SIGNAL_MA,NUM_CANDELS)\n",
    "    tb_pe=await pe_trade(data,SIGNAL_MA,NUM_CANDELS)\n",
    "    tb = pd.concat([tb_ce, tb_pe], ignore_index=True)\n",
    "    tb = tb.sort_values(by='date')\n",
    "    return (tb)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae4e479d-6c48-43f8-9a50-71b402ab253e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T16:07:17.704317Z",
     "iopub.status.busy": "2024-12-08T16:07:17.703789Z",
     "iopub.status.idle": "2024-12-08T16:07:17.712493Z",
     "shell.execute_reply": "2024-12-08T16:07:17.711495Z",
     "shell.execute_reply.started": "2024-12-08T16:07:17.704300Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_stats(tb_expiry, signal_ma,num_candels):\n",
    "    stats_df8 = pd.DataFrame(\n",
    "        index=range(2017, 2025),\n",
    "        columns=[\n",
    "            \"Total ROI\",\n",
    "            \"Total Trades\",\n",
    "            \"Win Rate\",\n",
    "            \"Avg Profit% per Trade\",\n",
    "            \"Avg Loss% per Trade\",\n",
    "            \"Max Drawdown\",\n",
    "            \"ROI/DD Ratio\",\n",
    "            \"Variation\",\n",
    "        ],\n",
    "    )\n",
    "    combined_df_sorted = tb_expiry\n",
    "    # combined_df_sorted = tb_expiry_ce\n",
    "    # combined_df_sorted = tb_expiry_pe\n",
    "    \n",
    "    # Iterate over each year\n",
    "    for year in range(2017, 2025):\n",
    "        # Filter trades for the current year\n",
    "        year_trades = combined_df_sorted[(combined_df_sorted[\"Trade Year\"] == year)]\n",
    "    \n",
    "        # Calculate total ROI\n",
    "        total_roi = year_trades[\"ROI%\"].sum()\n",
    "    \n",
    "        # Calculate total number of trades\n",
    "        total_trades = len(year_trades)\n",
    "    \n",
    "        # Calculate win rate\n",
    "        win_rate = (year_trades[\"ROI%\"] > 0).mean() * 100\n",
    "    \n",
    "        # Calculate average profit per trade\n",
    "        avg_profit = year_trades[year_trades[\"ROI%\"] > 0][\"ROI%\"].mean()\n",
    "    \n",
    "        # Calculate average loss per trade\n",
    "        avg_loss = year_trades[year_trades[\"ROI%\"] < 0][\"ROI%\"].mean()\n",
    "    \n",
    "        # Calculate maximum drawdown\n",
    "        max_drawdown = (\n",
    "            year_trades[\"ROI%\"].cumsum() - year_trades[\"ROI%\"].cumsum().cummax()\n",
    "        ).min()\n",
    "    \n",
    "        # Calculate ROI/DD ratio\n",
    "        roi_dd_ratio = total_roi / abs(max_drawdown)\n",
    "\n",
    "        variation = f' {signal_ma},{num_candels}'\n",
    "    \n",
    "        # Store the statistics in the DataFrame\n",
    "        stats_df8.loc[year] = [\n",
    "            total_roi,\n",
    "            total_trades,\n",
    "            win_rate,\n",
    "            avg_profit,\n",
    "            avg_loss,\n",
    "            max_drawdown,\n",
    "            roi_dd_ratio,\n",
    "            variation,\n",
    "        ]\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    overall_total_roi = stats_df8[\"Total ROI\"].sum()\n",
    "    overall_total_trades = stats_df8[\"Total Trades\"].sum()\n",
    "    overall_win_rate = (combined_df_sorted[\"ROI%\"] > 0).mean() * 100\n",
    "    overall_avg_profit = combined_df_sorted[combined_df_sorted[\"ROI%\"] > 0][\"ROI%\"].mean()\n",
    "    overall_avg_loss = combined_df_sorted[combined_df_sorted[\"ROI%\"] < 0][\"ROI%\"].mean()\n",
    "    overall_max_drawdown = (\n",
    "        combined_df_sorted[\"ROI%\"].cumsum() - combined_df_sorted[\"ROI%\"].cumsum().cummax()\n",
    "    ).min()\n",
    "    overall_roi_dd_ratio = overall_total_roi / abs(overall_max_drawdown)\n",
    "    overall_variation = variation\n",
    "    \n",
    "    # Store the overall statistics in the DataFrame\n",
    "    stats_df8.loc[\"Overall\"] = [\n",
    "        overall_total_roi,\n",
    "        overall_total_trades,\n",
    "        overall_win_rate,\n",
    "        overall_avg_profit,\n",
    "        overall_avg_loss,\n",
    "        overall_max_drawdown,\n",
    "        overall_roi_dd_ratio,\n",
    "        overall_variation,\n",
    "    ]\n",
    "    return {overall_roi_dd_ratio : stats_df8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78da30e4-3240-48c0-9da2-e7848114bb9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T16:07:19.946664Z",
     "iopub.status.busy": "2024-12-08T16:07:19.946248Z",
     "iopub.status.idle": "2024-12-08T16:07:20.177522Z",
     "shell.execute_reply": "2024-12-08T16:07:20.176009Z",
     "shell.execute_reply.started": "2024-12-08T16:07:19.946637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIGNAL MA : 10 , NO. CANDELS : 1 \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_expiry_nifty' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m y:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSIGNAL MA : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m , NO. CANDELS : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m execute(DF\u001b[38;5;241m=\u001b[39mdata,SIGNAL_MA\u001b[38;5;241m=\u001b[39m i,NUM_CANDELS\u001b[38;5;241m=\u001b[39m j)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# print(len(tb))\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tb) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#     tb_ce = tb[tb['Option Type'] == 'C']\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#     tb_pe = tb[tb['Option Type'] == 'P']\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(DF, SIGNAL_MA, NUM_CANDELS)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m (DF,SIGNAL_MA,NUM_CANDELS):\n\u001b[1;32m      2\u001b[0m     data\u001b[38;5;241m=\u001b[39mDF\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 3\u001b[0m     tb_ce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m ce_trade(data,SIGNAL_MA,NUM_CANDELS)\n\u001b[1;32m      4\u001b[0m     tb_pe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m pe_trade(data,SIGNAL_MA,NUM_CANDELS)\n\u001b[1;32m      5\u001b[0m     tb \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([tb_ce, tb_pe], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[14], line 52\u001b[0m, in \u001b[0;36mce_trade\u001b[0;34m(data, SIGNAL_MA, NUM_CANDELS)\u001b[0m\n\u001b[1;32m     49\u001b[0m spot_atm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39mceil(spot_open \u001b[38;5;241m/\u001b[39m INDEX_MROUND) \u001b[38;5;241m*\u001b[39m INDEX_MROUND)  \u001b[38;5;66;03m##ROUNDS TO NEAREST 500 OTM\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# print(f'spot atm : {spot_atm}')\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# nearest_expiry = await get_expiry(current_date)\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m nearest_expiry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mget_expiry_nifty\u001b[49m(current_date)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# if current_date== nearest_expiry:\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#     next_expiry_passing_value = current_date + dt.timedelta(days=1)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#     nearest_expiry = await get_expiry_nifty( next_expiry_passing_value)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# print(f'passing date for expry : {current_date}')\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# nearest_expiry = await get_monthly_expiry_nifty(current_date)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# print(f'nearest expiry{nearest_expiry}')\u001b[39;00m\n\u001b[1;32m     59\u001b[0m selected_strike_ce\u001b[38;5;241m=\u001b[39mspot_atm\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_expiry_nifty' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# SIMULATION\n",
    "\n",
    "x = [10,20,30,40,50] #SIGNAL_MA\n",
    "y = [1,2,3,4,5]                  #NO. OF CANDELS\n",
    "\n",
    "stats_dictionary = {}\n",
    "for i in x:\n",
    "    for j in y:\n",
    "                                \n",
    "        print(f\"SIGNAL MA : {i} , NO. CANDELS : {j} \")\n",
    "        tb = await execute(DF=data,SIGNAL_MA= i,NUM_CANDELS= j)\n",
    "        # print(len(tb))\n",
    "        if len(tb) > 0:\n",
    "        #     tb_ce = tb[tb['Option Type'] == 'C']\n",
    "        #     tb_pe = tb[tb['Option Type'] == 'P']\n",
    "            stats = generate_stats(tb, i, j)\n",
    "            # print(stats)\n",
    "        #     stats_ce = generate_stats(tb_ce, i, j, k, l,m,n,o,p)\n",
    "        #     stats_pe = generate_stats(tb_ce, i, j, k, l,m,n,o,p)\n",
    "    \n",
    "        for overall_roi_dd_ratio, stats_df in stats.items():\n",
    "            if overall_roi_dd_ratio is not None and overall_roi_dd_ratio > 0:\n",
    "                # print(\"Overall Combined\")\n",
    "                print(stats_df.to_string())\n",
    "                stats_dictionary[overall_roi_dd_ratio] = stats_df\n",
    "    \n",
    "            # for overall_roi_dd_ratio, stats_df in stats_ce.items():\n",
    "            #     if overall_roi_dd_ratio is not None and overall_roi_dd_ratio > 5:\n",
    "            #         print(\"Only CE\")\n",
    "            #         print(stats_df.to_string())\n",
    "            #         stats_dictionary[overall_roi_dd_ratio] = stats_df\n",
    "    \n",
    "            # for overall_roi_dd_ratio, stats_df in stats_pe.items():\n",
    "            #     if overall_roi_dd_ratio is not None and overall_roi_dd_ratio > 5:\n",
    "            #         print(\"Only PE\")\n",
    "            #         print(stats_df.to_string())\n",
    "            #         stats_dictionary[overall_roi_dd_ratio] = stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7b738d-9ac0-4b7b-9124-dc6c71f169e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035dcd47-8122-4f8d-b2d3-3498a69dfcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
