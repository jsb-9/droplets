{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e36f50-b09b-4da5-85c6-8c7da89c8cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:10:14.879019Z",
     "iopub.status.busy": "2025-01-02T21:10:14.878588Z",
     "iopub.status.idle": "2025-01-02T21:10:17.124704Z",
     "shell.execute_reply": "2025-01-02T21:10:17.123491Z",
     "shell.execute_reply.started": "2025-01-02T21:10:14.878972Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal\n",
    "import plotly.graph_objects as go\n",
    "import polars as pl\n",
    "from dash import Dash, dcc, html\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "nse = mcal.get_calendar(\"NSE\")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 25_000)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pl.Config.set_tbl_cols(500)\n",
    "pl.Config.set_tbl_rows(10_000)\n",
    "\n",
    "pd.options.display.float_format = \"{:.4f}\".format\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "# from tooling.enums import AssetClass, Index, Spot, StrikeSpread\n",
    "# from tooling.fetch import fetch_option_data, fetch_spot_data\n",
    "# from tooling.filter import find_atm, option_tool\n",
    "\n",
    "from fetching_from_local_db.enums import AssetClass, Index, StrikeSpread\n",
    "from fetching_from_local_db.fetch_from_db import (\n",
    "    _fetch_batch,\n",
    "    fetch_data,\n",
    "    fetch_spot_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c123b0-1b9a-4dd7-a6ad-cc7a947f437f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:10:17.126786Z",
     "iopub.status.busy": "2025-01-02T21:10:17.126255Z",
     "iopub.status.idle": "2025-01-02T21:10:17.144311Z",
     "shell.execute_reply": "2025-01-02T21:10:17.143391Z",
     "shell.execute_reply.started": "2025-01-02T21:10:17.126766Z"
    }
   },
   "outputs": [],
   "source": [
    "async def get_expiry(f_today):\n",
    "\n",
    "    if (f_today <= dt.date(2024, 1, 25)) and (f_today >= dt.date(2024, 1, 18)):\n",
    "        f_expiry = dt.date(2024, 1, 25)\n",
    "    elif (f_today <= dt.date(2024, 1, 31)) and (f_today >= dt.date(2024, 1, 26)):\n",
    "        f_expiry = dt.date(2024, 1, 31)\n",
    "    elif (f_today <= dt.date(2024, 2, 22)) and (f_today >= dt.date(2024, 2, 29)):\n",
    "        f_expiry = dt.date(2024, 2, 29)\n",
    "    elif (f_today <= dt.date(2024, 3, 25)) and (f_today >= dt.date(2024, 3, 27)):\n",
    "        f_expiry = dt.date(2024, 2, 27)\n",
    "    elif f_today < dt.date(2023, 9, 1):\n",
    "        days_to_thursday = (3 - f_today.weekday()) % 7\n",
    "        nearest_thursday = f_today + dt.timedelta(days=days_to_thursday)\n",
    "        f_expiry = nearest_thursday\n",
    "        if nse.valid_days(start_date=nearest_thursday, end_date=nearest_thursday).empty:\n",
    "            f_expiry = nearest_thursday - dt.timedelta(days=1)\n",
    "    elif f_today >= dt.date(2023, 9, 1):\n",
    "        if f_today.day < 24:\n",
    "            days_to_wednesday = (2 - f_today.weekday()) % 7\n",
    "            nearest_wednesday = f_today + dt.timedelta(days=days_to_wednesday)\n",
    "            f_expiry = nearest_wednesday\n",
    "            if nse.valid_days(\n",
    "                start_date=nearest_wednesday, end_date=nearest_wednesday\n",
    "            ).empty:\n",
    "                f_expiry = nearest_wednesday - dt.timedelta(days=1)\n",
    "        else:\n",
    "            days_to_thursday = (3 - f_today.weekday()) % 7\n",
    "            nearest_thursday = f_today + dt.timedelta(days=days_to_thursday)\n",
    "            f_expiry = nearest_thursday\n",
    "            if nse.valid_days(\n",
    "                start_date=nearest_thursday, end_date=nearest_thursday\n",
    "            ).empty:\n",
    "                f_expiry = nearest_thursday - dt.timedelta(days=1)\n",
    "    return f_expiry\n",
    "\n",
    "\n",
    "async def get_expiry_finnifty(f_today):\n",
    "\n",
    "    days_to_thursday = (1 - f_today.weekday()) % 7\n",
    "    nearest_thursday = f_today + dt.timedelta(days=days_to_thursday)\n",
    "    f_expiry = nearest_thursday\n",
    "    if nse.valid_days(start_date=nearest_thursday, end_date=nearest_thursday).empty:\n",
    "        f_expiry = nearest_thursday - dt.timedelta(days=1)\n",
    "    return f_expiry\n",
    "\n",
    "\n",
    "async def get_expiry_nifty(f_today):\n",
    "\n",
    "    days_to_thursday = (3 - f_today.weekday()) % 7\n",
    "    nearest_thursday = f_today + dt.timedelta(days=days_to_thursday)\n",
    "    f_expiry = nearest_thursday\n",
    "    if nse.valid_days(start_date=nearest_thursday, end_date=nearest_thursday).empty:\n",
    "        f_expiry = nearest_thursday - dt.timedelta(days=1)\n",
    "    return f_expiry\n",
    "\n",
    "\n",
    "async def get_expiry_midcpnifty(f_today):\n",
    "\n",
    "    days_to_thursday = (0 - f_today.weekday()) % 7\n",
    "    nearest_thursday = f_today + dt.timedelta(days=days_to_thursday)\n",
    "    f_expiry = nearest_thursday\n",
    "    if nse.valid_days(start_date=nearest_thursday, end_date=nearest_thursday).empty:\n",
    "        f_expiry = nearest_thursday - dt.timedelta(days=1)\n",
    "    return f_expiry\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "async def get_monthly_expiry_nifty(input_date):\n",
    "    # Get the last day of the current month\n",
    "    current_month_last_day = (\n",
    "        input_date.replace(day=28) + dt.timedelta(days=4)\n",
    "    ).replace(day=1) - dt.timedelta(days=1)\n",
    "\n",
    "    # Find the last Thursday of the current month\n",
    "    last_thursday_current_month = current_month_last_day - dt.timedelta(\n",
    "        days=(current_month_last_day.weekday() - 3) % 7\n",
    "    )\n",
    "\n",
    "    # Check if the current date is less than the last Thursday of the current month\n",
    "    if input_date < last_thursday_current_month:\n",
    "        last_thursday = last_thursday_current_month\n",
    "    else:\n",
    "        # If the current date has passed the last Thursday, find the last Thursday of the next month\n",
    "        next_month = (input_date.month % 12) + 1\n",
    "        next_month_year = input_date.year if next_month > 1 else input_date.year + 1\n",
    "\n",
    "        # Get the last day of the next month (considering February correctly)\n",
    "        if next_month == 2:  # February\n",
    "            if next_month_year % 4 == 0 and (\n",
    "                next_month_year % 100 != 0 or next_month_year % 400 == 0\n",
    "            ):\n",
    "                last_day_of_next_month = 29  # Leap year\n",
    "            else:\n",
    "                last_day_of_next_month = 28  # Non-leap year\n",
    "        else:\n",
    "            # Calculate the last day of the next month\n",
    "            last_day_of_next_month = (\n",
    "                dt.date(next_month_year, next_month, 1) + dt.timedelta(days=31)\n",
    "            ).replace(day=1) - dt.timedelta(days=1)\n",
    "            last_day_of_next_month = (\n",
    "                last_day_of_next_month.day\n",
    "            )  # Extract the day as an integer\n",
    "\n",
    "        # Create a date for the last day of the next month\n",
    "        last_day_of_next_month_date = dt.date(\n",
    "            next_month_year, next_month, last_day_of_next_month\n",
    "        )\n",
    "\n",
    "        # Find the last Thursday of the next month\n",
    "        last_thursday = last_day_of_next_month_date - dt.timedelta(\n",
    "            days=(last_day_of_next_month_date.weekday() - 3) % 7\n",
    "        )\n",
    "\n",
    "    # Validate if the last Thursday is a trading day\n",
    "    if nse.valid_days(start_date=last_thursday, end_date=last_thursday).empty:\n",
    "        # If it's a holiday, find the previous valid trading day\n",
    "        last_thursday -= dt.timedelta(days=1)\n",
    "        while nse.valid_days(start_date=last_thursday, end_date=last_thursday).empty:\n",
    "            last_thursday -= dt.timedelta(days=1)\n",
    "\n",
    "    return last_thursday\n",
    "\n",
    "\n",
    "async def get_option_contract_name(symbol, strike, expiry, opt_type):\n",
    "    temp = \"0\"\n",
    "    mth = expiry.month\n",
    "\n",
    "    if (expiry + dt.timedelta(days=7)).month != expiry.month:\n",
    "        date_string = expiry.strftime(\"%y%b\").upper()\n",
    "        return f\"{symbol}{date_string}{strike}{opt_type}\"\n",
    "    else:\n",
    "        if expiry.day <= 9:\n",
    "            date_string = f\"{expiry.year - 2000}{mth}{temp}{expiry.day}\"\n",
    "        else:\n",
    "            date_string = f\"{expiry.year - 2000}{mth}{expiry.day}\"\n",
    "        return f\"{symbol}{date_string}{strike}{opt_type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf51c95-4424-497d-8f84-a704e1f192cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:10:17.145377Z",
     "iopub.status.busy": "2025-01-02T21:10:17.145187Z",
     "iopub.status.idle": "2025-01-02T21:10:18.528355Z",
     "shell.execute_reply": "2025-01-02T21:10:18.527324Z",
     "shell.execute_reply.started": "2025-01-02T21:10:17.145360Z"
    }
   },
   "outputs": [],
   "source": [
    "# bnf_pandas = pd.read_csv(\"../data/bnf_min.csv\")\n",
    "bnf_pandas = pd.read_csv(\"../data/nifty.csv\")\n",
    "# bnf_pandas = pd.read_csv(\"../data/fin_min.csv\")\n",
    "# bnf_pandas = pd.read_csv(\"../data/midcp_min.csv\")\n",
    "# bnf_pandas = pd.read_csv(\"../data/sensex_min.csv\")\n",
    "# bnf_pandas = pd.read_csv(\"../data/bankex_min.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aaee50c-236e-4bde-b556-a09cc566b1f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:10:18.530448Z",
     "iopub.status.busy": "2025-01-02T21:10:18.530165Z",
     "iopub.status.idle": "2025-01-02T21:10:18.721386Z",
     "shell.execute_reply": "2025-01-02T21:10:18.720183Z",
     "shell.execute_reply.started": "2025-01-02T21:10:18.530428Z"
    }
   },
   "outputs": [],
   "source": [
    "# If Stocks Data ...\n",
    "bnf_pandas[\"datetime\"] = pd.to_datetime(bnf_pandas[\"datetime\"])\n",
    "bnf_pandas[\"datetime\"] = bnf_pandas[\"datetime\"].dt.tz_localize(None)\n",
    "bnf_pandas = bnf_pandas[bnf_pandas[\"datetime\"].dt.year >= 2017]\n",
    "# bnf_pandas.drop(columns=[\"time\"], inplace=True)\n",
    "# bnf_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8444676-b43d-4bb1-b475-fbc232cf06c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:10:18.722903Z",
     "iopub.status.busy": "2025-01-02T21:10:18.722503Z",
     "iopub.status.idle": "2025-01-02T21:10:18.746203Z",
     "shell.execute_reply": "2025-01-02T21:10:18.744948Z",
     "shell.execute_reply.started": "2025-01-02T21:10:18.722867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'polars.dataframe.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "bnf = pl.DataFrame(bnf_pandas)\n",
    "print(type(bnf))\n",
    "# bnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76f37f7-f35c-44b1-a3cb-2c20549b224b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:10:18.748136Z",
     "iopub.status.busy": "2025-01-02T21:10:18.747638Z",
     "iopub.status.idle": "2025-01-02T21:10:18.757109Z",
     "shell.execute_reply": "2025-01-02T21:10:18.756266Z",
     "shell.execute_reply.started": "2025-01-02T21:10:18.748044Z"
    }
   },
   "outputs": [],
   "source": [
    "bnf = bnf.with_columns([pl.col(\"datetime\").alias(\"index\")]).drop(\"datetime\")\n",
    "bnf = bnf.with_columns(pl.col(\"index\").alias(\"datetime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7f0c15c-b276-4b1e-9a78-b5e8b45b4b21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:10:18.759034Z",
     "iopub.status.busy": "2025-01-02T21:10:18.758367Z",
     "iopub.status.idle": "2025-01-02T21:10:18.763436Z",
     "shell.execute_reply": "2025-01-02T21:10:18.762163Z",
     "shell.execute_reply.started": "2025-01-02T21:10:18.759016Z"
    }
   },
   "outputs": [],
   "source": [
    "# bnf = bnf.rename({\"open\": \"o\", \"high\": \"h\", \"low\": \"l\", \"close\": \"c\", \"volume\": \"v\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ee8d470-3759-4016-aa63-40f4a8406141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:10:18.767366Z",
     "iopub.status.busy": "2025-01-02T21:10:18.767053Z",
     "iopub.status.idle": "2025-01-02T21:10:18.774756Z",
     "shell.execute_reply": "2025-01-02T21:10:18.773493Z",
     "shell.execute_reply.started": "2025-01-02T21:10:18.767346Z"
    }
   },
   "outputs": [],
   "source": [
    "def resample(data, timeframe, offset=None):\n",
    "    agg_list = [\n",
    "        pl.col(\"o\").first().alias(\"o\"),\n",
    "        pl.col(\"h\").max().alias(\"h\"),\n",
    "        pl.col(\"l\").min().alias(\"l\"),\n",
    "        pl.col(\"c\").last().alias(\"c\"),\n",
    "    ]\n",
    "    if timeframe == '10m':\n",
    "        offset = '5m'\n",
    "    if \"v\" in data.columns:\n",
    "        agg_list.append(pl.col(\"v\").sum().alias(\"v\"))\n",
    "    return (\n",
    "        data.set_sorted(\"datetime\")\n",
    "        .group_by_dynamic(\n",
    "            index_column=\"datetime\",\n",
    "            every=timeframe,\n",
    "            period=timeframe,\n",
    "            label=\"left\",\n",
    "            offset=offset,\n",
    "        )\n",
    "        .agg(agg_list)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a91ffff-6ff8-461b-a2b6-619a8373ea61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:10:18.776787Z",
     "iopub.status.busy": "2025-01-02T21:10:18.776395Z",
     "iopub.status.idle": "2025-01-02T21:10:18.787097Z",
     "shell.execute_reply": "2025-01-02T21:10:18.785946Z",
     "shell.execute_reply.started": "2025-01-02T21:10:18.776768Z"
    }
   },
   "outputs": [],
   "source": [
    "# def generate_signals(df, n=5):\n",
    "#     import numpy as np\n",
    "#     import pandas as pd\n",
    "\n",
    "#     # Ensure required columns are present\n",
    "#     required_cols = {'o', 'h', 'l', 'c', 'datetime'}\n",
    "#     if not required_cols.issubset(df.columns):\n",
    "#         raise ValueError(f\"DataFrame must contain columns: {required_cols}\")\n",
    "    \n",
    "#     # Ensure datetime is in datetime format\n",
    "#     if not np.issubdtype(df['datetime'].dtype, np.datetime64):\n",
    "#         df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    \n",
    "#     # Calculate the low of the previous n candles\n",
    "#     df['Prev_N_Low'] = df['l'].rolling(window=n).min().shift(1)\n",
    "    \n",
    "#     # Generate sell signal\n",
    "#     df['Sell Signal'] = df['c'] < df['Prev_N_Low']\n",
    "    \n",
    "#     # Drop intermediate columns if not needed\n",
    "#     df.drop(columns=['Prev_N_Low'], inplace=True, errors='ignore')\n",
    "    \n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c031f9-ca75-45fb-b07a-a825cc9357dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:10:18.788873Z",
     "iopub.status.busy": "2025-01-02T21:10:18.788306Z",
     "iopub.status.idle": "2025-01-02T21:10:18.802261Z",
     "shell.execute_reply": "2025-01-02T21:10:18.800815Z",
     "shell.execute_reply.started": "2025-01-02T21:10:18.788853Z"
    }
   },
   "outputs": [],
   "source": [
    "# USING SMA LOW for ENTRY\n",
    "def generate_signals(df, st_num=3, ema=5, pct=0.9):\n",
    "    \"\"\"\n",
    "    Calculate signals for reversal selling strategy with SMA-based condition.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame with columns 'datetime', 'o', 'h', 'l', 'c', and optionally 'v'.\n",
    "    st_num (int): Period for short-term SMA and low calculation.\n",
    "    ema (int): Period for EMA calculation.\n",
    "    pct (float): Percentage threshold for high price comparison.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with additional columns 'Reversal Sell Signal' and tracking indicators.\n",
    "    \"\"\"\n",
    "    # Ensure the DataFrame has the required columns\n",
    "    required_columns = {'datetime', 'h', 'l', 'c'}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        raise ValueError(f\"Input DataFrame must contain columns: {required_columns}\")\n",
    "    \n",
    "    # Calculate short-term SMA of the lows\n",
    "    df['SMA_Low'] = df['l'].rolling(window=st_num).mean().shift(1)\n",
    "    \n",
    "    # Calculate a very short-term EMA (e.g., 5-period)\n",
    "    df['EMA_5'] = df['c'].ewm(span=ema, adjust=False).mean()\n",
    "    \n",
    "    # Calculate daily high till now\n",
    "    df['daily_high_till_now'] = df.groupby(df['datetime'].dt.date)['h'].cummax()\n",
    "    \n",
    "    # Define Reversal Sell Signal\n",
    "    df['Sell Signal'] = (\n",
    "        (df['h'] > (pct * df['daily_high_till_now'].shift(1))) &  # Price is near or above the daily high\n",
    "        (df['c'] < df['SMA_Low'])  # Close below SMA of the lows\n",
    "    ).astype(int)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57cef06f-a6b6-472c-a04f-9abd8a6efa08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:10:19.260862Z",
     "iopub.status.busy": "2025-01-02T21:10:19.260341Z",
     "iopub.status.idle": "2025-01-02T21:10:19.266714Z",
     "shell.execute_reply": "2025-01-02T21:10:19.265831Z",
     "shell.execute_reply.started": "2025-01-02T21:10:19.260842Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_signals(df, st_num=3, ema=5, pct=0.9):\n",
    "    \"\"\"\n",
    "    Calculate signals for reversal selling strategy.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame with columns 'datetime', 'o', 'h', 'l', 'c', and optionally 'v'.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with additional columns 'Reversal Sell Signal' and tracking indicators.\n",
    "    \"\"\"\n",
    "    # Ensure the DataFrame has the required columns\n",
    "    required_columns = {'datetime', 'h', 'l', 'c'}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        raise ValueError(f\"Input DataFrame must contain columns: {required_columns}\")\n",
    "    \n",
    "    # Calculate a 3-period high (short-term high)\n",
    "    df['short_term_low'] = df['l'].rolling(window=st_num).min().shift(1)\n",
    "\n",
    "    # Calculate a very short-term EMA (e.g., 5-period)\n",
    "    df['EMA_5'] = df['c'].ewm(span=ema, adjust=False).mean()\n",
    "    \n",
    "    # Calculate daily high till now\n",
    "    df['daily_high_till_now'] = df.groupby(df['datetime'].dt.date)['h'].cummax()\n",
    "    \n",
    "    # Define Reversal Sell Signal\n",
    "    # df['Sell Signal'] = (\n",
    "    #     (df['h'] > (pct*df['daily_high_till_now'].shift(1))) &  # Price is near or above the daily high\n",
    "    #     (df['c'] < df['short_term_low']) &  # Closing below the short-term high (early weakness)\n",
    "    #     (df['c'] < df['EMA_5'])  # Close below very short-term EMA for confirmation\n",
    "    # ).astype(int)\n",
    "    df['Sell Signal'] = (\n",
    "        (df['h'] > (pct*df['daily_high_till_now'].shift(1))) &  # Price is near or above the daily high\n",
    "        (df['c'] < df['short_term_low'])).astype(int)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b424fbd9-0053-4192-9901-e9afed539868",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:10:19.816078Z",
     "iopub.status.busy": "2025-01-02T21:10:19.815546Z",
     "iopub.status.idle": "2025-01-02T21:10:20.011272Z",
     "shell.execute_reply": "2025-01-02T21:10:20.010343Z",
     "shell.execute_reply.started": "2025-01-02T21:10:19.816058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735722   2024-12-13 15:25:00\n",
      "735723   2024-12-13 15:26:00\n",
      "735724   2024-12-13 15:27:00\n",
      "735725   2024-12-13 15:28:00\n",
      "735726   2024-12-13 15:29:00\n",
      "Name: datetime, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "data = bnf_pandas.copy()\n",
    "# data['datetime'] = pd.to_datetime(data['datetime'].dt.date)\n",
    "print(data[\"datetime\"].tail())\n",
    "trading_days_set = set(data[\"datetime\"].dt.date)\n",
    "# sorted(trading_days_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3254ebab-103e-4f51-abf3-f0e1ecd195a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:19:02.416489Z",
     "iopub.status.busy": "2025-01-02T22:19:02.415488Z",
     "iopub.status.idle": "2025-01-02T22:19:02.424890Z",
     "shell.execute_reply": "2025-01-02T22:19:02.423780Z",
     "shell.execute_reply.started": "2025-01-02T22:19:02.416457Z"
    }
   },
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "INSTRUMENT = \"NIFTY\"\n",
    "INDEX = \"nifty\"\n",
    "INDEX_MROUND = 50\n",
    "# INDEX_MROUND=100\n",
    "\n",
    "# INSTRUMENT = \"NIFTY\"\n",
    "# INDEX = \"nifty\"\n",
    "# INDEX_MROUND=50\n",
    "\n",
    "PORTFOLIO_VALUE = 10_00_000\n",
    "INDEX_LEV = 8\n",
    "RPT_CE = 0.03\n",
    "RPT_PE = 0.03\n",
    "SLIPPAGE = 0.01\n",
    "TF = \"5m\"\n",
    "\n",
    "# SIGNAL_MA = 20\n",
    "# NUM_OF_CANDELS = 1\n",
    "# T_MA=20\n",
    "# TARGET=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c18b595b-c43c-4c06-9957-939b2a237fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:19:03.018477Z",
     "iopub.status.busy": "2025-01-02T22:19:03.018158Z",
     "iopub.status.idle": "2025-01-02T22:19:03.091710Z",
     "shell.execute_reply": "2025-01-02T22:19:03.090432Z",
     "shell.execute_reply.started": "2025-01-02T22:19:03.018459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>o</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147150</th>\n",
       "      <td>2024-12-13 15:05:00</td>\n",
       "      <td>24765.6000</td>\n",
       "      <td>24790.2500</td>\n",
       "      <td>24762.3000</td>\n",
       "      <td>24772.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147151</th>\n",
       "      <td>2024-12-13 15:10:00</td>\n",
       "      <td>24773.8000</td>\n",
       "      <td>24773.9000</td>\n",
       "      <td>24764.6000</td>\n",
       "      <td>24771.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147152</th>\n",
       "      <td>2024-12-13 15:15:00</td>\n",
       "      <td>24772.1500</td>\n",
       "      <td>24774.6500</td>\n",
       "      <td>24761.0500</td>\n",
       "      <td>24773.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147153</th>\n",
       "      <td>2024-12-13 15:20:00</td>\n",
       "      <td>24773.8000</td>\n",
       "      <td>24792.3000</td>\n",
       "      <td>24770.4000</td>\n",
       "      <td>24785.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147154</th>\n",
       "      <td>2024-12-13 15:25:00</td>\n",
       "      <td>24785.5000</td>\n",
       "      <td>24788.3500</td>\n",
       "      <td>24778.8500</td>\n",
       "      <td>24781.3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime          o          h          l          c\n",
       "147150 2024-12-13 15:05:00 24765.6000 24790.2500 24762.3000 24772.6000\n",
       "147151 2024-12-13 15:10:00 24773.8000 24773.9000 24764.6000 24771.4500\n",
       "147152 2024-12-13 15:15:00 24772.1500 24774.6500 24761.0500 24773.8000\n",
       "147153 2024-12-13 15:20:00 24773.8000 24792.3000 24770.4000 24785.7500\n",
       "147154 2024-12-13 15:25:00 24785.5000 24788.3500 24778.8500 24781.3000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnf = resample(bnf, TF)\n",
    "data = bnf.to_pandas()\n",
    "data.tail()\n",
    "# data[['MA','signal_spot']]=MA(data,200)\n",
    "# data[data['signal_spot']==1].head(50)\n",
    "# bnf\n",
    "# data.tail(50)\n",
    "# data[data['datetime'].dt.date == dt.date(2024, 4, 29)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42a54db1-27a4-4287-acbf-f444bf17e07f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:19:16.835790Z",
     "iopub.status.busy": "2025-01-02T22:19:16.835543Z",
     "iopub.status.idle": "2025-01-02T22:19:16.864975Z",
     "shell.execute_reply": "2025-01-02T22:19:16.863539Z",
     "shell.execute_reply.started": "2025-01-02T22:19:16.835772Z"
    }
   },
   "outputs": [],
   "source": [
    "async def ce_trade(data, st_high, ema, pct):\n",
    "    df = data.copy()\n",
    "\n",
    "    start_date = dt.date(2019, 1, 1)\n",
    "    end_date = dt.date(2024, 11, 30)\n",
    "\n",
    "    current_date = start_date\n",
    "\n",
    "    combined_trades = pd.DataFrame()\n",
    "    total_trades = pd.DataFrame()\n",
    "    time_of_day = dt.time(9, 15)\n",
    "    trade_book = []\n",
    "    ce_lowest_low = float(\"inf\")\n",
    "    ce_highest_high = float(\"-inf\")\n",
    "    entry_rsi = 0\n",
    "\n",
    "    while current_date < end_date:\n",
    "        # print(current_date)\n",
    "        entry = 0\n",
    "        initial_sl = 0\n",
    "        exit = 0\n",
    "        in_ce_trade = False\n",
    "        in_pe_trade = False\n",
    "        # signal_exist=False\n",
    "\n",
    "        points_captured = 0\n",
    "        remark = \"\"\n",
    "        trailing_active = False\n",
    "        tsl = 0\n",
    "        stop_trading = False\n",
    "        is_gap_ce_sl = False\n",
    "        previous_ce_sl_hit = False\n",
    "        current_date_increament_flag = False\n",
    "        # tsl_high = 0\n",
    "\n",
    "        starting_time = dt.time(9, 15)\n",
    "\n",
    "        ending_time = dt.time(15, 30)\n",
    "\n",
    "        if not in_ce_trade and current_date in trading_days_set:\n",
    "\n",
    "            ce_search_datetime = dt.datetime.combine(current_date, time_of_day)\n",
    "            # print(f'current date : {ce_search_datetime}')\n",
    "\n",
    "            spot_open = df.loc[df[\"datetime\"] >= ce_search_datetime, \"o\"].iloc[0]\n",
    "            # print(f'spot open : {spot_open}')\n",
    "            # spot_atm = int(round(spot_open / INDEX_MROUND) * INDEX_MROUND)\n",
    "            spot_atm = int(\n",
    "                math.ceil(spot_open / INDEX_MROUND) * INDEX_MROUND\n",
    "            )  ##ROUNDS TO NEAREST 500 OTM\n",
    "            # print(f'spot atm : {spot_atm}')\n",
    "            # nearest_expiry = await get_expiry(current_date)\n",
    "            nearest_expiry = await get_expiry_nifty(current_date)\n",
    "            # if current_date== nearest_expiry:\n",
    "            #     next_expiry_passing_value = current_date + dt.timedelta(days=1)\n",
    "            #     nearest_expiry = await get_expiry_nifty( next_expiry_passing_value)\n",
    "            # print(f'passing date for expry : {current_date}')\n",
    "            # nearest_expiry = await get_monthly_expiry_nifty(current_date)\n",
    "            # print(f'nearest expiry{nearest_expiry}')\n",
    "            selected_strike_ce = spot_atm\n",
    "            # print(f'selected strike CE : {selected_strike_ce}')\n",
    "            ce_df = await fetch_data(\n",
    "                index=INDEX,\n",
    "                start_date=nearest_expiry - dt.timedelta(days=7),\n",
    "                start_time=starting_time,\n",
    "                end_date=nearest_expiry,\n",
    "                end_time=ending_time,\n",
    "                strike=selected_strike_ce,\n",
    "                asset_class=\"C\",\n",
    "                expiry=nearest_expiry,\n",
    "            )\n",
    "            # print(ce_df)\n",
    "            if ce_df is not None and not isinstance(ce_df, str):\n",
    "                # print('new data fetched CE')\n",
    "                data_ce = True\n",
    "                ce_df = ce_df.select([\"datetime\", \"o\", \"h\", \"l\", \"c\", \"v\"])\n",
    "                ce_df = resample(ce_df, TF)\n",
    "                ce_df_pandas = ce_df.to_pandas()\n",
    "                ce_df = generate_signals(ce_df_pandas, st_high, ema, pct)\n",
    "                # ce_df = calculate_signals(ce_df_pandas)\n",
    "                # print(ce_df.to_string())\n",
    "            else:\n",
    "                data_ce = False\n",
    "                current_date += dt.timedelta(days=1)\n",
    "                continue\n",
    "\n",
    "            if data_ce:\n",
    "\n",
    "                for i in range(0, len(ce_df)):\n",
    "                    current_candle = ce_df.iloc[i]\n",
    "                    current_candle_open = ce_df.iloc[i][\"o\"]\n",
    "                    current_candle_high = ce_df.iloc[i][\"h\"]\n",
    "                    current_candle_low = ce_df.iloc[i][\"l\"]\n",
    "                    current_candle_close = ce_df.iloc[i][\"c\"]\n",
    "\n",
    "                    previous_candle_low = ce_df.iloc[i - 1][\"l\"]\n",
    "                    previous_candle_close = ce_df.iloc[i - 1][\"c\"]\n",
    "                    \n",
    "\n",
    "                    expiry = nearest_expiry\n",
    "                    strike = selected_strike_ce\n",
    "                    asset_class = \"C\"\n",
    "                    # print(ce_df.iloc[i])\n",
    "\n",
    "                    signal = ce_df.iloc[i - 1][\"Sell Signal\"]\n",
    "\n",
    "                    if ce_df.iloc[i][\"datetime\"] >= ce_search_datetime:\n",
    "\n",
    "\n",
    "                        if (\n",
    "                            not previous_ce_sl_hit\n",
    "                            and not in_ce_trade\n",
    "                            and signal\n",
    "                            # and current_candle_low < previous_candle_low\n",
    "                            and ce_df.iloc[i][\"datetime\"].time() > time_of_day\n",
    "                            and (\n",
    "                                (nearest_expiry - ce_df.iloc[i][\"datetime\"].date()).days\n",
    "                                >= 0\n",
    "                                and (\n",
    "                                    nearest_expiry - ce_df.iloc[i][\"datetime\"].date()\n",
    "                                ).days\n",
    "                                < 8\n",
    "                            )\n",
    "                            and ce_df.iloc[i][\"datetime\"].time() < dt.time(15, 25)\n",
    "                        ):\n",
    "                            # print(ce_df.iloc[i-1])\n",
    "                            # print(f'entry found {previous_candle_low}')\n",
    "                            # print(f'entry datetime {ce_df.iloc[i][\"datetime\"]}')\n",
    "                            \n",
    "                            # today_data = ce_df[ce_df['datetime'].dt.date == current_candle['datetime'].date()]\n",
    "                            # day_high = today_data.iloc[0 : i-1]['h'].max()\n",
    "                            # print(today_data.to_string())\n",
    "                            \n",
    "                            entry = previous_candle_close\n",
    "                            entry_date = ce_df.iloc[i-1][\"datetime\"].date()\n",
    "                            entry_time = ce_df.iloc[i-1][\"datetime\"].time()\n",
    "                            # initial_sl = ce_df.iloc[i - SL_CANDLES_NUM : i][\"h\"].max()\n",
    "                            # initial_sl = day_high\n",
    "                            initial_sl = ce_df.iloc[i-1]['daily_high_till_now']\n",
    "                            in_ce_trade = True\n",
    "                            ce_lowest_low = float(\"inf\")\n",
    "                            ce_highest_high = float(\"-inf\")\n",
    "                            # print(f'initial SL : {initial_sl}')\n",
    "                            # entry_rsi = ce_df.iloc[i-1]['RSI']\n",
    "\n",
    "                            qty = RPT_CE * PORTFOLIO_VALUE / (initial_sl - entry)\n",
    "                            if (\n",
    "                                (qty * strike) / (INDEX_LEV * PORTFOLIO_VALUE)\n",
    "                            ) * 100 > 250:\n",
    "                                qty = PORTFOLIO_VALUE * INDEX_LEV / strike * 2.5\n",
    "\n",
    "                            # print(f'qty : {qty}')\n",
    "\n",
    "                        # While in trade, track the highest high and lowest low\n",
    "                        if in_ce_trade:\n",
    "                            # Track the highest high\n",
    "                            ce_highest_high = max(ce_highest_high, current_candle_high)\n",
    "\n",
    "                            # Track the lowest low\n",
    "                            ce_lowest_low = min(ce_lowest_low, current_candle_low)\n",
    "\n",
    "                            # if all(\n",
    "                            #     ce_df.loc[i - j, \"h\"] <= ce_df.loc[i - fractal_num, \"h\"]\n",
    "                            #     for j in range(0, ((fractal_num * 2) + 1))\n",
    "                            # ):\n",
    "                            #     tsl_high = ce_df.loc[i - fractal_num, \"h\"]\n",
    "\n",
    "                        if (\n",
    "                            in_ce_trade\n",
    "                            and ce_df.iloc[i][\"datetime\"].time() == dt.time(9, 15)\n",
    "                            and current_candle_open > initial_sl\n",
    "                        ):\n",
    "\n",
    "                            # print(ce_df.iloc[i])\n",
    "                            # print(f'GAP sl hit {initial_sl}')\n",
    "                            # print(f'GAP sl datetime {ce_df.iloc[i][\"datetime\"]}')\n",
    "                            exit = current_candle_close\n",
    "                            in_ce_trade = False\n",
    "                            stop_trading = False\n",
    "                            previous_ce_sl_hit = True\n",
    "                            is_gap_ce_sl = False\n",
    "                            points_captured = entry - exit\n",
    "                            exit_time = ce_df.iloc[i][\"datetime\"].time()\n",
    "                            slippage = SLIPPAGE * (entry + exit)\n",
    "                            pnl = qty * (points_captured - slippage)\n",
    "                            remark = \"Gap SL hit\"\n",
    "                            weekday_int = entry_date.weekday()\n",
    "                            weekday_name = [\n",
    "                                \"Monday\",\n",
    "                                \"Tuesday\",\n",
    "                                \"Wednesday\",\n",
    "                                \"Thursday\",\n",
    "                                \"Friday\",\n",
    "                                \"Saturday\",\n",
    "                                \"Sunday\",\n",
    "                            ][weekday_int]\n",
    "                            trade = {\n",
    "                                \"date\": entry_date,\n",
    "                                \"day\": weekday_name,\n",
    "                                \"expiry\": expiry,\n",
    "                                \"DTE\": (nearest_expiry - entry_date).days,\n",
    "                                # 'atm' : atm,\n",
    "                                # 'scrip' : index ,\n",
    "                                \"strike\": strike,\n",
    "                                \"type\": asset_class,\n",
    "                                \"Entry Price\": entry,\n",
    "                                \"Entry Time\": entry_time,\n",
    "                                \"initial sl\": initial_sl,\n",
    "                                # \"TSL\": tsl_high,\n",
    "                                # 'OTM Entry' : otm_entry,\n",
    "                                \"Exit Price\": exit,\n",
    "                                \"Exit date\": ce_df.iloc[i][\"datetime\"].date(),\n",
    "                                \"Exit Time\": exit_time,\n",
    "                                'RSI on Entry': entry_rsi,\n",
    "                                # 'OTM EXIT ' : otm_exit,\n",
    "                                \"Remark\": remark,\n",
    "                                \"Points Captured\": points_captured,\n",
    "                                \"Slippage\": slippage,\n",
    "                                # 'OTM cost' : otm_exit-otm_entry,\n",
    "                                \"Qty\": qty,\n",
    "                                \"PnL\": pnl,\n",
    "                                \"ROI%\": (pnl / PORTFOLIO_VALUE) * 100,\n",
    "                                \"Trade Year\": ce_df.iloc[i][\"datetime\"].year,\n",
    "                                \"Trade Month\": ce_df.iloc[i][\"datetime\"].month,\n",
    "                                \"Highest High\": ce_highest_high,  # Add highest high to trade data\n",
    "                                \"Lowest Low\": ce_lowest_low,  # Add lowest low to trade data\n",
    "                                \"Max ROI%\": (\n",
    "                                    (qty * (entry - ce_lowest_low)) / PORTFOLIO_VALUE\n",
    "                                )\n",
    "                                * 100,\n",
    "                                \"Margin\": (\n",
    "                                    (qty * strike) / (INDEX_LEV * PORTFOLIO_VALUE)\n",
    "                                )\n",
    "                                * 100,\n",
    "                            }\n",
    "                            # print('apending initial sl trade')\n",
    "                            trade_book.append(trade)\n",
    "                            # tsl_high = 0\n",
    "                            points_captured = 0\n",
    "                            current_date = ce_df.iloc[i][\"datetime\"].date()\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = ce_df.iloc[i][\"datetime\"].time()\n",
    "                            # print(f'current date changed to : {current_date} and time to {time_of_day}')\n",
    "                            break\n",
    "\n",
    "                        if in_ce_trade and current_candle_high > initial_sl:\n",
    "                            # print(ce_df.iloc[i])\n",
    "                            # print(f'initial sl hit {initial_sl}')\n",
    "                            # print(f'initial sl datetime {ce_df.iloc[i][\"datetime\"]}')\n",
    "                            exit = initial_sl\n",
    "                            otm_datetime = ce_df.iloc[i][\"datetime\"]\n",
    "                            in_ce_trade = False\n",
    "                            stop_trading = False\n",
    "                            previous_ce_sl_hit = True\n",
    "                            is_gap_ce_sl = False\n",
    "                            points_captured = entry - exit\n",
    "                            exit_time = ce_df.iloc[i][\"datetime\"].time()\n",
    "                            slippage = SLIPPAGE * (entry + exit)\n",
    "                            pnl = qty * (points_captured - slippage)\n",
    "                            # pnl=(qty*(points_captured-slippage))-qty*(otm_exit-otm_entry)\n",
    "                            remark = \"SL hit\"\n",
    "                            weekday_int = entry_date.weekday()\n",
    "                            weekday_name = [\n",
    "                                \"Monday\",\n",
    "                                \"Tuesday\",\n",
    "                                \"Wednesday\",\n",
    "                                \"Thursday\",\n",
    "                                \"Friday\",\n",
    "                                \"Saturday\",\n",
    "                                \"Sunday\",\n",
    "                            ][weekday_int]\n",
    "                            trade = {\n",
    "                                \"date\": entry_date,\n",
    "                                \"day\": weekday_name,\n",
    "                                \"expiry\": expiry,\n",
    "                                \"DTE\": (nearest_expiry - entry_date).days,\n",
    "                                # 'atm' : atm,\n",
    "                                # 'scrip' : index ,\n",
    "                                \"strike\": strike,\n",
    "                                \"type\": asset_class,\n",
    "                                \"Entry Price\": entry,\n",
    "                                \"Entry Time\": entry_time,\n",
    "                                \"initial sl\": initial_sl,\n",
    "                                # \"TSL\": tsl_high,\n",
    "                                # 'OTM Entry' : otm_entry,\n",
    "                                \"Exit Price\": exit,\n",
    "                                \"Exit date\": ce_df.iloc[i][\"datetime\"].date(),\n",
    "                                \"Exit Time\": exit_time,\n",
    "                                'RSI on Entry': entry_rsi,\n",
    "                                # 'OTM EXIT ' : otm_exit,\n",
    "                                \"Remark\": remark,\n",
    "                                \"Points Captured\": points_captured,\n",
    "                                \"Slippage\": slippage,\n",
    "                                # 'OTM cost' : otm_exit-otm_entry,\n",
    "                                \"Qty\": qty,\n",
    "                                \"PnL\": pnl,\n",
    "                                \"ROI%\": (pnl / PORTFOLIO_VALUE) * 100,\n",
    "                                \"Trade Year\": ce_df.iloc[i][\"datetime\"].year,\n",
    "                                \"Trade Month\": ce_df.iloc[i][\"datetime\"].month,\n",
    "                                \"Highest High\": ce_highest_high,  # Add highest high to trade data\n",
    "                                \"Lowest Low\": ce_lowest_low,  # Add lowest low to trade data\n",
    "                                \"Max ROI%\": (\n",
    "                                    (qty * (entry - ce_lowest_low)) / PORTFOLIO_VALUE\n",
    "                                )\n",
    "                                * 100,\n",
    "                                \"Margin\": (\n",
    "                                    (qty * strike) / (INDEX_LEV * PORTFOLIO_VALUE)\n",
    "                                )\n",
    "                                * 100,\n",
    "                            }\n",
    "                            # print('apending initial sl trade')\n",
    "                            trade_book.append(trade)\n",
    "                            # tsl_high = 0\n",
    "                            points_captured = 0\n",
    "                            current_date = ce_df.iloc[i][\"datetime\"].date()\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = ce_df.iloc[i][\"datetime\"].time()\n",
    "                            # print(f'current date changed to : {current_date} and time to {time_of_day}')\n",
    "                            break\n",
    "\n",
    "                        if (\n",
    "                            in_ce_trade\n",
    "                            and ce_df.iloc[i][\"datetime\"].date() == nearest_expiry\n",
    "                            and ce_df.iloc[i]['datetime'].time() >= dt.time(15, 20)\n",
    "                        ):\n",
    "                            # print(ce_df.iloc[i])\n",
    "                            # print(f'EOD exit {current_candle_close}')\n",
    "                            # print(f'EOD datetime {ce_df.iloc[i][\"datetime\"]}')\n",
    "                            exit = current_candle_close\n",
    "                            otm_datetime = ce_df.iloc[i][\"datetime\"]\n",
    "                            in_ce_trade = False\n",
    "                            previous_ce_sl_hit = True\n",
    "                            is_gap_ce_sl = False\n",
    "                            points_captured = entry - exit\n",
    "                            exit_time = ce_df.iloc[i][\"datetime\"].time()\n",
    "                            slippage = SLIPPAGE * (entry + exit)\n",
    "                            pnl = qty * (points_captured - slippage)\n",
    "                            # pnl=(qty*(points_captured-slippage))-qty*(otm_exit-otm_entry)\n",
    "                            remark = \"EOD exit\"\n",
    "                            weekday_int = entry_date.weekday()\n",
    "                            weekday_name = [\n",
    "                                \"Monday\",\n",
    "                                \"Tuesday\",\n",
    "                                \"Wednesday\",\n",
    "                                \"Thursday\",\n",
    "                                \"Friday\",\n",
    "                                \"Saturday\",\n",
    "                                \"Sunday\",\n",
    "                            ][weekday_int]\n",
    "                            trade = {\n",
    "                                \"date\": entry_date,\n",
    "                                \"day\": weekday_name,\n",
    "                                \"expiry\": expiry,\n",
    "                                \"DTE\": (nearest_expiry - entry_date).days,\n",
    "                                # 'atm' : atm,\n",
    "                                # 'scrip' : index ,\n",
    "                                \"strike\": strike,\n",
    "                                \"type\": asset_class,\n",
    "                                \"Entry Price\": entry,\n",
    "                                \"Entry Time\": entry_time,\n",
    "                                \"initial sl\": initial_sl,\n",
    "                                # \"TSL\": tsl_high,\n",
    "                                # 'OTM Entry' : otm_entry,\n",
    "                                \"Exit Price\": exit,\n",
    "                                \"Exit date\": ce_df.iloc[i][\"datetime\"].date(),\n",
    "                                \"Exit Time\": exit_time,\n",
    "                                'RSI on Entry': entry_rsi,\n",
    "                                # 'OTM EXIT ' : otm_exit,\n",
    "                                \"Remark\": remark,\n",
    "                                \"Points Captured\": points_captured,\n",
    "                                \"Slippage\": slippage,\n",
    "                                # 'OTM cost' : otm_exit-otm_entry,\n",
    "                                \"Qty\": qty,\n",
    "                                \"PnL\": pnl,\n",
    "                                \"ROI%\": (pnl / PORTFOLIO_VALUE) * 100,\n",
    "                                \"Trade Year\": ce_df.iloc[i][\"datetime\"].year,\n",
    "                                \"Trade Month\": ce_df.iloc[i][\"datetime\"].month,\n",
    "                                \"Highest High\": ce_highest_high,  # Add highest high to trade data\n",
    "                                \"Lowest Low\": ce_lowest_low,  # Add lowest low to trade data\n",
    "                                \"Max ROI%\": (\n",
    "                                    (qty * (entry - ce_lowest_low)) / PORTFOLIO_VALUE\n",
    "                                )\n",
    "                                * 100,\n",
    "                                \"Margin\": (\n",
    "                                    (qty * strike) / (INDEX_LEV * PORTFOLIO_VALUE)\n",
    "                                )\n",
    "                                * 100,\n",
    "                            }\n",
    "                            # print('apending EOD trade')\n",
    "                            trade_book.append(trade)\n",
    "                            # tsl_high = 0\n",
    "                            points_captured = 0\n",
    "                            current_date = nearest_expiry + dt.timedelta(days=1)\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = dt.time(9, 15)\n",
    "                            # print(f'current date increased by 1 on expiry : {current_date}')\n",
    "                            break\n",
    "\n",
    "                        if (\n",
    "                            not in_ce_trade\n",
    "                            and not previous_ce_sl_hit\n",
    "                            and ce_df.iloc[i][\"datetime\"].time() > dt.time(15, 00)\n",
    "                        ):\n",
    "                            # print('inside exoiry non trade date increment')\n",
    "                            current_date = current_date + dt.timedelta(days=1)\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = dt.time(9, 15)\n",
    "                            break\n",
    "\n",
    "        if not current_date_increament_flag:\n",
    "            current_date = current_date + dt.timedelta(days=1)\n",
    "            current_date_increament_flag = False\n",
    "\n",
    "    trade_book_df = pd.DataFrame(trade_book)\n",
    "\n",
    "    return trade_book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5aaf60ba-1818-40bc-97a7-e6067e9f687f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:19:17.065694Z",
     "iopub.status.busy": "2025-01-02T22:19:17.065365Z",
     "iopub.status.idle": "2025-01-02T22:19:17.092441Z",
     "shell.execute_reply": "2025-01-02T22:19:17.091138Z",
     "shell.execute_reply.started": "2025-01-02T22:19:17.065668Z"
    }
   },
   "outputs": [],
   "source": [
    "async def pe_trade(data, st_high, ema, pct):\n",
    "    df = data.copy()\n",
    "\n",
    "    start_date = dt.date(2019, 1, 1)\n",
    "    end_date = dt.date(2024, 11, 30)\n",
    "\n",
    "    current_date = start_date\n",
    "\n",
    "    combined_trades = pd.DataFrame()\n",
    "    total_trades = pd.DataFrame()\n",
    "    time_of_day = dt.time(9, 15)\n",
    "    trade_book = []\n",
    "    pe_lowest_low = float(\"inf\")\n",
    "    pe_highest_high = float(\"-inf\")\n",
    "    entry_rsi = 0\n",
    "\n",
    "    while current_date < end_date:\n",
    "        # print(current_date)\n",
    "        entry = 0\n",
    "        initial_sl = 0\n",
    "        exit = 0\n",
    "        in_pe_trade = False\n",
    "        in_pe_trade = False\n",
    "        # signal_exist=False\n",
    "\n",
    "        points_captured = 0\n",
    "        remark = \"\"\n",
    "        trailing_active = False\n",
    "        tsl = 0\n",
    "        stop_trading = False\n",
    "        is_gap_pe_sl = False\n",
    "        previous_pe_sl_hit = False\n",
    "        current_date_increament_flag = False\n",
    "        # tsl_high = 0\n",
    "\n",
    "        starting_time = dt.time(9, 15)\n",
    "\n",
    "        ending_time = dt.time(15, 30)\n",
    "\n",
    "        if not in_pe_trade and current_date in trading_days_set:\n",
    "\n",
    "            pe_search_datetime = dt.datetime.combine(current_date, time_of_day)\n",
    "            # print(f'current date : {pe_search_datetime}')\n",
    "\n",
    "            spot_open = df.loc[df[\"datetime\"] >= pe_search_datetime, \"o\"].iloc[0]\n",
    "            # print(f'spot open : {spot_open}')\n",
    "            # spot_atm = int(round(spot_open / INDEX_MROUND) * INDEX_MROUND)\n",
    "            spot_atm = int(\n",
    "                math.floor(spot_open / INDEX_MROUND) * INDEX_MROUND\n",
    "            )  ##ROUNDS TO NEAREST 500 OTM\n",
    "            # print(f'spot atm : {spot_atm}')\n",
    "            # nearest_expiry = await get_expiry(current_date)\n",
    "            nearest_expiry = await get_expiry_nifty(current_date)\n",
    "            # if current_date== nearest_expiry:\n",
    "            #     next_expiry_passing_value = current_date + dt.timedelta(days=1)\n",
    "            #     nearest_expiry = await get_expiry_nifty( next_expiry_passing_value)\n",
    "            # print(f'passing date for expry : {current_date}')\n",
    "            # nearest_expiry = await get_monthly_expiry_nifty(current_date)\n",
    "            # print(f'nearest expiry{nearest_expiry}')\n",
    "            selected_strike_pe = spot_atm\n",
    "            # print(f'selected strike PE : {selected_strike_pe}')\n",
    "            pe_df = await fetch_data(\n",
    "                index=INDEX,\n",
    "                start_date=nearest_expiry - dt.timedelta(days=7),\n",
    "                start_time=starting_time,\n",
    "                end_date=nearest_expiry,\n",
    "                end_time=ending_time,\n",
    "                strike=selected_strike_pe,\n",
    "                asset_class=\"P\",\n",
    "                expiry=nearest_expiry,\n",
    "            )\n",
    "            if pe_df is not None and not isinstance(pe_df, str):\n",
    "                # print('new data fetched PE')\n",
    "                data_pe = True\n",
    "                pe_df = pe_df.select([\"datetime\", \"o\", \"h\", \"l\", \"c\", \"v\"])\n",
    "                pe_df = resample(pe_df, TF)\n",
    "                pe_df_pandas = pe_df.to_pandas()\n",
    "                pe_df = generate_signals(pe_df_pandas, st_high, ema, pct)\n",
    "                # pe_df = calculate_signals(pe_df_pandas)\n",
    "                # print(pe_df.to_string())\n",
    "            else:\n",
    "                data_pe = False\n",
    "                current_date += dt.timedelta(days=1)\n",
    "                continue\n",
    "\n",
    "            if data_pe:\n",
    "\n",
    "                for i in range(0, len(pe_df)):\n",
    "                    current_candle = pe_df.iloc[i]\n",
    "                    current_candle_open = pe_df.iloc[i][\"o\"]\n",
    "                    current_candle_high = pe_df.iloc[i][\"h\"]\n",
    "                    current_candle_low = pe_df.iloc[i][\"l\"]\n",
    "                    current_candle_close = pe_df.iloc[i][\"c\"]\n",
    "\n",
    "                    previous_candle_low = pe_df.iloc[i - 1][\"l\"]\n",
    "                    previous_candle_close = pe_df.iloc[i - 1][\"c\"]\n",
    "                    \n",
    "\n",
    "                    expiry = nearest_expiry\n",
    "                    strike = selected_strike_pe\n",
    "                    asset_class = \"P\"\n",
    "                    # print(pe_df.iloc[i])\n",
    "\n",
    "                    signal = pe_df.iloc[i - 1][\"Sell Signal\"]\n",
    "\n",
    "                    if pe_df.iloc[i][\"datetime\"] >= pe_search_datetime:\n",
    "\n",
    "\n",
    "                        if (\n",
    "                            not previous_pe_sl_hit\n",
    "                            and not in_pe_trade\n",
    "                            and signal\n",
    "                            # and current_candle_low < previous_candle_low\n",
    "                            and pe_df.iloc[i][\"datetime\"].time() > time_of_day\n",
    "                            and (\n",
    "                                (nearest_expiry - pe_df.iloc[i][\"datetime\"].date()).days\n",
    "                                >= 0\n",
    "                                and (\n",
    "                                    nearest_expiry - pe_df.iloc[i][\"datetime\"].date()\n",
    "                                ).days\n",
    "                                < 8\n",
    "                            )\n",
    "                            and pe_df.iloc[i][\"datetime\"].time() < dt.time(15, 25)\n",
    "                        ):\n",
    "                            # print(pe_df.iloc[i-1])\n",
    "                            # print(f'entry found {previous_candle_low}')\n",
    "                            # print(f'entry datetime {pe_df.iloc[i][\"datetime\"]}')\n",
    "                            \n",
    "                            # today_data = pe_df[pe_df['datetime'].dt.date == current_candle['datetime'].date()]\n",
    "                            # day_high = today_data.iloc[0 : i]['h'].max()\n",
    "                            # print(today_data.to_string())\n",
    "                            \n",
    "                            entry = previous_candle_close\n",
    "                            entry_date = pe_df.iloc[i-1][\"datetime\"].date()\n",
    "                            entry_time = pe_df.iloc[i-1][\"datetime\"].time()\n",
    "                            # initial_sl = pe_df.iloc[i - SL_CANDLES_NUM : i][\"h\"].max()\n",
    "                            # initial_sl = day_high\n",
    "                            initial_sl = pe_df.iloc[i-1]['daily_high_till_now']\n",
    "                            in_pe_trade = True\n",
    "                            pe_lowest_low = float(\"inf\")\n",
    "                            pe_highest_high = float(\"-inf\")\n",
    "                            # entry_rsi = pe_df.iloc[i-1]['RSI']\n",
    "\n",
    "                            qty = RPT_PE * PORTFOLIO_VALUE / (initial_sl - entry)\n",
    "                            if (\n",
    "                                (qty * strike) / (INDEX_LEV * PORTFOLIO_VALUE)\n",
    "                            ) * 100 > 250:\n",
    "                                qty = PORTFOLIO_VALUE * INDEX_LEV / strike * 2.5\n",
    "\n",
    "                        # While in trade, track the highest high and lowest low\n",
    "                        if in_pe_trade:\n",
    "                            # Track the highest high\n",
    "                            pe_highest_high = max(pe_highest_high, current_candle_high)\n",
    "\n",
    "                            # Track the lowest low\n",
    "                            pe_lowest_low = min(pe_lowest_low, current_candle_low)\n",
    "\n",
    "                            # if all(\n",
    "                            #     pe_df.loc[i - j, \"h\"] <= pe_df.loc[i - fractal_num, \"h\"]\n",
    "                            #     for j in range(0, ((fractal_num * 2) + 1))\n",
    "                            # ):\n",
    "                            #     tsl_high = pe_df.loc[i - fractal_num, \"h\"]\n",
    "\n",
    "                        if (\n",
    "                            in_pe_trade\n",
    "                            and pe_df.iloc[i][\"datetime\"].time() == dt.time(9, 15)\n",
    "                            and current_candle_open > initial_sl\n",
    "                        ):\n",
    "\n",
    "                            # print(pe_df.iloc[i])\n",
    "                            # print(f'GAP sl hit {initial_sl}')\n",
    "                            # print(f'GAP sl datetime {pe_df.iloc[i][\"datetime\"]}')\n",
    "                            exit = current_candle_close\n",
    "                            in_pe_trade = False\n",
    "                            stop_trading = False\n",
    "                            previous_pe_sl_hit = True\n",
    "                            is_gap_pe_sl = False\n",
    "                            points_captured = entry - exit\n",
    "                            exit_time = pe_df.iloc[i][\"datetime\"].time()\n",
    "                            slippage = SLIPPAGE * (entry + exit)\n",
    "                            pnl = qty * (points_captured - slippage)\n",
    "                            remark = \"Gap SL hit\"\n",
    "                            weekday_int = entry_date.weekday()\n",
    "                            weekday_name = [\n",
    "                                \"Monday\",\n",
    "                                \"Tuesday\",\n",
    "                                \"Wednesday\",\n",
    "                                \"Thursday\",\n",
    "                                \"Friday\",\n",
    "                                \"Saturday\",\n",
    "                                \"Sunday\",\n",
    "                            ][weekday_int]\n",
    "                            trade = {\n",
    "                                \"date\": entry_date,\n",
    "                                \"day\": weekday_name,\n",
    "                                \"expiry\": expiry,\n",
    "                                \"DTE\": (nearest_expiry - entry_date).days,\n",
    "                                # 'atm' : atm,\n",
    "                                # 'scrip' : index ,\n",
    "                                \"strike\": strike,\n",
    "                                \"type\": asset_class,\n",
    "                                \"Entry Price\": entry,\n",
    "                                \"Entry Time\": entry_time,\n",
    "                                \"initial sl\": initial_sl,\n",
    "                                # \"TSL\": tsl_high,\n",
    "                                # 'OTM Entry' : otm_entry,\n",
    "                                \"Exit Price\": exit,\n",
    "                                \"Exit date\": pe_df.iloc[i][\"datetime\"].date(),\n",
    "                                \"Exit Time\": exit_time,\n",
    "                                'RSI on Entry': entry_rsi,\n",
    "                                # 'OTM EXIT ' : otm_exit,\n",
    "                                \"Remark\": remark,\n",
    "                                \"Points Captured\": points_captured,\n",
    "                                \"Slippage\": slippage,\n",
    "                                # 'OTM cost' : otm_exit-otm_entry,\n",
    "                                \"Qty\": qty,\n",
    "                                \"PnL\": pnl,\n",
    "                                \"ROI%\": (pnl / PORTFOLIO_VALUE) * 100,\n",
    "                                \"Trade Year\": pe_df.iloc[i][\"datetime\"].year,\n",
    "                                \"Trade Month\": pe_df.iloc[i][\"datetime\"].month,\n",
    "                                \"Highest High\": pe_highest_high,  # Add highest high to trade data\n",
    "                                \"Lowest Low\": pe_lowest_low,  # Add lowest low to trade data\n",
    "                                \"Max ROI%\": (\n",
    "                                    (qty * (entry - pe_lowest_low)) / PORTFOLIO_VALUE\n",
    "                                )\n",
    "                                * 100,\n",
    "                                \"Margin\": (\n",
    "                                    (qty * strike) / (INDEX_LEV * PORTFOLIO_VALUE)\n",
    "                                )\n",
    "                                * 100,\n",
    "                            }\n",
    "                            # print('apending initial sl trade')\n",
    "                            trade_book.append(trade)\n",
    "                            # tsl_high = 0\n",
    "                            points_captured = 0\n",
    "                            current_date = pe_df.iloc[i][\"datetime\"].date()\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = pe_df.iloc[i][\"datetime\"].time()\n",
    "                            # print(f'current date changed to : {current_date} and time to {time_of_day}')\n",
    "                            break\n",
    "\n",
    "                        if in_pe_trade and current_candle_high > initial_sl:\n",
    "                            # print(pe_df.iloc[i])\n",
    "                            # print(f'initial sl hit {initial_sl}')\n",
    "                            # print(f'initial sl datetime {pe_df.iloc[i][\"datetime\"]}')\n",
    "                            exit = initial_sl\n",
    "                            otm_datetime = pe_df.iloc[i][\"datetime\"]\n",
    "                            in_pe_trade = False\n",
    "                            stop_trading = False\n",
    "                            previous_pe_sl_hit = True\n",
    "                            is_gap_pe_sl = False\n",
    "                            points_captured = entry - exit\n",
    "                            exit_time = pe_df.iloc[i][\"datetime\"].time()\n",
    "                            slippage = SLIPPAGE * (entry + exit)\n",
    "                            pnl = qty * (points_captured - slippage)\n",
    "                            # pnl=(qty*(points_captured-slippage))-qty*(otm_exit-otm_entry)\n",
    "                            remark = \"SL hit\"\n",
    "                            weekday_int = entry_date.weekday()\n",
    "                            weekday_name = [\n",
    "                                \"Monday\",\n",
    "                                \"Tuesday\",\n",
    "                                \"Wednesday\",\n",
    "                                \"Thursday\",\n",
    "                                \"Friday\",\n",
    "                                \"Saturday\",\n",
    "                                \"Sunday\",\n",
    "                            ][weekday_int]\n",
    "                            trade = {\n",
    "                                \"date\": entry_date,\n",
    "                                \"day\": weekday_name,\n",
    "                                \"expiry\": expiry,\n",
    "                                \"DTE\": (nearest_expiry - entry_date).days,\n",
    "                                # 'atm' : atm,\n",
    "                                # 'scrip' : index ,\n",
    "                                \"strike\": strike,\n",
    "                                \"type\": asset_class,\n",
    "                                \"Entry Price\": entry,\n",
    "                                \"Entry Time\": entry_time,\n",
    "                                \"initial sl\": initial_sl,\n",
    "                                # \"TSL\": tsl_high,\n",
    "                                # 'OTM Entry' : otm_entry,\n",
    "                                \"Exit Price\": exit,\n",
    "                                \"Exit date\": pe_df.iloc[i][\"datetime\"].date(),\n",
    "                                \"Exit Time\": exit_time,\n",
    "                                'RSI on Entry': entry_rsi,\n",
    "                                # 'OTM EXIT ' : otm_exit,\n",
    "                                \"Remark\": remark,\n",
    "                                \"Points Captured\": points_captured,\n",
    "                                \"Slippage\": slippage,\n",
    "                                # 'OTM cost' : otm_exit-otm_entry,\n",
    "                                \"Qty\": qty,\n",
    "                                \"PnL\": pnl,\n",
    "                                \"ROI%\": (pnl / PORTFOLIO_VALUE) * 100,\n",
    "                                \"Trade Year\": pe_df.iloc[i][\"datetime\"].year,\n",
    "                                \"Trade Month\": pe_df.iloc[i][\"datetime\"].month,\n",
    "                                \"Highest High\": pe_highest_high,  # Add highest high to trade data\n",
    "                                \"Lowest Low\": pe_lowest_low,  # Add lowest low to trade data\n",
    "                                \"Max ROI%\": (\n",
    "                                    (qty * (entry - pe_lowest_low)) / PORTFOLIO_VALUE\n",
    "                                )\n",
    "                                * 100,\n",
    "                                \"Margin\": (\n",
    "                                    (qty * strike) / (INDEX_LEV * PORTFOLIO_VALUE)\n",
    "                                )\n",
    "                                * 100,\n",
    "                            }\n",
    "                            # print('apending initial sl trade')\n",
    "                            trade_book.append(trade)\n",
    "                            tsl_high = 0\n",
    "                            points_captured = 0\n",
    "                            current_date = pe_df.iloc[i][\"datetime\"].date()\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = pe_df.iloc[i][\"datetime\"].time()\n",
    "                            # print(f'current date changed to : {current_date} and time to {time_of_day}')\n",
    "                            break\n",
    "\n",
    "                        # if in_pe_trade and (current_candle_close > tsl_high) and (tsl_high > 10):\n",
    "                        #     # print(pe_df.iloc[i])\n",
    "                        #     # print(f'initial sl hit {initial_sl}')\n",
    "                        #     # print(f'initial sl datetime {pe_df.iloc[i][\"datetime\"]}')\n",
    "                        #     exit=current_candle_close\n",
    "                        #     otm_datetime = pe_df.iloc[i]['datetime']\n",
    "                        #     in_pe_trade=False\n",
    "                        #     stop_trading=False\n",
    "                        #     previous_pe_sl_hit=True\n",
    "                        #     is_gap_pe_sl = False\n",
    "                        #     points_captured=entry-exit\n",
    "                        #     exit_time = pe_df.iloc[i]['datetime'].time()\n",
    "                        #     slippage= SLIPPAGE * (entry+exit)\n",
    "                        #     pnl=(qty*(points_captured-slippage))\n",
    "                        #     # pnl=(qty*(points_captured-slippage))-qty*(otm_exit-otm_entry)\n",
    "                        #     remark = \"TSL hit\"\n",
    "                        #     weekday_int = entry_date.weekday()\n",
    "                        #     weekday_name = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"][weekday_int]\n",
    "                        #     trade = {\n",
    "                        #             'date' : entry_date,\n",
    "                        #             'day' : weekday_name,\n",
    "                        #             'expiry' : expiry,\n",
    "                        #             'DTE' : (nearest_expiry-entry_date).days,\n",
    "                        #             # 'atm' : atm,\n",
    "                        #             # 'scrip' : index ,\n",
    "                        #             'strike' : strike,\n",
    "                        #             'type' : asset_class,\n",
    "                        #             'Entry Price': entry,\n",
    "                        #             'Entry Time': entry_time,\n",
    "                        #             'initial sl' : initial_sl,\n",
    "                        #             'TSL' : tsl_high,\n",
    "                        #             # 'OTM Entry' : otm_entry,\n",
    "                        #             'Exit Price': exit,\n",
    "                        #             'Exit date' : pe_df.iloc[i]['datetime'].date(),\n",
    "                        #             'Exit Time': exit_time,\n",
    "                        #             # 'OTM EXIT ' : otm_exit,\n",
    "                        #             'Remark' : remark,\n",
    "                        #             'Points Captured': points_captured,\n",
    "                        #             'Slippage': slippage,\n",
    "                        #             # 'OTM cost' : otm_exit-otm_entry,\n",
    "                        #             'Qty': qty,\n",
    "                        #             'PnL' : pnl,\n",
    "                        #             'ROI%': (pnl/ PORTFOLIO_VALUE) * 100,\n",
    "                        #             'Trade Year': pe_df.iloc[i]['datetime'].year,\n",
    "                        #             'Trade Month': pe_df.iloc[i]['datetime'].month,\n",
    "                        #             'Highest High': pe_highest_high,  # Add highest high to trade data\n",
    "                        #             'Lowest Low': pe_lowest_low ,      # Add lowest low to trade data\n",
    "                        #             'Max ROI%' : ((qty*(entry-pe_lowest_low))/PORTFOLIO_VALUE)*100,\n",
    "                        #             'Margin' : ((qty*strike)/(INDEX_LEV*PORTFOLIO_VALUE))*100\n",
    "                        #               }\n",
    "                        #     # print('apending initial sl trade')\n",
    "                        #     trade_book.append(trade)\n",
    "                        #     tsl_high = 0\n",
    "                        #     points_captured=0\n",
    "                        #     current_date = pe_df.iloc[i]['datetime'].date()\n",
    "                        #     current_date_increament_flag = True\n",
    "                        #     time_of_day = pe_df.iloc[i]['datetime'].time()\n",
    "                        #     # print(f'current date changed to : {current_date} and time to {time_of_day}')\n",
    "                        #     break\n",
    "\n",
    "                        if (\n",
    "                            in_pe_trade\n",
    "                            and pe_df.iloc[i][\"datetime\"].date() == nearest_expiry\n",
    "                            and pe_df.iloc[i]['datetime'].time() >= dt.time(15, 20)\n",
    "                        ):\n",
    "                            # print(pe_df.iloc[i])\n",
    "                            # print(f'EOD exit {current_candle_close}')\n",
    "                            # print(f'EOD datetime {pe_df.iloc[i][\"datetime\"]}')\n",
    "                            exit = current_candle_close\n",
    "                            otm_datetime = pe_df.iloc[i][\"datetime\"]\n",
    "                            in_pe_trade = False\n",
    "                            previous_pe_sl_hit = True\n",
    "                            is_gap_pe_sl = False\n",
    "                            points_captured = entry - exit\n",
    "                            exit_time = pe_df.iloc[i][\"datetime\"].time()\n",
    "                            slippage = SLIPPAGE * (entry + exit)\n",
    "                            pnl = qty * (points_captured - slippage)\n",
    "                            # pnl=(qty*(points_captured-slippage))-qty*(otm_exit-otm_entry)\n",
    "                            remark = \"EOD exit\"\n",
    "                            weekday_int = entry_date.weekday()\n",
    "                            weekday_name = [\n",
    "                                \"Monday\",\n",
    "                                \"Tuesday\",\n",
    "                                \"Wednesday\",\n",
    "                                \"Thursday\",\n",
    "                                \"Friday\",\n",
    "                                \"Saturday\",\n",
    "                                \"Sunday\",\n",
    "                            ][weekday_int]\n",
    "                            trade = {\n",
    "                                \"date\": entry_date,\n",
    "                                \"day\": weekday_name,\n",
    "                                \"expiry\": expiry,\n",
    "                                \"DTE\": (nearest_expiry - entry_date).days,\n",
    "                                # 'atm' : atm,\n",
    "                                # 'scrip' : index ,\n",
    "                                \"strike\": strike,\n",
    "                                \"type\": asset_class,\n",
    "                                \"Entry Price\": entry,\n",
    "                                \"Entry Time\": entry_time,\n",
    "                                \"initial sl\": initial_sl,\n",
    "                                # \"TSL\": tsl_high,\n",
    "                                # 'OTM Entry' : otm_entry,\n",
    "                                \"Exit Price\": exit,\n",
    "                                \"Exit date\": pe_df.iloc[i][\"datetime\"].date(),\n",
    "                                \"Exit Time\": exit_time,\n",
    "                                'RSI on Entry': entry_rsi,\n",
    "                                # 'OTM EXIT ' : otm_exit,\n",
    "                                \"Remark\": remark,\n",
    "                                \"Points Captured\": points_captured,\n",
    "                                \"Slippage\": slippage,\n",
    "                                # 'OTM cost' : otm_exit-otm_entry,\n",
    "                                \"Qty\": qty,\n",
    "                                \"PnL\": pnl,\n",
    "                                \"ROI%\": (pnl / PORTFOLIO_VALUE) * 100,\n",
    "                                \"Trade Year\": pe_df.iloc[i][\"datetime\"].year,\n",
    "                                \"Trade Month\": pe_df.iloc[i][\"datetime\"].month,\n",
    "                                \"Highest High\": pe_highest_high,  # Add highest high to trade data\n",
    "                                \"Lowest Low\": pe_lowest_low,  # Add lowest low to trade data\n",
    "                                \"Max ROI%\": (\n",
    "                                    (qty * (entry - pe_lowest_low)) / PORTFOLIO_VALUE\n",
    "                                )\n",
    "                                * 100,\n",
    "                                \"Margin\": (\n",
    "                                    (qty * strike) / (INDEX_LEV * PORTFOLIO_VALUE)\n",
    "                                )\n",
    "                                * 100,\n",
    "                            }\n",
    "                            # print('apending EOD trade')\n",
    "                            trade_book.append(trade)\n",
    "                            # tsl_high = 0\n",
    "                            points_captured = 0\n",
    "                            current_date = nearest_expiry + dt.timedelta(days=1)\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = dt.time(9, 15)\n",
    "                            # print(f'current date increased by 1 on expiry : {current_date}')\n",
    "                            break\n",
    "\n",
    "                        if (\n",
    "                            not in_pe_trade\n",
    "                            and not previous_pe_sl_hit\n",
    "                            and pe_df.iloc[i][\"datetime\"].time() > dt.time(15, 00)\n",
    "                        ):\n",
    "                            # print('inside exoiry non trade date increment')\n",
    "                            current_date = current_date + dt.timedelta(days=1)\n",
    "                            current_date_increament_flag = True\n",
    "                            time_of_day = dt.time(9, 15)\n",
    "                            break\n",
    "\n",
    "        if not current_date_increament_flag:\n",
    "            current_date = current_date + dt.timedelta(days=1)\n",
    "            current_date_increament_flag = False\n",
    "\n",
    "    trade_book_df = pd.DataFrame(trade_book)\n",
    "\n",
    "    return trade_book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77077b44-6231-43d1-99c5-bda5d541a1cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:19:17.219028Z",
     "iopub.status.busy": "2025-01-02T22:19:17.217898Z",
     "iopub.status.idle": "2025-01-02T22:19:17.223645Z",
     "shell.execute_reply": "2025-01-02T22:19:17.222650Z",
     "shell.execute_reply.started": "2025-01-02T22:19:17.219000Z"
    }
   },
   "outputs": [],
   "source": [
    "async def execute(DF, n, rsi_n, rsi_overbought):\n",
    "    data = DF.copy()\n",
    "    tb_ce = await ce_trade(data, n, rsi_n, rsi_overbought)\n",
    "    tb_pe = await pe_trade(data, n, rsi_n, rsi_overbought)\n",
    "    tb = pd.concat([tb_ce, tb_pe], ignore_index=True)\n",
    "    # print(len(tb))\n",
    "    if len(tb)>0:\n",
    "        tb = tb.sort_values(by=\"date\")\n",
    "    return tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "663b049b-be11-42d9-a3d2-d1e40c2e2063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:19:17.510677Z",
     "iopub.status.busy": "2025-01-02T22:19:17.510415Z",
     "iopub.status.idle": "2025-01-02T22:19:17.518751Z",
     "shell.execute_reply": "2025-01-02T22:19:17.517656Z",
     "shell.execute_reply.started": "2025-01-02T22:19:17.510653Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_stats(tb_expiry, ema_window):\n",
    "    stats_df8 = pd.DataFrame(\n",
    "        index=range(2019, 2025),\n",
    "        columns=[\n",
    "            \"Total ROI\",\n",
    "            \"Total Trades\",\n",
    "            \"Win Rate\",\n",
    "            \"Avg Profit% per Trade\",\n",
    "            \"Avg Loss% per Trade\",\n",
    "            \"Max Drawdown\",\n",
    "            \"ROI/DD Ratio\",\n",
    "            \"Variation\",\n",
    "        ],\n",
    "    )\n",
    "    combined_df_sorted = tb_expiry\n",
    "    # combined_df_sorted = tb_expiry_ce\n",
    "    # combined_df_sorted = tb_expiry_pe\n",
    "\n",
    "    # Iterate over each year\n",
    "    for year in range(2019, 2025):\n",
    "        # Filter trades for the current year\n",
    "        year_trades = combined_df_sorted[(combined_df_sorted[\"Trade Year\"] == year)]\n",
    "\n",
    "        # Calculate total ROI\n",
    "        total_roi = year_trades[\"ROI%\"].sum()\n",
    "\n",
    "        # Calculate total number of trades\n",
    "        total_trades = len(year_trades)\n",
    "\n",
    "        # Calculate win rate\n",
    "        win_rate = (year_trades[\"ROI%\"] > 0).mean() * 100\n",
    "\n",
    "        # Calculate average profit per trade\n",
    "        avg_profit = year_trades[year_trades[\"ROI%\"] > 0][\"ROI%\"].mean()\n",
    "\n",
    "        # Calculate average loss per trade\n",
    "        avg_loss = year_trades[year_trades[\"ROI%\"] < 0][\"ROI%\"].mean()\n",
    "\n",
    "        # Calculate maximum drawdown\n",
    "        max_drawdown = (\n",
    "            year_trades[\"ROI%\"].cumsum() - year_trades[\"ROI%\"].cumsum().cummax()\n",
    "        ).min()\n",
    "\n",
    "        # Calculate ROI/DD ratio\n",
    "        roi_dd_ratio = total_roi / abs(max_drawdown)\n",
    "\n",
    "        variation = f\"{ema_window}\"\n",
    "\n",
    "        # Store the statistics in the DataFrame\n",
    "        stats_df8.loc[year] = [\n",
    "            total_roi,\n",
    "            total_trades,\n",
    "            win_rate,\n",
    "            avg_profit,\n",
    "            avg_loss,\n",
    "            max_drawdown,\n",
    "            roi_dd_ratio,\n",
    "            variation,\n",
    "        ]\n",
    "\n",
    "    # Calculate overall statistics\n",
    "    overall_total_roi = stats_df8[\"Total ROI\"].sum()\n",
    "    overall_total_trades = stats_df8[\"Total Trades\"].sum()\n",
    "    overall_win_rate = (combined_df_sorted[\"ROI%\"] > 0).mean() * 100\n",
    "    overall_avg_profit = combined_df_sorted[combined_df_sorted[\"ROI%\"] > 0][\n",
    "        \"ROI%\"\n",
    "    ].mean()\n",
    "    overall_avg_loss = combined_df_sorted[combined_df_sorted[\"ROI%\"] < 0][\"ROI%\"].mean()\n",
    "    overall_max_drawdown = (\n",
    "        combined_df_sorted[\"ROI%\"].cumsum()\n",
    "        - combined_df_sorted[\"ROI%\"].cumsum().cummax()\n",
    "    ).min()\n",
    "    overall_roi_dd_ratio = overall_total_roi / abs(overall_max_drawdown)\n",
    "    overall_variation = variation\n",
    "\n",
    "    # Store the overall statistics in the DataFrame\n",
    "    stats_df8.loc[\"Overall\"] = [\n",
    "        overall_total_roi,\n",
    "        overall_total_trades,\n",
    "        overall_win_rate,\n",
    "        overall_avg_profit,\n",
    "        overall_avg_loss,\n",
    "        overall_max_drawdown,\n",
    "        overall_roi_dd_ratio,\n",
    "        overall_variation,\n",
    "    ]\n",
    "    return {overall_roi_dd_ratio: stats_df8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4adc1620-bf18-4253-8cd7-5809d310870d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:19:19.712467Z",
     "iopub.status.busy": "2025-01-02T22:19:19.712113Z",
     "iopub.status.idle": "2025-01-02T22:19:19.716626Z",
     "shell.execute_reply": "2025-01-02T22:19:19.715634Z",
     "shell.execute_reply.started": "2025-01-02T22:19:19.712449Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # short_ma = 4\n",
    "# # long_ma = 12\n",
    "# # signal_window = 9\n",
    "# # ema_window = 25\n",
    "# n = 4\n",
    "# rsi_n = 6\n",
    "# rsi_overbought = 45\n",
    "\n",
    "# tb = await execute(data, 40, 50000, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e068665-2a21-4663-8b3a-5e95ec760338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:19:28.327881Z",
     "iopub.status.busy": "2025-01-02T22:19:28.327570Z",
     "iopub.status.idle": "2025-01-02T22:19:28.332853Z",
     "shell.execute_reply": "2025-01-02T22:19:28.331557Z",
     "shell.execute_reply.started": "2025-01-02T22:19:28.327860Z"
    }
   },
   "outputs": [],
   "source": [
    "# stats = generate_stats(tb, '...')\n",
    "# for x, y in stats.items():\n",
    "#     z = pd.DataFrame(y)\n",
    "#     break\n",
    "\n",
    "# z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e0635-2b9f-4233-af9a-6ef576c34884",
   "metadata": {},
   "source": [
    "# 5min BT Running for candle close below prev n candles low variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5984cd20-0fd3-4e6b-9726-ba27365d4eb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:19:40.269051Z",
     "iopub.status.busy": "2025-01-02T22:19:40.268538Z",
     "iopub.status.idle": "2025-01-02T22:19:40.273579Z",
     "shell.execute_reply": "2025-01-02T22:19:40.272479Z",
     "shell.execute_reply.started": "2025-01-02T22:19:40.269033Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e2b1cb2-31c5-4d0f-ba70-a8c7b9a98e75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:19:41.812245Z",
     "iopub.status.busy": "2025-01-02T22:19:41.811767Z",
     "iopub.status.idle": "2025-01-02T22:19:41.816348Z",
     "shell.execute_reply": "2025-01-02T22:19:41.815325Z",
     "shell.execute_reply.started": "2025-01-02T22:19:41.812225Z"
    }
   },
   "outputs": [],
   "source": [
    "# tb.to_csv('n_low_close_3min_40_0pt3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ce117-dd5e-41e3-b972-8c4e64176e37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:25:56.942020Z",
     "iopub.status.busy": "2025-01-02T22:25:56.941528Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12, 0.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35607/1336650796.py:146: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  qty = RPT_CE * PORTFOLIO_VALUE / (initial_sl - entry)\n",
      "/tmp/ipykernel_35607/1336650796.py:146: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  qty = RPT_CE * PORTFOLIO_VALUE / (initial_sl - entry)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Total ROI Total Trades Win Rate Avg Profit% per Trade Avg Loss% per Trade Max Drawdown ROI/DD Ratio Variation\n",
      "2019     164.4770          212  41.9811                5.6513             -2.7520     -24.4371       6.7306  12, 0.2%\n",
      "2020     215.7785          257  37.7432                7.1103             -2.9620     -31.5809       6.8326  12, 0.2%\n",
      "2021     132.6573          243  40.3292                5.6818             -2.9252     -27.1728       4.8820  12, 0.2%\n",
      "2022      25.7740          273  35.8974                6.1805             -3.3138     -73.1910       0.3521  12, 0.2%\n",
      "2023      81.1010          240  38.3333                5.2077             -2.6892     -27.9181       2.9050  12, 0.2%\n",
      "2024      43.0098          179  35.1955                5.8528             -2.8079     -38.5013       1.1171  12, 0.2%\n",
      "Overall  662.7976         1404  38.2479                5.9646             -2.9299     -73.1910       9.0557  12, 0.2%\n",
      "12, 0.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35607/1336650796.py:146: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  qty = RPT_CE * PORTFOLIO_VALUE / (initial_sl - entry)\n",
      "/tmp/ipykernel_35607/1336650796.py:146: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  qty = RPT_CE * PORTFOLIO_VALUE / (initial_sl - entry)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Total ROI Total Trades Win Rate Avg Profit% per Trade Avg Loss% per Trade Max Drawdown ROI/DD Ratio Variation\n",
      "2019     164.4770          212  41.9811                5.6513             -2.7520     -24.0668       6.8342  12, 0.3%\n",
      "2020     217.4779          256  37.8906                7.1103             -2.9699     -29.4899       7.3747  12, 0.3%\n",
      "2021     132.0851          240  40.0000                5.7916             -2.9438     -28.6066       4.6173  12, 0.3%\n",
      "2022      21.2725          274  35.4015                6.2589             -3.3098     -63.9412       0.3327  12, 0.3%\n",
      "2023      80.7832          239  38.0753                5.2614             -2.6892     -29.8927       2.7024  12, 0.3%\n",
      "2024      42.2941          178  34.8315                5.9357             -2.8079     -38.5013       1.0985  12, 0.3%\n",
      "Overall  658.3900         1399  38.0272                6.0199             -2.9345     -63.9412      10.2968  12, 0.3%\n",
      "12, 0.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35607/1336650796.py:146: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  qty = RPT_CE * PORTFOLIO_VALUE / (initial_sl - entry)\n",
      "/tmp/ipykernel_35607/1336650796.py:146: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  qty = RPT_CE * PORTFOLIO_VALUE / (initial_sl - entry)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Total ROI Total Trades Win Rate Avg Profit% per Trade Avg Loss% per Trade Max Drawdown ROI/DD Ratio Variation\n",
      "2019     163.6776          211  42.1801                5.6369             -2.7705     -25.1504       6.5079  12, 0.4%\n",
      "2020     213.5016          253  37.9447                7.1091             -2.9871     -21.7309       9.8248  12, 0.4%\n",
      "2021     128.4473          241  39.8340                5.7938             -2.9501     -28.6200       4.4880  12, 0.4%\n",
      "2022      11.6413          270  35.5556                6.1908             -3.3487     -67.9608       0.1713  12, 0.4%\n",
      "2023      80.2462          235  37.4468                5.4252             -2.7018     -30.0696       2.6687  12, 0.4%\n",
      "2024      41.9677          175  34.2857                6.1009             -2.8182     -37.8785       1.1080  12, 0.4%\n",
      "Overall  639.4817         1385  37.9061                6.0536             -2.9519     -67.9608       9.4096  12, 0.4%\n",
      "12, 0.5%\n"
     ]
    }
   ],
   "source": [
    "#10min\n",
    "stats_dictionary = {}\n",
    "for i in range(12, 49, 4):\n",
    "    for j in range(20, 71, 10):\n",
    "        print(f'{i}, {j/100}%')\n",
    "        tb = await execute(data, i, 5, j/100)\n",
    "        if len(tb) > 0:\n",
    "            stats = generate_stats(tb, f'{i}, {j/100}%')\n",
    "            for x, y in stats.items():\n",
    "                z = pd.DataFrame(y)\n",
    "                print(z.to_string())\n",
    "                stats_dictionary[x] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e21f57e-b215-4d10-9d3c-6f4fcac949dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sum_roi_by_dte(tb):\n",
    "    \"\"\"\n",
    "    Plots the sum of ROI% across all unique DTE values.\n",
    "\n",
    "    Parameters:\n",
    "    tb (pd.DataFrame): Input DataFrame with 'DTE' and 'ROI%' columns.\n",
    "    \"\"\"\n",
    "    # Ensure the DataFrame contains the required columns\n",
    "    required_columns = {'DTE', 'ROI%'}\n",
    "    if not required_columns.issubset(tb.columns):\n",
    "        raise ValueError(f\"Input DataFrame must contain columns: {required_columns}\")\n",
    "    \n",
    "    # Group by DTE and calculate the sum of ROI%\n",
    "    result = tb.groupby('DTE', as_index=False)['ROI%'].sum()\n",
    "    result.rename(columns={'ROI%': 'Sum_ROI%'}, inplace=True)\n",
    "\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(result['DTE'], result['Sum_ROI%'], color='skyblue', edgecolor='black')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.title('Sum of ROI% Across Unique DTE Values', fontsize=14)\n",
    "    plt.xlabel('DTE', fontsize=12)\n",
    "    plt.ylabel('Sum of ROI%', fontsize=12)\n",
    "    plt.xticks(rotation=45, fontsize=10)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# tb = pd.DataFrame({'DTE': [...], 'ROI%': [...]})  # Replace with your actual DataFrame\n",
    "plot_sum_roi_by_dte(tb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "64778897-2449-4d1c-96b9-14f2801b2bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:01:57.496709Z",
     "iopub.status.busy": "2025-01-02T21:01:57.496405Z",
     "iopub.status.idle": "2025-01-02T21:01:57.501289Z",
     "shell.execute_reply": "2025-01-02T21:01:57.500391Z",
     "shell.execute_reply.started": "2025-01-02T21:01:57.496689Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_max_dd(tb):\n",
    "    \"\"\"\n",
    "    Calculates the maximum drawdown for each group of 'DTE'.\n",
    "    \n",
    "    Parameters:\n",
    "    tb (pd.DataFrame): Input DataFrame with 'DTE' and 'ROI%' columns.\n",
    "    \n",
    "    Returns:\n",
    "    pd.Series: Maximum drawdown for each unique DTE.\n",
    "    \"\"\"\n",
    "    # Calculate cumulative sum of ROI%\n",
    "    cumulative_returns = tb[\"ROI%\"].cumsum()\n",
    "    \n",
    "    # Calculate maximum drawdown\n",
    "    max_drawdown = (cumulative_returns - cumulative_returns.cummax()).min()\n",
    "    \n",
    "    return max_drawdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c6b5a-a7a7-4d82-806a-a25e9d0fcd6f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_sum_roi_and_max_dd_by_dte(tb):\n",
    "    \"\"\"\n",
    "    Plots the sum of ROI% and Absolute Max Drawdown (Max DD) across all unique DTE values\n",
    "    using a single Y-axis, and prints the resulting DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    tb (pd.DataFrame): Input DataFrame with 'DTE' and 'ROI%' columns.\n",
    "    \"\"\"\n",
    "    # Ensure the DataFrame contains the required columns\n",
    "    required_columns = {'DTE', 'ROI%'}\n",
    "    if not required_columns.issubset(tb.columns):\n",
    "        raise ValueError(f\"Input DataFrame must contain columns: {required_columns}\")\n",
    "    \n",
    "    # Group by DTE and calculate the sum of ROI%\n",
    "    roi_result = tb.groupby('DTE', as_index=False)['ROI%'].sum()\n",
    "    roi_result.rename(columns={'ROI%': 'Sum_ROI%'}, inplace=True)\n",
    "\n",
    "    # Group by DTE and calculate Max DD (in absolute terms)\n",
    "    dd_result = tb.groupby('DTE').apply(calculate_max_dd).reset_index()\n",
    "    dd_result.rename(columns={0: 'Max_DD%'}, inplace=True)\n",
    "    dd_result['Max_DD%'] = dd_result['Max_DD%'].abs()\n",
    "\n",
    "    # Merge the sum of ROI% and Max DD data\n",
    "    result = pd.merge(roi_result, dd_result, on='DTE')\n",
    "\n",
    "    # Add ROI% / Max DD ratio\n",
    "    result['ROI/DD_Ratio'] = result.apply(\n",
    "        lambda row: row['Sum_ROI%'] / row['Max_DD%'] if row['Max_DD%'] != 0 else float('inf'), axis=1\n",
    "    )\n",
    "\n",
    "    # Format values\n",
    "    result['Sum_ROI%'] = result['Sum_ROI%'].round(2)\n",
    "    result['Max_DD%'] = result['Max_DD%'].round(2)\n",
    "    result['ROI/DD_Ratio'] = result['ROI/DD_Ratio'].round(2)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(\"\\nResulting DataFrame:\")\n",
    "    print(result)\n",
    "\n",
    "    # Plot the data\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot Sum of ROI%\n",
    "    ax.bar(result['DTE'], result['Sum_ROI%'], color='skyblue', edgecolor='black', label='Sum of ROI%', width=0.4, align='center')\n",
    "    \n",
    "    # Overlay Max DD (absolute values) on the same axis\n",
    "    ax.plot(result['DTE'], result['Max_DD%'], color='red', marker='o', label='Max Drawdown (absolute)', linestyle='--', linewidth=2)\n",
    "\n",
    "    ax.set_xlabel('DTE', fontsize=12)\n",
    "    ax.set_ylabel('Values', fontsize=12)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Title, legend, and grid\n",
    "    plt.title('Sum of ROI%, Absolute Max Drawdown, and ROI/DD Ratio', fontsize=14)\n",
    "    ax.legend(loc='upper left', fontsize=10)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Show the plot\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_sum_roi_and_max_dd_by_dte(tb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b8dd1-e46d-478c-8891-c31882e8c494",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_sum_roi_and_max_dd_by_dte(tb):\n",
    "    \"\"\"\n",
    "    Plots the sum of ROI% and Absolute Max Drawdown (Max DD) across all unique DTE values\n",
    "    using a single Y-axis, and prints the resulting DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    tb (pd.DataFrame): Input DataFrame with 'DTE' and 'ROI%' columns.\n",
    "    \"\"\"\n",
    "    # Ensure the DataFrame contains the required columns\n",
    "    required_columns = {'DTE', 'ROI%'}\n",
    "    if not required_columns.issubset(tb.columns):\n",
    "        raise ValueError(f\"Input DataFrame must contain columns: {required_columns}\")\n",
    "    \n",
    "    # Group by DTE and calculate the sum of ROI%\n",
    "    roi_result = tb.groupby('DTE', as_index=False)['ROI%'].sum()\n",
    "    roi_result.rename(columns={'ROI%': 'Sum_ROI%'}, inplace=True)\n",
    "\n",
    "    # Group by DTE and calculate Max DD (in absolute terms)\n",
    "    dd_result = tb.groupby('DTE').apply(calculate_max_dd).reset_index()\n",
    "    dd_result.rename(columns={0: 'Max_DD%'}, inplace=True)\n",
    "    dd_result['Max_DD%'] = dd_result['Max_DD%'].abs()\n",
    "\n",
    "    # Merge the sum of ROI% and Max DD data\n",
    "    result = pd.merge(roi_result, dd_result, on='DTE')\n",
    "\n",
    "    # Add ROI% / Max DD ratio\n",
    "    result['ROI/DD_Ratio'] = result.apply(\n",
    "        lambda row: row['Sum_ROI%'] / row['Max_DD%'] if row['Max_DD%'] != 0 else float('inf'), axis=1\n",
    "    )\n",
    "\n",
    "    # Format values\n",
    "    result['Sum_ROI%'] = result['Sum_ROI%'].round(2)\n",
    "    result['Max_DD%'] = result['Max_DD%'].round(2)\n",
    "    result['ROI/DD_Ratio'] = result['ROI/DD_Ratio'].round(2)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(\"\\nResulting DataFrame:\")\n",
    "    print(result)\n",
    "\n",
    "    # Plot the data\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot Sum of ROI%\n",
    "    ax.bar(result['DTE'], result['Sum_ROI%'], color='skyblue', edgecolor='black', label='Sum of ROI%', width=0.4, align='center')\n",
    "    \n",
    "    # Overlay Max DD (absolute values) on the same axis\n",
    "    ax.plot(result['DTE'], result['Max_DD%'], color='red', marker='o', label='Max Drawdown (absolute)', linestyle='--', linewidth=2)\n",
    "\n",
    "    ax.set_xlabel('DTE', fontsize=12)\n",
    "    ax.set_ylabel('Values', fontsize=12)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Title, legend, and grid\n",
    "    plt.title('Sum of ROI%, Absolute Max Drawdown, and ROI/DD Ratio', fontsize=14)\n",
    "    ax.legend(loc='upper left', fontsize=10)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Show the plot\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_sum_roi_and_max_dd_by_dte(tb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609941f7-aa2d-4b32-9b08-2dd521614e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
