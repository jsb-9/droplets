{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea141014-2dac-4228-b25f-9ff1d70e7043",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T05:03:44.178273Z",
     "iopub.status.busy": "2025-03-27T05:03:44.177359Z",
     "iopub.status.idle": "2025-03-27T05:03:44.526315Z",
     "shell.execute_reply": "2025-03-27T05:03:44.525423Z",
     "shell.execute_reply.started": "2025-03-27T05:03:44.178248Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal\n",
    "import plotly.graph_objects as go\n",
    "import polars as pl\n",
    "from dash import Dash, dcc, html\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "nse = mcal.get_calendar(\"NSE\")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 25_000)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pl.Config.set_tbl_cols(500)\n",
    "pl.Config.set_tbl_rows(10_000)\n",
    "\n",
    "pd.options.display.float_format = \"{:.4f}\".format\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from tooling.enums import AssetClass, Index, Spot, StrikeSpread\n",
    "from tooling.fetch import fetch_option_data, fetch_spot_data\n",
    "from tooling.filter import find_atm, option_tool\n",
    "\n",
    "from fetching_from_local_db.enums import AssetClass, Index, StrikeSpread\n",
    "from fetching_from_local_db.fetch_from_db import (\n",
    "    _fetch_batch,\n",
    "    fetch_data,\n",
    "    fetch_spot_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9630589e-6c73-4fcd-8e14-4f87baf52af5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:44:15.534941Z",
     "iopub.status.busy": "2025-03-27T04:44:15.534450Z",
     "iopub.status.idle": "2025-03-27T04:44:16.171431Z",
     "shell.execute_reply": "2025-03-27T04:44:16.170243Z",
     "shell.execute_reply.started": "2025-03-27T04:44:15.534924Z"
    }
   },
   "outputs": [],
   "source": [
    "bnf_pandas = pd.read_csv(\"../data/indices/NIFTY BANK.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af80ad7-eabf-4c62-97c3-0e9be32210f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:44:20.232938Z",
     "iopub.status.busy": "2025-03-27T04:44:20.232434Z",
     "iopub.status.idle": "2025-03-27T04:44:20.237741Z",
     "shell.execute_reply": "2025-03-27T04:44:20.236962Z",
     "shell.execute_reply.started": "2025-03-27T04:44:20.232916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# symbol = 'midcp'\n",
    "# symbol = 'nifty'\n",
    "# symbol = 'fnf'\n",
    "symbol = 'bnf'\n",
    "# symbol = 'sensex'\n",
    "# symbol = 'bankex'\n",
    "\n",
    "if symbol == 'bnf' or symbol == 'bankex':\n",
    "    LEVERAGE_ = 5\n",
    "    LOT_SIZE_ = 15\n",
    "    SLIPPAGE_ = 0.0001\n",
    "elif symbol == 'nifty' or symbol == 'fnf':\n",
    "    LEVERAGE_ = 7\n",
    "    LOT_SIZE_ = 25\n",
    "    SLIPPAGE_ = 0.0002\n",
    "elif symbol == 'midcp':\n",
    "    LEVERAGE_ = 8\n",
    "    LOT_SIZE_ = 50\n",
    "    SLIPPAGE_ = 0.0005\n",
    "elif symbol == 'sensex':\n",
    "    LEVERAGE_ = 8\n",
    "    LOT_SIZE_ = 10\n",
    "    SLIPPAGE_ = 0.0001\n",
    "\n",
    "PORTFOLIO = 1000000\n",
    "print(LEVERAGE_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f918f2-721d-4b5d-8c42-94a15895b5c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:44:32.062128Z",
     "iopub.status.busy": "2025-03-27T04:44:32.061715Z",
     "iopub.status.idle": "2025-03-27T04:44:32.084316Z",
     "shell.execute_reply": "2025-03-27T04:44:32.083557Z",
     "shell.execute_reply.started": "2025-03-27T04:44:32.062103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>o</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-02T09:15:00.000000</td>\n",
       "      <td>18242.3000</td>\n",
       "      <td>18248.2000</td>\n",
       "      <td>18175.9000</td>\n",
       "      <td>18181.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-02T09:16:00.000000</td>\n",
       "      <td>18181.8500</td>\n",
       "      <td>18194.7000</td>\n",
       "      <td>18179.9500</td>\n",
       "      <td>18184.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-02T09:17:00.000000</td>\n",
       "      <td>18184.9500</td>\n",
       "      <td>18189.2500</td>\n",
       "      <td>18133.8000</td>\n",
       "      <td>18133.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-02T09:18:00.000000</td>\n",
       "      <td>18135.1000</td>\n",
       "      <td>18141.5500</td>\n",
       "      <td>18118.5500</td>\n",
       "      <td>18138.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-02T09:19:00.000000</td>\n",
       "      <td>18138.9500</td>\n",
       "      <td>18142.5500</td>\n",
       "      <td>18120.4500</td>\n",
       "      <td>18124.3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     datetime          o          h          l          c\n",
       "0  2017-01-02T09:15:00.000000 18242.3000 18248.2000 18175.9000 18181.2000\n",
       "1  2017-01-02T09:16:00.000000 18181.8500 18194.7000 18179.9500 18184.4500\n",
       "2  2017-01-02T09:17:00.000000 18184.9500 18189.2500 18133.8000 18133.8000\n",
       "3  2017-01-02T09:18:00.000000 18135.1000 18141.5500 18118.5500 18138.9500\n",
       "4  2017-01-02T09:19:00.000000 18138.9500 18142.5500 18120.4500 18124.3000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnf_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550bfa0a-d76a-42b7-9de7-fd7951842782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:44:36.502933Z",
     "iopub.status.busy": "2025-03-27T04:44:36.502545Z",
     "iopub.status.idle": "2025-03-27T04:44:36.659067Z",
     "shell.execute_reply": "2025-03-27T04:44:36.657774Z",
     "shell.execute_reply.started": "2025-03-27T04:44:36.502907Z"
    }
   },
   "outputs": [],
   "source": [
    "# If Stocks Data ...\n",
    "bnf_pandas[\"datetime\"] = pd.to_datetime(bnf_pandas[\"datetime\"])\n",
    "bnf_pandas[\"datetime\"] = bnf_pandas[\"datetime\"].dt.tz_localize(None)\n",
    "bnf_pandas = bnf_pandas[bnf_pandas[\"datetime\"].dt.year >= 2017]\n",
    "# bnf_pandas.drop(columns=[\"datetime\"], inplace=True)\n",
    "# bnf_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9044f54e-f8c4-4248-b1e3-d333cb7ed2d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:44:41.041039Z",
     "iopub.status.busy": "2025-03-27T04:44:41.040777Z",
     "iopub.status.idle": "2025-03-27T04:44:41.149470Z",
     "shell.execute_reply": "2025-03-27T04:44:41.148351Z",
     "shell.execute_reply.started": "2025-03-27T04:44:41.041018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'polars.dataframe.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "bnf = pl.DataFrame(bnf_pandas)\n",
    "print(type(bnf))\n",
    "# bnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "440a2f80-fd77-4920-b53e-d67c2469dfbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:44:45.311714Z",
     "iopub.status.busy": "2025-03-27T04:44:45.311356Z",
     "iopub.status.idle": "2025-03-27T04:44:45.342849Z",
     "shell.execute_reply": "2025-03-27T04:44:45.341544Z",
     "shell.execute_reply.started": "2025-03-27T04:44:45.311692Z"
    }
   },
   "outputs": [],
   "source": [
    "bnf = bnf.with_columns([pl.col(\"datetime\").alias(\"index\")]).drop(\"datetime\")\n",
    "bnf = bnf.with_columns(pl.col(\"index\").alias(\"datetime\"))\n",
    "bnf.tail()\n",
    "bnf_pandas = bnf.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d46196-7fb0-42aa-b216-35b1537a7a38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:44:49.980815Z",
     "iopub.status.busy": "2025-03-27T04:44:49.979900Z",
     "iopub.status.idle": "2025-03-27T04:44:49.985708Z",
     "shell.execute_reply": "2025-03-27T04:44:49.984566Z",
     "shell.execute_reply.started": "2025-03-27T04:44:49.980792Z"
    }
   },
   "outputs": [],
   "source": [
    "def resample(\n",
    "    data: pl.DataFrame, timeframe, offset: dt.timedelta | None = None\n",
    ") -> pl.DataFrame:\n",
    "    return (\n",
    "        data.set_sorted(\"datetime\")\n",
    "        .group_by_dynamic(\n",
    "            index_column=\"datetime\",\n",
    "            every=timeframe,\n",
    "            period=timeframe,\n",
    "            label=\"left\",\n",
    "            offset=offset,\n",
    "        )\n",
    "        .agg(\n",
    "            [\n",
    "                pl.col(\"o\").first().alias(\"o\"),\n",
    "                pl.col(\"h\").max().alias(\"h\"),\n",
    "                pl.col(\"l\").min().alias(\"l\"),\n",
    "                pl.col(\"c\").last().alias(\"c\"),\n",
    "                # pl.col(\"volume\").sum().alias(\"volume\"),\n",
    "            ]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24405aef-e273-4419-b074-6896ceacaccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:46:50.060877Z",
     "iopub.status.busy": "2025-03-27T04:46:50.060257Z",
     "iopub.status.idle": "2025-03-27T04:46:50.067876Z",
     "shell.execute_reply": "2025-03-27T04:46:50.066829Z",
     "shell.execute_reply.started": "2025-03-27T04:46:50.060856Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_stats(tb_expiry, variation):\n",
    "    stats_df8 = pd.DataFrame(\n",
    "        index=range(2017, 2026),\n",
    "        columns=[\n",
    "            \"Total ROI\",\n",
    "            \"Total Trades\",\n",
    "            \"Win Rate\",\n",
    "            \"Avg Profit% per Trade\",\n",
    "            \"Avg Loss% per Trade\",\n",
    "            \"Max Drawdown\",\n",
    "            \"ROI/DD Ratio\",\n",
    "            \"Variation\",\n",
    "        ],\n",
    "    )\n",
    "    combined_df_sorted = tb_expiry\n",
    "    # combined_df_sorted = tb_expiry_ce\n",
    "    # combined_df_sorted = tb_expiry_pe\n",
    "    \n",
    "    # Iterate over each year\n",
    "    for year in range(2017, 2026):\n",
    "        # Filter trades for the current year\n",
    "        year_trades = combined_df_sorted[(combined_df_sorted[\"Trade Year\"] == year)]\n",
    "    \n",
    "        # Calculate total ROI\n",
    "        total_roi = year_trades[\"ROI%\"].sum()\n",
    "    \n",
    "        # Calculate total number of trades\n",
    "        total_trades = len(year_trades)\n",
    "    \n",
    "        # Calculate win rate\n",
    "        win_rate = (year_trades[\"ROI%\"] > 0).mean() * 100\n",
    "    \n",
    "        # Calculate average profit per trade\n",
    "        avg_profit = year_trades[year_trades[\"ROI%\"] > 0][\"ROI%\"].mean()\n",
    "    \n",
    "        # Calculate average loss per trade\n",
    "        avg_loss = year_trades[year_trades[\"ROI%\"] < 0][\"ROI%\"].mean()\n",
    "    \n",
    "        # Calculate maximum drawdown\n",
    "        max_drawdown = (\n",
    "            year_trades[\"ROI%\"].cumsum() - year_trades[\"ROI%\"].cumsum().cummax()\n",
    "        ).min()\n",
    "    \n",
    "        # Calculate ROI/DD ratio\n",
    "        roi_dd_ratio = total_roi / abs(max_drawdown)\n",
    "\n",
    "        variation = variation\n",
    "    \n",
    "        # Store the statistics in the DataFrame\n",
    "        stats_df8.loc[year] = [\n",
    "            total_roi,\n",
    "            total_trades,\n",
    "            win_rate,\n",
    "            avg_profit,\n",
    "            avg_loss,\n",
    "            max_drawdown,\n",
    "            roi_dd_ratio,\n",
    "            variation,\n",
    "        ]\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    overall_total_roi = stats_df8[\"Total ROI\"].sum()\n",
    "    overall_total_trades = stats_df8[\"Total Trades\"].sum()\n",
    "    overall_win_rate = (combined_df_sorted[\"ROI%\"] > 0).mean() * 100\n",
    "    overall_avg_profit = combined_df_sorted[combined_df_sorted[\"ROI%\"] > 0][\"ROI%\"].mean()\n",
    "    overall_avg_loss = combined_df_sorted[combined_df_sorted[\"ROI%\"] < 0][\"ROI%\"].mean()\n",
    "    overall_max_drawdown = (\n",
    "        combined_df_sorted[\"ROI%\"].cumsum() - combined_df_sorted[\"ROI%\"].cumsum().cummax()\n",
    "    ).min()\n",
    "    overall_roi_dd_ratio = overall_total_roi / abs(overall_max_drawdown)\n",
    "    overall_variation = variation\n",
    "    \n",
    "    # Store the overall statistics in the DataFrame\n",
    "    stats_df8.loc[\"Overall\"] = [\n",
    "        overall_total_roi,\n",
    "        overall_total_trades,\n",
    "        overall_win_rate,\n",
    "        overall_avg_profit,\n",
    "        overall_avg_loss,\n",
    "        overall_max_drawdown,\n",
    "        overall_roi_dd_ratio,\n",
    "        overall_variation,\n",
    "    ]\n",
    "    return {overall_roi_dd_ratio : stats_df8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b08f43e9-699d-47db-9414-1d05d8b0b4c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:46:39.560868Z",
     "iopub.status.busy": "2025-03-27T04:46:39.560517Z",
     "iopub.status.idle": "2025-03-27T04:46:39.568597Z",
     "shell.execute_reply": "2025-03-27T04:46:39.567812Z",
     "shell.execute_reply.started": "2025-03-27T04:46:39.560852Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_stats_options(tb_expiry, variation):\n",
    "    stats_df8 = pd.DataFrame(\n",
    "        index=range(2017, 2026),\n",
    "        columns=[\n",
    "            \"Total ROI\",\n",
    "            \"Total Trades\",\n",
    "            \"Win Rate\",\n",
    "            \"Avg Profit% per Trade\",\n",
    "            \"Avg Loss% per Trade\",\n",
    "            \"Max Drawdown\",\n",
    "            \"ROI/DD Ratio\",\n",
    "            \"Variation\",\n",
    "        ],\n",
    "    )\n",
    "    combined_df_sorted = tb_expiry\n",
    "    # combined_df_sorted = tb_expiry_ce\n",
    "    # combined_df_sorted = tb_expiry_pe\n",
    "    \n",
    "    # Iterate over each year\n",
    "    for year in range(2017, 2026):\n",
    "        # Filter trades for the current year\n",
    "        year_trades = combined_df_sorted[(combined_df_sorted[\"Trade Year\"] == year)]\n",
    "    \n",
    "        # Calculate total ROI\n",
    "        total_roi = year_trades[\"Opt ROI%\"].sum()\n",
    "    \n",
    "        # Calculate total number of trades\n",
    "        total_trades = len(year_trades)\n",
    "    \n",
    "        # Calculate win rate\n",
    "        win_rate = (year_trades[\"Opt ROI%\"] > 0).mean() * 100\n",
    "    \n",
    "        # Calculate average profit per trade\n",
    "        avg_profit = year_trades[year_trades[\"Opt ROI%\"] > 0][\"Opt ROI%\"].mean()\n",
    "    \n",
    "        # Calculate average loss per trade\n",
    "        avg_loss = year_trades[year_trades[\"Opt ROI%\"] < 0][\"Opt ROI%\"].mean()\n",
    "    \n",
    "        # Calculate maximum drawdown\n",
    "        max_drawdown = (\n",
    "            year_trades[\"Opt ROI%\"].cumsum() - year_trades[\"Opt ROI%\"].cumsum().cummax()\n",
    "        ).min()\n",
    "    \n",
    "        # Calculate ROI/DD ratio\n",
    "        roi_dd_ratio = total_roi / abs(max_drawdown)\n",
    "\n",
    "        variation = variation\n",
    "    \n",
    "        # Store the statistics in the DataFrame\n",
    "        stats_df8.loc[year] = [\n",
    "            total_roi,\n",
    "            total_trades,\n",
    "            win_rate,\n",
    "            avg_profit,\n",
    "            avg_loss,\n",
    "            max_drawdown,\n",
    "            roi_dd_ratio,\n",
    "            variation,\n",
    "        ]\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    overall_total_roi = stats_df8[\"Total ROI\"].sum()\n",
    "    overall_total_trades = stats_df8[\"Total Trades\"].sum()\n",
    "    overall_win_rate = (combined_df_sorted[\"Opt ROI%\"] > 0).mean() * 100\n",
    "    overall_avg_profit = combined_df_sorted[combined_df_sorted[\"Opt ROI%\"] > 0][\"Opt ROI%\"].mean()\n",
    "    overall_avg_loss = combined_df_sorted[combined_df_sorted[\"Opt ROI%\"] < 0][\"Opt ROI%\"].mean()\n",
    "    overall_max_drawdown = (\n",
    "        combined_df_sorted[\"Opt ROI%\"].cumsum() - combined_df_sorted[\"Opt ROI%\"].cumsum().cummax()\n",
    "    ).min()\n",
    "    overall_roi_dd_ratio = overall_total_roi / abs(overall_max_drawdown)\n",
    "    overall_variation = variation\n",
    "    \n",
    "    # Store the overall statistics in the DataFrame\n",
    "    stats_df8.loc[\"Overall\"] = [\n",
    "        overall_total_roi,\n",
    "        overall_total_trades,\n",
    "        overall_win_rate,\n",
    "        overall_avg_profit,\n",
    "        overall_avg_loss,\n",
    "        overall_max_drawdown,\n",
    "        overall_roi_dd_ratio,\n",
    "        overall_variation,\n",
    "    ]\n",
    "    return {overall_roi_dd_ratio : stats_df8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6527d579-e961-4d0b-9e19-fa6c29d466ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:53:43.277552Z",
     "iopub.status.busy": "2025-03-27T04:53:43.277044Z",
     "iopub.status.idle": "2025-03-27T04:53:43.294985Z",
     "shell.execute_reply": "2025-03-27T04:53:43.294101Z",
     "shell.execute_reply.started": "2025-03-27T04:53:43.277527Z"
    }
   },
   "outputs": [],
   "source": [
    "from expiries import dict_expiries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c429b345-e730-4aec-9626-edecb8505798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:58:16.729648Z",
     "iopub.status.busy": "2025-03-27T04:58:16.729333Z",
     "iopub.status.idle": "2025-03-27T04:58:16.733753Z",
     "shell.execute_reply": "2025-03-27T04:58:16.733051Z",
     "shell.execute_reply.started": "2025-03-27T04:58:16.729632Z"
    }
   },
   "outputs": [],
   "source": [
    "TF_ = '15m'\n",
    "TF_int = 15\n",
    "OPT_SLIPPAGE_ = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e0b027-d17e-422d-bcd6-15a417a9f1a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:47:23.372891Z",
     "iopub.status.busy": "2025-03-27T04:47:23.372331Z",
     "iopub.status.idle": "2025-03-27T04:47:23.403482Z",
     "shell.execute_reply": "2025-03-27T04:47:23.402330Z",
     "shell.execute_reply.started": "2025-03-27T04:47:23.372871Z"
    }
   },
   "outputs": [],
   "source": [
    "bnf2 = resample(bnf, TF_)\n",
    "bnf_pandas = bnf2.to_pandas()\n",
    "bnf_pandas.rename(columns={'o': 'open', 'h': 'high', 'l': 'low', 'c': 'close'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a11ba51f-d4c3-4072-bdd1-ad4959a47b97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:53:31.557082Z",
     "iopub.status.busy": "2025-03-27T04:53:31.556012Z",
     "iopub.status.idle": "2025-03-27T04:53:31.561986Z",
     "shell.execute_reply": "2025-03-27T04:53:31.561148Z",
     "shell.execute_reply.started": "2025-03-27T04:53:31.557051Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_monthly_expiry(entry_time, index_expiries):\n",
    "    \"\"\"Get the nearest monthly expiry based on entry time.\"\"\"\n",
    "    expiry_df = pd.DataFrame({\"expiry\": index_expiries})\n",
    "    \n",
    "    # Convert date back to datetime to use .dt accessor\n",
    "    expiry_df[\"expiry\"] = pd.to_datetime(expiry_df[\"expiry\"])\n",
    "\n",
    "    expiry_df[\"year_month\"] = expiry_df[\"expiry\"].dt.to_period(\"M\")\n",
    "\n",
    "    # Extract the last expiry for each month\n",
    "    monthly_expiries = expiry_df.groupby(\"year_month\")[\"expiry\"].max().values\n",
    "\n",
    "    # Get the next expiry after entry_time\n",
    "    next_expiry = next((exp for exp in monthly_expiries if exp >= entry_time), None)\n",
    "\n",
    "    return pd.Timestamp(next_expiry).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86ae1a6e-46e0-4afb-99ef-f102ed471943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:49:07.451848Z",
     "iopub.status.busy": "2025-03-27T04:49:07.450716Z",
     "iopub.status.idle": "2025-03-27T04:49:07.457459Z",
     "shell.execute_reply": "2025-03-27T04:49:07.456343Z",
     "shell.execute_reply.started": "2025-03-27T04:49:07.451795Z"
    }
   },
   "outputs": [],
   "source": [
    "def ma_crossover_logic(df, fast_ma, slow_ma):\n",
    "    df['close'] = pd.to_numeric(df['close'], errors='coerce')\n",
    "    \n",
    "    fast_ema = df['close'].rolling(fast_ma).mean()\n",
    "    slow_ema = df['close'].rolling(slow_ma).mean()\n",
    "    df['fast_ma'] = fast_ema\n",
    "    df['slow_ma'] = slow_ema\n",
    "    \n",
    "    df['signal'] = 0  # Default to no signal\n",
    "    df.loc[fast_ema > slow_ema, 'signal'] = 1   # Long Signal\n",
    "    df.loc[fast_ema < slow_ema, 'signal'] = -1  # Short Signal\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be27c629-5d87-412c-b418-25ece92f1824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:49:14.807086Z",
     "iopub.status.busy": "2025-03-27T04:49:14.806717Z",
     "iopub.status.idle": "2025-03-27T04:49:14.822600Z",
     "shell.execute_reply": "2025-03-27T04:49:14.821552Z",
     "shell.execute_reply.started": "2025-03-27T04:49:14.807069Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def execute(df, sl_pct, n, portfolio=100000, leverage=1, lot_size=1, slippage=0.0001, rpt = 1):\n",
    "    \n",
    "    trade_book = []\n",
    "    in_trade_long = False\n",
    "    in_trade_short = False\n",
    "    signal_initial_sl_long = 0\n",
    "    signal_initial_sl_short = 0\n",
    "    cumulative_roi = 0\n",
    "    max_drawdown = 0\n",
    "    peak_roi = 0\n",
    "\n",
    "    # print(df.tail(50).to_string())\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        points = 0\n",
    "        \n",
    "        current_candle_open = df.iloc[i][\"open\"]\n",
    "        current_candle_high = df.iloc[i][\"high\"]\n",
    "        current_candle_low = df.iloc[i][\"low\"]\n",
    "        current_candle_close = df.iloc[i][\"close\"]\n",
    "\n",
    "        previous_candle_open = df.iloc[i-1][\"open\"]\n",
    "        previous_candle_high = df.iloc[i-1][\"high\"]\n",
    "        previous_candle_low = df.iloc[i-1][\"low\"]\n",
    "        previous_candle_close = df.iloc[i-1][\"close\"]\n",
    "\n",
    "        if not in_trade_long:\n",
    "            if (df.iloc[i-1]['signal'] == 1) and current_candle_high >= previous_candle_high and current_candle_open <= previous_candle_high:\n",
    "                # Entry Triggered\n",
    "                entry_price_long = previous_candle_high\n",
    "                initial_sl_long = entry_price_long * (1 - (sl_pct / 100))\n",
    "                # initial_sl_long = df.iloc[max(0, i-n):i]['low'].min()\n",
    "                signal_generation_time_long = df.iloc[i-1]['datetime']\n",
    "                entry_time_long = df.iloc[i]['datetime']\n",
    "                in_trade_long = True\n",
    "\n",
    "        if in_trade_long:\n",
    "\n",
    "            if current_candle_low <= initial_sl_long:\n",
    "                if current_candle_open > initial_sl_long:\n",
    "                    # Initial SL Hit\n",
    "                    in_trade_long = False\n",
    "                    exit_price_long = initial_sl_long\n",
    "                    exit_time_long = df.iloc[i]['datetime']\n",
    "                    points = exit_price_long - entry_price_long\n",
    "                    remarks = 'ISL Hit'\n",
    "                elif current_candle_open < initial_sl_long  and (df.iloc[i]['datetime'] != entry_time_long):\n",
    "                    # Gap Open SL\n",
    "                    in_trade_long = False\n",
    "                    exit_price_long = current_candle_open\n",
    "                    exit_time_long = df.iloc[i]['datetime']\n",
    "                    points = exit_price_long - entry_price_long\n",
    "                    remarks = 'Gap SL Hit'\n",
    "                else:\n",
    "                    # Initial SL Hit\n",
    "                    in_trade_long = False\n",
    "                    exit_price_long = initial_sl_long\n",
    "                    exit_time_long = df.iloc[i]['datetime']\n",
    "                    points = exit_price_long - entry_price_long\n",
    "                    remarks = 'ISL Hit'\n",
    "                    \n",
    "            elif df.iloc[i-1]['signal'] == -1 and current_candle_low <= previous_candle_low and previous_candle_low > initial_sl_long:\n",
    "                # MA Cross in Opposite Direction\n",
    "                if current_candle_open >= previous_candle_low:\n",
    "                    in_trade_long = False\n",
    "                    exit_price_long = previous_candle_low\n",
    "                    exit_time_long = df.iloc[i]['datetime']\n",
    "                    points = exit_price_long - entry_price_long\n",
    "                    remarks = 'MA Cross Opp'\n",
    "                else:\n",
    "                    if current_candle_high >= previous_candle_low:\n",
    "                        in_trade_long = False\n",
    "                        exit_price_long = previous_candle_low\n",
    "                        exit_time_long = df.iloc[i]['datetime']\n",
    "                        points = exit_price_long - entry_price_long\n",
    "                        remarks = 'MA Cross Opp'\n",
    "                    else:\n",
    "                        in_trade_long = False\n",
    "                        exit_price_long = current_candle_close\n",
    "                        exit_time_long = df.iloc[i]['datetime']\n",
    "                        points = exit_price_long - entry_price_long\n",
    "                        remarks = 'MA Cross Opp W Gap Exit'\n",
    "\n",
    "            if not in_trade_long and points:\n",
    "                # Exit Found\n",
    "                # qty = int(round((portfolio * leverage / entry_price_long) / lot_size)) * lot_size\n",
    "                qty = int(round((portfolio * rpt / 100) / abs(entry_price_long - initial_sl_long)) / lot_size) * lot_size\n",
    "                slippage_ = slippage * (entry_price_long + exit_price_long)\n",
    "                final_points = points - slippage_\n",
    "                pnl = final_points * qty\n",
    "                roi = (pnl / portfolio) * 100\n",
    "                \n",
    "                trade_book.append({\n",
    "                    \"Trade Type\": \"LONG\",\n",
    "                    \"Entry Time\": entry_time_long,\n",
    "                    \"Entry Price\": entry_price_long,\n",
    "                    \"Initial SL\": initial_sl_long,\n",
    "                    \"Exit Time\": exit_time_long,\n",
    "                    \"Exit Price\": exit_price_long,\n",
    "                    \"Points Captured\": points,\n",
    "                    \"Slippage\": slippage_,\n",
    "                    \"Qty\": qty,\n",
    "                    \"Final Points\": final_points,\n",
    "                    \"PnL\": pnl,\n",
    "                    \"ROI%\": roi,\n",
    "                    \"Trade Duration\": exit_time_long - entry_time_long,\n",
    "                    \"Remarks\": remarks,\n",
    "                })\n",
    "\n",
    "                remarks = \"\"\n",
    "                points = 0\n",
    "\n",
    "        if not in_trade_short:\n",
    "            if (df.iloc[i-1]['signal'] == -1) and current_candle_low <= previous_candle_low and current_candle_open >= previous_candle_low:\n",
    "                # Entry Triggered for Short\n",
    "                entry_price_short = previous_candle_low\n",
    "                initial_sl_short = entry_price_short * (1 + (sl_pct / 100))\n",
    "                # initial_sl_short = df.iloc[max(0, i-n):i]['high'].max()\n",
    "                entry_time_short = df.iloc[i]['datetime']\n",
    "                in_trade_short = True\n",
    "\n",
    "        if in_trade_short:\n",
    "            \n",
    "            if current_candle_high >= initial_sl_short:\n",
    "                if current_candle_open < initial_sl_short:\n",
    "                    # Initial SL Hit for Short\n",
    "                    in_trade_short = False\n",
    "                    exit_price_short = initial_sl_short\n",
    "                    exit_time_short = df.iloc[i]['datetime']\n",
    "                    points = entry_price_short - exit_price_short\n",
    "                    remarks = 'ISL Hit'\n",
    "                elif current_candle_open < initial_sl_short and (df.iloc[i]['datetime'] != entry_time_short):\n",
    "                    # Initial SL Hit for Short\n",
    "                    in_trade_short = False\n",
    "                    exit_price_short = current_candle_open\n",
    "                    exit_time_short = df.iloc[i]['datetime']\n",
    "                    points = entry_price_short - exit_price_short\n",
    "                    remarks = 'Gap SL Hit'\n",
    "                else:\n",
    "                    # Initial SL Hit for Short\n",
    "                    in_trade_short = False\n",
    "                    exit_price_short = initial_sl_short\n",
    "                    exit_time_short = df.iloc[i]['datetime']\n",
    "                    points = entry_price_short - exit_price_short\n",
    "                    remarks = 'ISL Hit'\n",
    "                    \n",
    "            elif df.iloc[i-1]['signal'] == 1 and current_candle_high >= previous_candle_high and previous_candle_high < initial_sl_short:\n",
    "                # MA Cross in Opposite Direction for Short\n",
    "                if current_candle_open <= previous_candle_high:\n",
    "                    in_trade_short = False\n",
    "                    exit_price_short = previous_candle_high\n",
    "                    exit_time_short = df.iloc[i]['datetime']\n",
    "                    points = entry_price_short - exit_price_short\n",
    "                    remarks = 'MA Cross Opp'\n",
    "                else:\n",
    "                    if current_candle_low <= previous_candle_high:\n",
    "                        in_trade_short = False\n",
    "                        exit_price_short = previous_candle_high\n",
    "                        exit_time_short = df.iloc[i]['datetime']\n",
    "                        points = entry_price_short - exit_price_short\n",
    "                        remarks = 'MA Cross Opp'\n",
    "                    else:\n",
    "                        in_trade_short = False\n",
    "                        exit_price_short = current_candle_close\n",
    "                        exit_time_short = df.iloc[i]['datetime']\n",
    "                        points = entry_price_short - exit_price_short\n",
    "                        remarks = 'MA Cross Opp W Gap Exit'\n",
    "\n",
    "            if not in_trade_short and points:\n",
    "                # Exit Found\n",
    "                # qty = int(round((portfolio * leverage / entry_price_short) / lot_size)) * lot_size\n",
    "                qty = int(round((portfolio * rpt / 100) / abs(entry_price_short - initial_sl_short)) / lot_size) * lot_size\n",
    "                slippage_ = slippage * (entry_price_short + exit_price_short)\n",
    "                final_points = points - slippage_\n",
    "                pnl = final_points * qty\n",
    "                roi = (pnl / portfolio) * 100\n",
    "\n",
    "                trade_book.append({\n",
    "                    \"Trade Type\": \"SHORT\",\n",
    "                    \"Entry Time\": entry_time_short,\n",
    "                    \"Entry Price\": entry_price_short,\n",
    "                    \"Initial SL\": initial_sl_short,\n",
    "                    \"Exit Time\": exit_time_short,\n",
    "                    \"Exit Price\": exit_price_short,\n",
    "                    \"Points Captured\": points,\n",
    "                    \"Slippage\": slippage_,\n",
    "                    \"Qty\": qty,\n",
    "                    \"Final Points\": final_points,\n",
    "                    \"PnL\": pnl,\n",
    "                    \"ROI%\": roi,\n",
    "                    \"Trade Duration\": exit_time_short - entry_time_short,\n",
    "                    \"Remarks\": remarks,\n",
    "                })\n",
    "\n",
    "                remarks = \"\"\n",
    "                points = 0\n",
    "\n",
    "    trade_book_df = pd.DataFrame(trade_book)\n",
    "    return trade_book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbb70128-a879-4667-a39b-cf7f2b2984ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T05:04:54.729591Z",
     "iopub.status.busy": "2025-03-27T05:04:54.729155Z",
     "iopub.status.idle": "2025-03-27T05:04:54.741845Z",
     "shell.execute_reply": "2025-03-27T05:04:54.740960Z",
     "shell.execute_reply.started": "2025-03-27T05:04:54.729574Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "async def evaluate_tradebook(tradebook_df, index_symbol, expiries_dict, lot_size=30, strike_spread=100):\n",
    "    results = []\n",
    "    is_roll_over = False\n",
    "    spot_dataframe = bnf_pandas\n",
    "    for _, row in tradebook_df.iterrows():\n",
    "        trade_type = row[\"Trade Type\"]\n",
    "        entry_time = pd.to_datetime(row[\"Entry Time\"])\n",
    "        exit_time = pd.to_datetime(row[\"Exit Time\"])\n",
    "        entry_price = row[\"Entry Price\"]\n",
    "        trade_no = row.index\n",
    "        spot_points = row['Final Points']\n",
    "        spot_entry = row['Entry Price']\n",
    "        spot_exit = row['Exit Price']\n",
    "        remarks = row['Remarks']\n",
    "\n",
    "        # Determine Option Type and ATM Strike\n",
    "        option_type = \"C\" if trade_type == \"SHORT\" else \"P\"\n",
    "        atm_strike = round(entry_price / strike_spread) * strike_spread  # Rounding to nearest 100\n",
    "\n",
    "        # Find initial expiry based on entry date\n",
    "        index_expiries = expiries_dict[index_symbol]\n",
    "        index_expiries = [exp.date() for exp in index_expiries]\n",
    "        index_expiries.sort()\n",
    "        expiry = get_monthly_expiry(entry_time, index_expiries)\n",
    "        # expiry = pd.Timestamp(expiry).date()\n",
    "\n",
    "        total_pnl = 0\n",
    "        rollover_logs = []\n",
    "\n",
    "        # print(row)\n",
    "        # print(\"Entry Exit Expiry\", entry_time, exit_time, expiry)\n",
    "        # print(\"Nearest\", min(entry_time.date(), expiry))\n",
    "\n",
    "        # Ensure all expiries are in datetime.date format\n",
    "        valid_expiries = []\n",
    "        for exp in index_expiries:\n",
    "            if isinstance(exp, dt.datetime):\n",
    "                exp_date = exp.date()\n",
    "            elif isinstance(exp, dt.date):\n",
    "                exp_date = exp\n",
    "            elif isinstance(exp, int):  # Convert integer timestamps (if present)\n",
    "                exp_date = dt.datetime.fromtimestamp(exp).date()\n",
    "                # print(f\"Converted timestamp {exp} → {exp_date}\")  # Debugging log\n",
    "            else:\n",
    "                # print(f\"Skipping invalid expiry: {exp} (type: {type(exp)})\")\n",
    "                continue\n",
    "            # print(type(entry_time.date()), type(exp_date), type(expiry))\n",
    "            if entry_time.date() <= exp_date <= expiry:\n",
    "                valid_expiries.append(exp_date)\n",
    "        \n",
    "        # print(f\"Expiries between {entry_time.date()} and {expiry}: {valid_expiries}\")\n",
    "        \n",
    "        while entry_time < exit_time:\n",
    "            # print(\"Entry Exit Expiry\", entry_time, exit_time, expiry)\n",
    "            current_expiry = expiry\n",
    "            # Get next expiry if needed\n",
    "            if (entry_time.date() > expiry) and is_roll_over: \n",
    "                remarks='Roll-over'\n",
    "                expiry = get_monthly_expiry(entry_time + timedelta(days=1), index_expiries)\n",
    "                # entry_time = pd.Timestamp(expiry) + timedelta(hours=15, minutes=15)  # Start fresh at expiry close\n",
    "                # print(\"Rolling Over, New Entry Time & Expiry : \", entry_time, expiry)\n",
    "                # Try to fetch spot data for the current entry_time date\n",
    "                spot_row = spot_dataframe[spot_dataframe['datetime'].dt.date == entry_time.date()]\n",
    "            \n",
    "                # If no data found, check the next available date\n",
    "                next_date = entry_time.date() + timedelta(days=1)\n",
    "                while spot_row.empty and next_date <= expiry:\n",
    "                    spot_row = spot_dataframe[spot_dataframe['datetime'].dt.date == next_date]\n",
    "                    next_date += timedelta(days=1)  # Move to the next day\n",
    "            \n",
    "                # Ensure we found a valid spot price before proceeding\n",
    "                if spot_row.empty:\n",
    "                    print(\"No spot data available even for future dates. Exiting roll-over logic.\")\n",
    "                else:\n",
    "                    # print(f\"Spot data found for date: {spot_row.iloc[0]['datetime'].date()}\")\n",
    "                    atm_strike = round(spot_row.iloc[TF_int]['close'] / strike_spread) * strike_spread\n",
    "                    entry_date = next_date\n",
    "                    \n",
    "                # print(len(spot_row))\n",
    "                atm_strike = round(spot_row.iloc[TF_int]['close'] / 100) * 100\n",
    "\n",
    "            # print(entry_time, exit_time, expiry)\n",
    "            # Fetch option data for current expiry\n",
    "            # print(type(entry_time.date()))\n",
    "            option_df = await fetch_data(\n",
    "                index=index_symbol,\n",
    "                expiry=expiry,\n",
    "                strike=atm_strike,\n",
    "                asset_class=option_type,\n",
    "                start_date=entry_time.date(),\n",
    "                end_date=min(exit_time.date(), expiry),\n",
    "                start_time = entry_time.time(),\n",
    "                end_time=(exit_time + dt.timedelta(minutes=TF_int-1)).time() if exit_time.date() <= expiry else dt.time(15, 30)\n",
    "            )\n",
    "\n",
    "            # If no data, attempt fetching from previous expiries\n",
    "            while (option_df is None or option_df.is_empty()) and expiry >= entry_time.date():\n",
    "                # print(f\"Missing data for {index_symbol} {option_type} {atm_strike} {expiry}. Trying previous expiry...\")\n",
    "            \n",
    "                # Find index of current expiry in the expiry list\n",
    "                if expiry in index_expiries:\n",
    "                    expiry_index = index_expiries.index(expiry)\n",
    "                    if expiry_index > 0:\n",
    "                        prev_expiry = index_expiries[expiry_index - 1]\n",
    "            \n",
    "                        # Stop retrying if expiry is older than entry_time.date()\n",
    "                        if prev_expiry < entry_time.date():\n",
    "                            # print(f\"Stopped retrying as previous expiry {prev_expiry} is older than entry date {entry_time.date()}\")\n",
    "                            break\n",
    "                        \n",
    "                        # print(f\"Refetching data for previous expiry: {prev_expiry}\")\n",
    "                        expiry = prev_expiry  # Update expiry to the previous expiry\n",
    "                        \n",
    "                        # Retry fetching data\n",
    "                        option_df = await fetch_data(\n",
    "                            index=index_symbol,\n",
    "                            expiry=expiry,\n",
    "                            strike=atm_strike,\n",
    "                            asset_class=option_type,\n",
    "                            start_date=entry_time.date(),\n",
    "                            end_date=min(exit_time.date(), expiry),\n",
    "                            start_time=entry_time.time(),\n",
    "                            end_time=(exit_time + dt.timedelta(minutes=TF_int)).time() if exit_time.date() <= expiry else dt.time(15, 30)\n",
    "                        )\n",
    "                    else:\n",
    "                        # print(f\"No previous expiry available for {index_symbol}\")\n",
    "                        break\n",
    "                else:\n",
    "                    # print(f\"Expiry {expiry} not found in index_expiries dictionary\")\n",
    "                    break\n",
    "            \n",
    "            # Convert to Pandas DataFrame if data exists\n",
    "            if option_df is None:\n",
    "                # print(f\"Final data fetch failed for {index_symbol} {option_type} {atm_strike}\")\n",
    "                break  # Exit loop if no data is available\n",
    "                \n",
    "            elif option_df is not None and not option_df.is_empty():\n",
    "                option_df = resample(option_df, '15m')\n",
    "                option_df = option_df.to_pandas()\n",
    "                \n",
    "                entry_option_price = option_df.iloc[0]['c']\n",
    "                exit_option_price = option_df.iloc[-1]['c']\n",
    "                \n",
    "                if not results or results[-1][\"Option Entry Time\"] != entry_time:\n",
    "                    results.append({\n",
    "                        \"Trade No.\": trade_no,\n",
    "                        \"Trade Type\": trade_type,\n",
    "                        \"Spot Entry\": spot_entry,\n",
    "                        \"Spot Exit\": spot_exit,\n",
    "                        \"ATM Strike\": atm_strike,\n",
    "                        \"Expiry\": expiry,\n",
    "                        \"Option Type\": option_type,\n",
    "                        \"Option Entry Time\": entry_time,\n",
    "                        \"Option Exit Time\": exit_time,\n",
    "                        \"Option Entry Price\": entry_option_price,\n",
    "                        \"Option Exit Price\": exit_option_price,\n",
    "                        \"Option Points\": entry_option_price - exit_option_price,\n",
    "                        \"Slippages\": OPT_SLIPPAGE_ * (entry_option_price + exit_option_price),\n",
    "                        \"Remarks\": remarks,\n",
    "                        \"Option Final Points\": (entry_option_price - exit_option_price) - (0.01 * (entry_option_price + exit_option_price)),\n",
    "                        \"Spot Final Points\": spot_points,\n",
    "                    })\n",
    "                # break\n",
    "                option_df = pd.DataFrame()\n",
    "            \n",
    "            else:\n",
    "                print(f\"Final data fetch failed for {index_symbol} {option_type} {atm_strike}\")\n",
    "                break  # Exit loop if no data is available\n",
    "                \n",
    "            entry_time = pd.Timestamp(current_expiry) + timedelta(days=1, hours=9, minutes=15)\n",
    "\n",
    "            # Set a Roll-over flag also\n",
    "            is_roll_over = True\n",
    "\n",
    "        is_roll_over = False\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "804fd873-e602-4cfd-904f-e729313fed44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T05:03:04.334367Z",
     "iopub.status.busy": "2025-03-27T05:03:04.333793Z",
     "iopub.status.idle": "2025-03-27T05:03:04.338578Z",
     "shell.execute_reply": "2025-03-27T05:03:04.337463Z",
     "shell.execute_reply.started": "2025-03-27T05:03:04.334344Z"
    }
   },
   "outputs": [],
   "source": [
    "PORTFOLIO = 50_00_000\n",
    "LEVERAGE_ = 5\n",
    "LOT_SIZE_ = 30\n",
    "SLIPPAGE_ = 0.0001\n",
    "RPT_ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1c46858-c7f6-49ba-b13a-0a89e42857b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T05:08:38.730874Z",
     "iopub.status.busy": "2025-03-27T05:08:38.730449Z",
     "iopub.status.idle": "2025-03-27T05:08:38.738770Z",
     "shell.execute_reply": "2025-03-27T05:08:38.737844Z",
     "shell.execute_reply.started": "2025-03-27T05:08:38.730857Z"
    }
   },
   "outputs": [],
   "source": [
    "async def setup():\n",
    "    sl_pct_range = [0.5, 0.75, 1, 1.25, 1.5]\n",
    "    stats_dictionary = {}\n",
    "    \n",
    "    PORTFOLIO = 1_00_00_000\n",
    "    LEVERAGE_ = 5\n",
    "    LOT_SIZE_ = 30\n",
    "    STRIKE_SPREAD_ = 100\n",
    "    SLIPPAGE_ = 0.0001\n",
    "    \n",
    "    for i in range(4, 41, 2):\n",
    "        for j in range(6, 81, 2):\n",
    "            for sl in sl_pct_range:\n",
    "                if i < j and ((j-i) <= 16):\n",
    "                    variation = f'MA1 : {i}, MA2 : {j}, SL : {sl}%'\n",
    "                    print(variation)\n",
    "                    df_spot = ma_crossover_logic(bnf_pandas, i, j)\n",
    "                    tb = execute(df_spot, sl, 1, PORTFOLIO, LEVERAGE_, LOT_SIZE_, SLIPPAGE_, 3)\n",
    "                    if len(tb) > 0:\n",
    "                        tb['Trade Year'] = tb['Entry Time'].dt.year\n",
    "                        tb = tb.sort_values(by=\"Entry Time\")\n",
    "                        stats = generate_stats(tb, f'SPOT -> {variation}')\n",
    "        \n",
    "                        for overall_roi_dd_ratio, stats_df in stats.items():\n",
    "                            if overall_roi_dd_ratio is not None and overall_roi_dd_ratio > -10:\n",
    "                                print('---------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "                                print(stats_df.to_string())\n",
    "                                # print(tb.head().to_string())\n",
    "\n",
    "                        df = tb\n",
    "                        df['Entry Time'] = pd.to_datetime(df['Entry Time'])\n",
    "                        df['Exit Time'] = pd.to_datetime(df['Exit Time'])\n",
    "\n",
    "                        option_tb = await evaluate_tradebook(df, symbol, dict_expiries, LOT_SIZE_, STRIKE_SPREAD_)\n",
    "\n",
    "                        option_tb['Opt Slippage'] = 0.01 * (option_tb['Option Entry Price'] + option_tb['Option Exit Price'])\n",
    "                        option_tb['Opt Qty'] = 5000000 * 6 / option_tb['ATM Strike']\n",
    "                        option_tb['Opt PnL'] = option_tb['Opt Qty'] * option_tb['Option Final Points']\n",
    "                        option_tb['Opt ROI%'] = option_tb['Opt PnL'] * 100 / PORTFOLIO\n",
    "                        option_tb['Trade Year'] = option_tb['Option Entry Time'].dt.year\n",
    "\n",
    "                        stats_opt = generate_stats_options(option_tb, f'OPT -> {variation}')\n",
    "                        for overall_roi_dd_ratio, stats_df in stats_opt.items():\n",
    "                            if overall_roi_dd_ratio is not None and overall_roi_dd_ratio > -10:\n",
    "                                print(stats_df.to_string())\n",
    "                                print('---------------------------------------------------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca06d6-b6bc-4836-8662-428eca805e4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T05:08:39.678385Z",
     "iopub.status.busy": "2025-03-27T05:08:39.677609Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "        Total ROI Total Trades Win Rate Avg Profit% per Trade Avg Loss% per Trade Max Drawdown ROI/DD Ratio                            Variation\n",
      "2017     -36.6379          773  31.0479                2.6014             -1.2401     -62.5337      -0.5859  SPOT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2018      11.3946          765  30.1961                3.5295             -1.5055     -70.1955       0.1623  SPOT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2019      94.3033          758  31.7942                3.8548             -1.6145     -86.2721       1.0931  SPOT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2020     278.4848          892  26.6816                7.9496             -2.4672    -108.5010       2.5667  SPOT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2021     124.6349          754  32.4934                4.7741             -2.0531     -50.5188       2.4671  SPOT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2022     250.9075          741  34.6829                4.6296             -1.9399     -91.4664       2.7432  SPOT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2023    -104.6015          774  30.3618                2.6496             -1.3493    -142.3803      -0.7347  SPOT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2024     -23.3630          736  29.8913                3.4239             -1.5051     -81.0122      -0.2884  SPOT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2025      21.1345           73  38.3562                3.5472             -1.7375     -25.9222       0.8153  SPOT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "Overall  616.2572         6266  30.8809                4.1836             -1.7269    -158.3932       3.8907  SPOT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "        Total ROI Total Trades Win Rate Avg Profit% per Trade Avg Loss% per Trade Max Drawdown ROI/DD Ratio                           Variation\n",
      "2017     -31.2908          767  33.1160                0.5232             -0.3200     -34.7063      -0.9016  OPT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2018     -14.5365          753  35.3254                0.6701             -0.3959     -32.3714      -0.4491  OPT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2019     -33.3884          741  33.1984                0.7632             -0.4467     -40.4373      -0.8257  OPT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2020     -67.6236          766  30.8094                1.6472             -0.8611     -85.6683      -0.7894  OPT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2021       4.3354          718  36.9081                0.9998             -0.5753     -17.7773       0.2439  OPT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2022       0.6717          721  36.3384                0.9627             -0.5481     -37.2212       0.0180  OPT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2023     -20.1830          769  39.5319                0.4675             -0.3490     -26.4116      -0.7642  OPT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2024     -44.7954          709  38.6460                0.5939             -0.4771     -47.7248      -0.9386  OPT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "2025       3.8984           68  32.3529                0.9990             -0.3930      -4.8255       0.8079  OPT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "Overall -202.9123         6012  35.4125                0.8134             -0.4982    -207.7272      -0.9768  OPT -> MA1 : 4, MA2 : 6, SL : 0.5%\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "MA1 : 4, MA2 : 6, SL : 0.75%\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "        Total ROI Total Trades Win Rate Avg Profit% per Trade Avg Loss% per Trade Max Drawdown ROI/DD Ratio                             Variation\n",
      "2017     -11.1279          762  31.3648                1.7512             -0.8215     -34.3534      -0.3239  SPOT -> MA1 : 4, MA2 : 6, SL : 0.75%\n",
      "2018      19.7187          749  30.9746                2.3536             -1.0180     -41.7806       0.4720  SPOT -> MA1 : 4, MA2 : 6, SL : 0.75%\n",
      "2019      58.2089          747  32.3963                2.5630             -1.1129     -53.8193       1.0816  SPOT -> MA1 : 4, MA2 : 6, SL : 0.75%\n",
      "2020     168.0073          818  30.4401                5.1704             -1.9674     -73.2220       2.2945  SPOT -> MA1 : 4, MA2 : 6, SL : 0.75%\n",
      "2021      71.0860          721  34.3967                3.1685             -1.5110     -43.0408       1.6516  SPOT -> MA1 : 4, MA2 : 6, SL : 0.75%\n",
      "2022     177.1168          717  35.9833                3.0950             -1.3538     -61.3492       2.8870  SPOT -> MA1 : 4, MA2 : 6, SL : 0.75%\n",
      "2023     -67.8383          766  30.9399                1.7577             -0.9157     -92.9222      -0.7301  SPOT -> MA1 : 4, MA2 : 6, SL : 0.75%\n",
      "2024      11.1442          720  30.6944                2.3408             -1.0144     -46.4319       0.2400  SPOT -> MA1 : 4, MA2 : 6, SL : 0.75%\n",
      "2025      12.5240           73  38.3562                2.3621             -1.1914     -18.6553       0.6713  SPOT -> MA1 : 4, MA2 : 6, SL : 0.75%\n",
      "Overall  438.8399         6073  32.1752                2.7925             -1.2182     -92.9222       4.7227  SPOT -> MA1 : 4, MA2 : 6, SL : 0.75%\n"
     ]
    }
   ],
   "source": [
    "await setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5431a3-d1a8-47ae-a021-96c5e6ce0933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
